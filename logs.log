2025-07-10 09:18:41,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 09:18:41,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 09:18:41,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 09:18:41,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 09:18:45,878:INFO:PyCaret ClassificationExperiment
2025-07-10 09:18:45,878:INFO:Logging name: clf-default-name
2025-07-10 09:18:45,879:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-10 09:18:45,879:INFO:version 3.3.2
2025-07-10 09:18:45,879:INFO:Initializing setup()
2025-07-10 09:18:45,879:INFO:self.USI: c074
2025-07-10 09:18:45,879:INFO:self._variable_keys: {'pipeline', 'exp_id', 'log_plots_param', 'fix_imbalance', 'n_jobs_param', 'gpu_param', 'seed', 'gpu_n_jobs_param', 'fold_groups_param', 'memory', 'target_param', 'y_test', 'html_param', 'X', 'is_multiclass', 'y', 'logging_param', 'X_train', 'X_test', 'USI', '_ml_usecase', '_available_plots', 'idx', 'data', 'y_train', 'exp_name_log', 'fold_generator', 'fold_shuffle_param'}
2025-07-10 09:18:45,880:INFO:Checking environment
2025-07-10 09:18:45,880:INFO:python_version: 3.11.7
2025-07-10 09:18:45,880:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-10 09:18:45,880:INFO:machine: AMD64
2025-07-10 09:18:45,880:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-10 09:18:45,880:INFO:Memory: svmem(total=12698038272, available=4457947136, percent=64.9, used=8240091136, free=4457947136)
2025-07-10 09:18:45,881:INFO:Physical Core: 2
2025-07-10 09:18:45,881:INFO:Logical Core: 4
2025-07-10 09:18:45,881:INFO:Checking libraries
2025-07-10 09:18:45,881:INFO:System:
2025-07-10 09:18:45,881:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-10 09:18:45,882:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-10 09:18:45,882:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-10 09:18:45,882:INFO:PyCaret required dependencies:
2025-07-10 09:18:47,733:INFO:                 pip: 23.3.1
2025-07-10 09:18:47,733:INFO:          setuptools: 68.2.2
2025-07-10 09:18:47,733:INFO:             pycaret: 3.3.2
2025-07-10 09:18:47,733:INFO:             IPython: 8.20.0
2025-07-10 09:18:47,733:INFO:          ipywidgets: 7.7.2
2025-07-10 09:18:47,733:INFO:                tqdm: 4.65.0
2025-07-10 09:18:47,733:INFO:               numpy: 1.26.4
2025-07-10 09:18:47,733:INFO:              pandas: 2.1.4
2025-07-10 09:18:47,733:INFO:              jinja2: 3.1.3
2025-07-10 09:18:47,733:INFO:               scipy: 1.11.4
2025-07-10 09:18:47,733:INFO:              joblib: 1.2.0
2025-07-10 09:18:47,733:INFO:             sklearn: 1.4.2
2025-07-10 09:18:47,733:INFO:                pyod: 2.0.5
2025-07-10 09:18:47,733:INFO:            imblearn: 0.13.0
2025-07-10 09:18:47,733:INFO:   category_encoders: 2.7.0
2025-07-10 09:18:47,733:INFO:            lightgbm: 4.6.0
2025-07-10 09:18:47,733:INFO:               numba: 0.59.0
2025-07-10 09:18:47,733:INFO:            requests: 2.31.0
2025-07-10 09:18:47,733:INFO:          matplotlib: 3.7.5
2025-07-10 09:18:47,733:INFO:          scikitplot: 0.3.7
2025-07-10 09:18:47,733:INFO:         yellowbrick: 1.5
2025-07-10 09:18:47,733:INFO:              plotly: 5.24.1
2025-07-10 09:18:47,733:INFO:    plotly-resampler: Not installed
2025-07-10 09:18:47,733:INFO:             kaleido: 1.0.0
2025-07-10 09:18:47,733:INFO:           schemdraw: 0.15
2025-07-10 09:18:47,733:INFO:         statsmodels: 0.14.0
2025-07-10 09:18:47,733:INFO:              sktime: 0.26.0
2025-07-10 09:18:47,733:INFO:               tbats: 1.1.3
2025-07-10 09:18:47,733:INFO:            pmdarima: 2.0.4
2025-07-10 09:18:47,733:INFO:              psutil: 5.9.0
2025-07-10 09:18:47,733:INFO:          markupsafe: 2.1.3
2025-07-10 09:18:47,733:INFO:             pickle5: Not installed
2025-07-10 09:18:47,733:INFO:         cloudpickle: 2.2.1
2025-07-10 09:18:47,733:INFO:         deprecation: 2.1.0
2025-07-10 09:18:47,733:INFO:              xxhash: 3.5.0
2025-07-10 09:18:47,733:INFO:           wurlitzer: Not installed
2025-07-10 09:18:47,733:INFO:PyCaret optional dependencies:
2025-07-10 09:18:47,749:INFO:                shap: Not installed
2025-07-10 09:18:47,749:INFO:           interpret: Not installed
2025-07-10 09:18:47,749:INFO:                umap: Not installed
2025-07-10 09:18:47,749:INFO:     ydata_profiling: 4.7.0
2025-07-10 09:18:47,749:INFO:  explainerdashboard: Not installed
2025-07-10 09:18:47,749:INFO:             autoviz: Not installed
2025-07-10 09:18:47,749:INFO:           fairlearn: Not installed
2025-07-10 09:18:47,749:INFO:          deepchecks: Not installed
2025-07-10 09:18:47,749:INFO:             xgboost: Not installed
2025-07-10 09:18:47,749:INFO:            catboost: Not installed
2025-07-10 09:18:47,749:INFO:              kmodes: Not installed
2025-07-10 09:18:47,749:INFO:             mlxtend: Not installed
2025-07-10 09:18:47,749:INFO:       statsforecast: Not installed
2025-07-10 09:18:47,749:INFO:        tune_sklearn: Not installed
2025-07-10 09:18:47,749:INFO:                 ray: Not installed
2025-07-10 09:18:47,749:INFO:            hyperopt: Not installed
2025-07-10 09:18:47,749:INFO:              optuna: Not installed
2025-07-10 09:18:47,749:INFO:               skopt: Not installed
2025-07-10 09:18:47,749:INFO:              mlflow: Not installed
2025-07-10 09:18:47,749:INFO:              gradio: Not installed
2025-07-10 09:18:47,749:INFO:             fastapi: Not installed
2025-07-10 09:18:47,749:INFO:             uvicorn: Not installed
2025-07-10 09:18:47,749:INFO:              m2cgen: Not installed
2025-07-10 09:18:47,749:INFO:           evidently: Not installed
2025-07-10 09:18:47,749:INFO:               fugue: Not installed
2025-07-10 09:18:47,749:INFO:           streamlit: 1.46.1
2025-07-10 09:18:47,749:INFO:             prophet: Not installed
2025-07-10 09:18:47,749:INFO:None
2025-07-10 09:18:47,749:INFO:Set up data.
2025-07-10 09:18:47,786:INFO:Set up folding strategy.
2025-07-10 09:18:47,786:INFO:Set up train/test split.
2025-07-10 09:18:47,833:INFO:Set up index.
2025-07-10 09:18:47,833:INFO:Assigning column types.
2025-07-10 09:18:47,865:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-10 09:18:48,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,018:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,234:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,303:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-10 09:18:48,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 09:18:48,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,665:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-10 09:18:48,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:48,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,103:INFO:Preparing preprocessing pipeline...
2025-07-10 09:18:49,103:INFO:Set up simple imputation.
2025-07-10 09:18:49,204:INFO:Finished creating preprocessing pipeline.
2025-07-10 09:18:49,204:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-07-10 09:18:49,204:INFO:Creating final display dataframe.
2025-07-10 09:18:49,454:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape       (22800, 24)
4        Transformed data shape       (22800, 24)
5   Transformed train set shape       (15959, 24)
6    Transformed test set shape        (6841, 24)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c074
2025-07-10 09:18:49,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:18:49,874:INFO:setup() successfully completed in 4.0s...............
2025-07-10 09:18:57,163:INFO:Initializing compare_models()
2025-07-10 09:18:57,163:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, include=None, exclude=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-10 09:18:57,164:INFO:Checking exceptions
2025-07-10 09:18:57,200:INFO:Preparing display monitor
2025-07-10 09:18:57,271:INFO:Initializing Logistic Regression
2025-07-10 09:18:57,271:INFO:Total runtime is 0.0 minutes
2025-07-10 09:18:57,280:INFO:SubProcess create_model() called ==================================
2025-07-10 09:18:57,281:INFO:Initializing create_model()
2025-07-10 09:18:57,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:18:57,285:INFO:Checking exceptions
2025-07-10 09:18:57,285:INFO:Importing libraries
2025-07-10 09:18:57,285:INFO:Copying training dataset
2025-07-10 09:18:57,382:INFO:Defining folds
2025-07-10 09:18:57,383:INFO:Declaring metric variables
2025-07-10 09:18:57,390:INFO:Importing untrained model
2025-07-10 09:18:57,415:INFO:Logistic Regression Imported successfully
2025-07-10 09:18:57,435:INFO:Starting cross validation
2025-07-10 09:18:57,437:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:17,441:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 09:19:17,512:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 09:19:17,614:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 09:19:19,259:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 09:19:20,036:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 09:19:20,076:INFO:Calculating mean and std
2025-07-10 09:19:20,076:INFO:Creating metrics dataframe
2025-07-10 09:19:20,084:INFO:Uploading results into container
2025-07-10 09:19:20,086:INFO:Uploading model into container now
2025-07-10 09:19:20,086:INFO:_master_model_container: 1
2025-07-10 09:19:20,086:INFO:_display_container: 2
2025-07-10 09:19:20,086:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-10 09:19:20,086:INFO:create_model() successfully completed......................................
2025-07-10 09:19:20,199:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:20,199:INFO:Creating metrics dataframe
2025-07-10 09:19:20,252:INFO:Initializing K Neighbors Classifier
2025-07-10 09:19:20,252:INFO:Total runtime is 0.38301920890808105 minutes
2025-07-10 09:19:20,257:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:20,258:INFO:Initializing create_model()
2025-07-10 09:19:20,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:20,259:INFO:Checking exceptions
2025-07-10 09:19:20,259:INFO:Importing libraries
2025-07-10 09:19:20,259:INFO:Copying training dataset
2025-07-10 09:19:20,297:INFO:Defining folds
2025-07-10 09:19:20,297:INFO:Declaring metric variables
2025-07-10 09:19:20,297:INFO:Importing untrained model
2025-07-10 09:19:20,314:INFO:K Neighbors Classifier Imported successfully
2025-07-10 09:19:20,331:INFO:Starting cross validation
2025-07-10 09:19:20,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:23,006:INFO:Calculating mean and std
2025-07-10 09:19:23,014:INFO:Creating metrics dataframe
2025-07-10 09:19:23,016:INFO:Uploading results into container
2025-07-10 09:19:23,016:INFO:Uploading model into container now
2025-07-10 09:19:23,016:INFO:_master_model_container: 2
2025-07-10 09:19:23,016:INFO:_display_container: 2
2025-07-10 09:19:23,016:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-10 09:19:23,016:INFO:create_model() successfully completed......................................
2025-07-10 09:19:23,135:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:23,135:INFO:Creating metrics dataframe
2025-07-10 09:19:23,145:INFO:Initializing Naive Bayes
2025-07-10 09:19:23,145:INFO:Total runtime is 0.43124315738677976 minutes
2025-07-10 09:19:23,159:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:23,160:INFO:Initializing create_model()
2025-07-10 09:19:23,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:23,160:INFO:Checking exceptions
2025-07-10 09:19:23,161:INFO:Importing libraries
2025-07-10 09:19:23,161:INFO:Copying training dataset
2025-07-10 09:19:23,196:INFO:Defining folds
2025-07-10 09:19:23,196:INFO:Declaring metric variables
2025-07-10 09:19:23,205:INFO:Importing untrained model
2025-07-10 09:19:23,214:INFO:Naive Bayes Imported successfully
2025-07-10 09:19:23,225:INFO:Starting cross validation
2025-07-10 09:19:23,225:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:23,506:INFO:Calculating mean and std
2025-07-10 09:19:23,508:INFO:Creating metrics dataframe
2025-07-10 09:19:23,508:INFO:Uploading results into container
2025-07-10 09:19:23,508:INFO:Uploading model into container now
2025-07-10 09:19:23,508:INFO:_master_model_container: 3
2025-07-10 09:19:23,508:INFO:_display_container: 2
2025-07-10 09:19:23,508:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-10 09:19:23,508:INFO:create_model() successfully completed......................................
2025-07-10 09:19:23,623:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:23,648:INFO:Creating metrics dataframe
2025-07-10 09:19:23,663:INFO:Initializing Decision Tree Classifier
2025-07-10 09:19:23,663:INFO:Total runtime is 0.43987536032994584 minutes
2025-07-10 09:19:23,679:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:23,682:INFO:Initializing create_model()
2025-07-10 09:19:23,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:23,682:INFO:Checking exceptions
2025-07-10 09:19:23,682:INFO:Importing libraries
2025-07-10 09:19:23,683:INFO:Copying training dataset
2025-07-10 09:19:23,728:INFO:Defining folds
2025-07-10 09:19:23,728:INFO:Declaring metric variables
2025-07-10 09:19:23,745:INFO:Importing untrained model
2025-07-10 09:19:23,749:INFO:Decision Tree Classifier Imported successfully
2025-07-10 09:19:23,764:INFO:Starting cross validation
2025-07-10 09:19:23,764:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:25,049:INFO:Calculating mean and std
2025-07-10 09:19:25,067:INFO:Creating metrics dataframe
2025-07-10 09:19:25,077:INFO:Uploading results into container
2025-07-10 09:19:25,077:INFO:Uploading model into container now
2025-07-10 09:19:25,077:INFO:_master_model_container: 4
2025-07-10 09:19:25,077:INFO:_display_container: 2
2025-07-10 09:19:25,077:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 09:19:25,077:INFO:create_model() successfully completed......................................
2025-07-10 09:19:25,208:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:25,208:INFO:Creating metrics dataframe
2025-07-10 09:19:25,238:INFO:Initializing SVM - Linear Kernel
2025-07-10 09:19:25,238:INFO:Total runtime is 0.46611878077189123 minutes
2025-07-10 09:19:25,246:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:25,246:INFO:Initializing create_model()
2025-07-10 09:19:25,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:25,247:INFO:Checking exceptions
2025-07-10 09:19:25,247:INFO:Importing libraries
2025-07-10 09:19:25,248:INFO:Copying training dataset
2025-07-10 09:19:25,290:INFO:Defining folds
2025-07-10 09:19:25,290:INFO:Declaring metric variables
2025-07-10 09:19:25,305:INFO:Importing untrained model
2025-07-10 09:19:25,316:INFO:SVM - Linear Kernel Imported successfully
2025-07-10 09:19:25,333:INFO:Starting cross validation
2025-07-10 09:19:25,335:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:26,296:INFO:Calculating mean and std
2025-07-10 09:19:26,296:INFO:Creating metrics dataframe
2025-07-10 09:19:26,296:INFO:Uploading results into container
2025-07-10 09:19:26,296:INFO:Uploading model into container now
2025-07-10 09:19:26,296:INFO:_master_model_container: 5
2025-07-10 09:19:26,296:INFO:_display_container: 2
2025-07-10 09:19:26,296:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-10 09:19:26,296:INFO:create_model() successfully completed......................................
2025-07-10 09:19:26,448:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:26,449:INFO:Creating metrics dataframe
2025-07-10 09:19:26,470:INFO:Initializing Ridge Classifier
2025-07-10 09:19:26,470:INFO:Total runtime is 0.48666199445724484 minutes
2025-07-10 09:19:26,479:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:26,480:INFO:Initializing create_model()
2025-07-10 09:19:26,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:26,480:INFO:Checking exceptions
2025-07-10 09:19:26,480:INFO:Importing libraries
2025-07-10 09:19:26,480:INFO:Copying training dataset
2025-07-10 09:19:26,570:INFO:Defining folds
2025-07-10 09:19:26,570:INFO:Declaring metric variables
2025-07-10 09:19:26,608:INFO:Importing untrained model
2025-07-10 09:19:26,610:INFO:Ridge Classifier Imported successfully
2025-07-10 09:19:26,637:INFO:Starting cross validation
2025-07-10 09:19:26,641:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:26,968:INFO:Calculating mean and std
2025-07-10 09:19:26,970:INFO:Creating metrics dataframe
2025-07-10 09:19:26,970:INFO:Uploading results into container
2025-07-10 09:19:26,970:INFO:Uploading model into container now
2025-07-10 09:19:26,970:INFO:_master_model_container: 6
2025-07-10 09:19:26,970:INFO:_display_container: 2
2025-07-10 09:19:26,982:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-10 09:19:26,982:INFO:create_model() successfully completed......................................
2025-07-10 09:19:27,109:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:27,109:INFO:Creating metrics dataframe
2025-07-10 09:19:27,124:INFO:Initializing Random Forest Classifier
2025-07-10 09:19:27,124:INFO:Total runtime is 0.4975610097249349 minutes
2025-07-10 09:19:27,143:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:27,144:INFO:Initializing create_model()
2025-07-10 09:19:27,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:27,144:INFO:Checking exceptions
2025-07-10 09:19:27,145:INFO:Importing libraries
2025-07-10 09:19:27,145:INFO:Copying training dataset
2025-07-10 09:19:27,189:INFO:Defining folds
2025-07-10 09:19:27,189:INFO:Declaring metric variables
2025-07-10 09:19:27,205:INFO:Importing untrained model
2025-07-10 09:19:27,211:INFO:Random Forest Classifier Imported successfully
2025-07-10 09:19:27,228:INFO:Starting cross validation
2025-07-10 09:19:27,239:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:37,865:INFO:Calculating mean and std
2025-07-10 09:19:37,873:INFO:Creating metrics dataframe
2025-07-10 09:19:37,875:INFO:Uploading results into container
2025-07-10 09:19:37,875:INFO:Uploading model into container now
2025-07-10 09:19:37,875:INFO:_master_model_container: 7
2025-07-10 09:19:37,875:INFO:_display_container: 2
2025-07-10 09:19:37,875:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-10 09:19:37,883:INFO:create_model() successfully completed......................................
2025-07-10 09:19:38,048:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:38,048:INFO:Creating metrics dataframe
2025-07-10 09:19:38,076:INFO:Initializing Quadratic Discriminant Analysis
2025-07-10 09:19:38,076:INFO:Total runtime is 0.6800867358843485 minutes
2025-07-10 09:19:38,088:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:38,089:INFO:Initializing create_model()
2025-07-10 09:19:38,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:38,090:INFO:Checking exceptions
2025-07-10 09:19:38,090:INFO:Importing libraries
2025-07-10 09:19:38,091:INFO:Copying training dataset
2025-07-10 09:19:38,141:INFO:Defining folds
2025-07-10 09:19:38,143:INFO:Declaring metric variables
2025-07-10 09:19:38,161:INFO:Importing untrained model
2025-07-10 09:19:38,169:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-10 09:19:38,189:INFO:Starting cross validation
2025-07-10 09:19:38,189:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:38,563:INFO:Calculating mean and std
2025-07-10 09:19:38,571:INFO:Creating metrics dataframe
2025-07-10 09:19:38,573:INFO:Uploading results into container
2025-07-10 09:19:38,573:INFO:Uploading model into container now
2025-07-10 09:19:38,573:INFO:_master_model_container: 8
2025-07-10 09:19:38,573:INFO:_display_container: 2
2025-07-10 09:19:38,573:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-10 09:19:38,573:INFO:create_model() successfully completed......................................
2025-07-10 09:19:38,744:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:38,744:INFO:Creating metrics dataframe
2025-07-10 09:19:38,772:INFO:Initializing Ada Boost Classifier
2025-07-10 09:19:38,772:INFO:Total runtime is 0.6916944543520609 minutes
2025-07-10 09:19:38,782:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:38,782:INFO:Initializing create_model()
2025-07-10 09:19:38,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:38,783:INFO:Checking exceptions
2025-07-10 09:19:38,783:INFO:Importing libraries
2025-07-10 09:19:38,783:INFO:Copying training dataset
2025-07-10 09:19:38,829:INFO:Defining folds
2025-07-10 09:19:38,829:INFO:Declaring metric variables
2025-07-10 09:19:38,843:INFO:Importing untrained model
2025-07-10 09:19:38,853:INFO:Ada Boost Classifier Imported successfully
2025-07-10 09:19:38,876:INFO:Starting cross validation
2025-07-10 09:19:38,879:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:19:38,988:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 09:19:38,996:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 09:19:38,998:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 09:19:39,038:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 09:19:41,648:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 09:19:43,670:INFO:Calculating mean and std
2025-07-10 09:19:43,670:INFO:Creating metrics dataframe
2025-07-10 09:19:43,678:INFO:Uploading results into container
2025-07-10 09:19:43,678:INFO:Uploading model into container now
2025-07-10 09:19:43,678:INFO:_master_model_container: 9
2025-07-10 09:19:43,678:INFO:_display_container: 2
2025-07-10 09:19:43,678:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-10 09:19:43,678:INFO:create_model() successfully completed......................................
2025-07-10 09:19:43,832:INFO:SubProcess create_model() end ==================================
2025-07-10 09:19:43,832:INFO:Creating metrics dataframe
2025-07-10 09:19:43,863:INFO:Initializing Gradient Boosting Classifier
2025-07-10 09:19:43,863:INFO:Total runtime is 0.7765442093213398 minutes
2025-07-10 09:19:43,872:INFO:SubProcess create_model() called ==================================
2025-07-10 09:19:43,873:INFO:Initializing create_model()
2025-07-10 09:19:43,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:19:43,873:INFO:Checking exceptions
2025-07-10 09:19:43,873:INFO:Importing libraries
2025-07-10 09:19:43,873:INFO:Copying training dataset
2025-07-10 09:19:43,929:INFO:Defining folds
2025-07-10 09:19:43,929:INFO:Declaring metric variables
2025-07-10 09:19:43,946:INFO:Importing untrained model
2025-07-10 09:19:43,955:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 09:19:43,976:INFO:Starting cross validation
2025-07-10 09:19:43,980:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:20:02,498:INFO:Calculating mean and std
2025-07-10 09:20:02,498:INFO:Creating metrics dataframe
2025-07-10 09:20:02,498:INFO:Uploading results into container
2025-07-10 09:20:02,498:INFO:Uploading model into container now
2025-07-10 09:20:02,498:INFO:_master_model_container: 10
2025-07-10 09:20:02,498:INFO:_display_container: 2
2025-07-10 09:20:02,506:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 09:20:02,506:INFO:create_model() successfully completed......................................
2025-07-10 09:20:02,627:INFO:SubProcess create_model() end ==================================
2025-07-10 09:20:02,627:INFO:Creating metrics dataframe
2025-07-10 09:20:02,647:INFO:Initializing Linear Discriminant Analysis
2025-07-10 09:20:02,647:INFO:Total runtime is 1.0895995497703552 minutes
2025-07-10 09:20:02,647:INFO:SubProcess create_model() called ==================================
2025-07-10 09:20:02,661:INFO:Initializing create_model()
2025-07-10 09:20:02,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:20:02,662:INFO:Checking exceptions
2025-07-10 09:20:02,662:INFO:Importing libraries
2025-07-10 09:20:02,662:INFO:Copying training dataset
2025-07-10 09:20:02,704:INFO:Defining folds
2025-07-10 09:20:02,704:INFO:Declaring metric variables
2025-07-10 09:20:02,715:INFO:Importing untrained model
2025-07-10 09:20:02,720:INFO:Linear Discriminant Analysis Imported successfully
2025-07-10 09:20:02,736:INFO:Starting cross validation
2025-07-10 09:20:02,736:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:20:03,131:INFO:Calculating mean and std
2025-07-10 09:20:03,131:INFO:Creating metrics dataframe
2025-07-10 09:20:03,143:INFO:Uploading results into container
2025-07-10 09:20:03,145:INFO:Uploading model into container now
2025-07-10 09:20:03,146:INFO:_master_model_container: 11
2025-07-10 09:20:03,146:INFO:_display_container: 2
2025-07-10 09:20:03,148:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-10 09:20:03,148:INFO:create_model() successfully completed......................................
2025-07-10 09:20:03,264:INFO:SubProcess create_model() end ==================================
2025-07-10 09:20:03,264:INFO:Creating metrics dataframe
2025-07-10 09:20:03,273:INFO:Initializing Extra Trees Classifier
2025-07-10 09:20:03,273:INFO:Total runtime is 1.1000433603922526 minutes
2025-07-10 09:20:03,283:INFO:SubProcess create_model() called ==================================
2025-07-10 09:20:03,287:INFO:Initializing create_model()
2025-07-10 09:20:03,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:20:03,287:INFO:Checking exceptions
2025-07-10 09:20:03,287:INFO:Importing libraries
2025-07-10 09:20:03,288:INFO:Copying training dataset
2025-07-10 09:20:03,326:INFO:Defining folds
2025-07-10 09:20:03,326:INFO:Declaring metric variables
2025-07-10 09:20:03,335:INFO:Importing untrained model
2025-07-10 09:20:03,349:INFO:Extra Trees Classifier Imported successfully
2025-07-10 09:20:03,364:INFO:Starting cross validation
2025-07-10 09:20:03,366:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:20:08,810:INFO:Calculating mean and std
2025-07-10 09:20:08,810:INFO:Creating metrics dataframe
2025-07-10 09:20:08,810:INFO:Uploading results into container
2025-07-10 09:20:08,826:INFO:Uploading model into container now
2025-07-10 09:20:08,826:INFO:_master_model_container: 12
2025-07-10 09:20:08,826:INFO:_display_container: 2
2025-07-10 09:20:08,826:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-10 09:20:08,826:INFO:create_model() successfully completed......................................
2025-07-10 09:20:08,972:INFO:SubProcess create_model() end ==================================
2025-07-10 09:20:08,972:INFO:Creating metrics dataframe
2025-07-10 09:20:09,010:INFO:Initializing Light Gradient Boosting Machine
2025-07-10 09:20:09,010:INFO:Total runtime is 1.1956594228744506 minutes
2025-07-10 09:20:09,010:INFO:SubProcess create_model() called ==================================
2025-07-10 09:20:09,020:INFO:Initializing create_model()
2025-07-10 09:20:09,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:20:09,020:INFO:Checking exceptions
2025-07-10 09:20:09,020:INFO:Importing libraries
2025-07-10 09:20:09,021:INFO:Copying training dataset
2025-07-10 09:20:09,075:INFO:Defining folds
2025-07-10 09:20:09,077:INFO:Declaring metric variables
2025-07-10 09:20:09,092:INFO:Importing untrained model
2025-07-10 09:20:09,102:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-10 09:20:09,123:INFO:Starting cross validation
2025-07-10 09:20:09,125:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:20:11,152:INFO:Calculating mean and std
2025-07-10 09:20:11,160:INFO:Creating metrics dataframe
2025-07-10 09:20:11,162:INFO:Uploading results into container
2025-07-10 09:20:11,162:INFO:Uploading model into container now
2025-07-10 09:20:11,162:INFO:_master_model_container: 13
2025-07-10 09:20:11,162:INFO:_display_container: 2
2025-07-10 09:20:11,168:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-10 09:20:11,168:INFO:create_model() successfully completed......................................
2025-07-10 09:20:11,314:INFO:SubProcess create_model() end ==================================
2025-07-10 09:20:11,314:INFO:Creating metrics dataframe
2025-07-10 09:20:11,344:INFO:Initializing Dummy Classifier
2025-07-10 09:20:11,344:INFO:Total runtime is 1.234563652674357 minutes
2025-07-10 09:20:11,349:INFO:SubProcess create_model() called ==================================
2025-07-10 09:20:11,350:INFO:Initializing create_model()
2025-07-10 09:20:11,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B78724A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:20:11,351:INFO:Checking exceptions
2025-07-10 09:20:11,351:INFO:Importing libraries
2025-07-10 09:20:11,351:INFO:Copying training dataset
2025-07-10 09:20:11,385:INFO:Defining folds
2025-07-10 09:20:11,385:INFO:Declaring metric variables
2025-07-10 09:20:11,396:INFO:Importing untrained model
2025-07-10 09:20:11,403:INFO:Dummy Classifier Imported successfully
2025-07-10 09:20:11,416:INFO:Starting cross validation
2025-07-10 09:20:11,416:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:20:11,551:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 09:20:11,551:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 09:20:11,566:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 09:20:11,582:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 09:20:11,646:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 09:20:11,666:INFO:Calculating mean and std
2025-07-10 09:20:11,666:INFO:Creating metrics dataframe
2025-07-10 09:20:11,666:INFO:Uploading results into container
2025-07-10 09:20:11,674:INFO:Uploading model into container now
2025-07-10 09:20:11,676:INFO:_master_model_container: 14
2025-07-10 09:20:11,676:INFO:_display_container: 2
2025-07-10 09:20:11,677:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-10 09:20:11,677:INFO:create_model() successfully completed......................................
2025-07-10 09:20:11,815:INFO:SubProcess create_model() end ==================================
2025-07-10 09:20:11,815:INFO:Creating metrics dataframe
2025-07-10 09:20:11,853:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-10 09:20:11,871:INFO:Initializing create_model()
2025-07-10 09:20:11,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:20:11,872:INFO:Checking exceptions
2025-07-10 09:20:11,875:INFO:Importing libraries
2025-07-10 09:20:11,875:INFO:Copying training dataset
2025-07-10 09:20:11,913:INFO:Defining folds
2025-07-10 09:20:11,913:INFO:Declaring metric variables
2025-07-10 09:20:11,914:INFO:Importing untrained model
2025-07-10 09:20:11,914:INFO:Declaring custom model
2025-07-10 09:20:11,915:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 09:20:11,916:INFO:Cross validation set to False
2025-07-10 09:20:11,916:INFO:Fitting Model
2025-07-10 09:20:20,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 09:20:20,955:INFO:create_model() successfully completed......................................
2025-07-10 09:20:21,117:INFO:_master_model_container: 14
2025-07-10 09:20:21,117:INFO:_display_container: 2
2025-07-10 09:20:21,117:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 09:20:21,117:INFO:compare_models() successfully completed......................................
2025-07-10 09:21:53,710:INFO:gpu_param set to False
2025-07-10 09:21:53,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:21:53,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:21:54,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:21:54,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 09:22:02,541:INFO:Initializing create_model()
2025-07-10 09:22:02,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:22:02,542:INFO:Checking exceptions
2025-07-10 09:22:02,578:INFO:Importing libraries
2025-07-10 09:22:02,578:INFO:Copying training dataset
2025-07-10 09:22:02,616:INFO:Defining folds
2025-07-10 09:22:02,616:INFO:Declaring metric variables
2025-07-10 09:22:02,633:INFO:Importing untrained model
2025-07-10 09:22:02,642:INFO:Decision Tree Classifier Imported successfully
2025-07-10 09:22:02,649:INFO:Starting cross validation
2025-07-10 09:22:02,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:22:05,017:INFO:Calculating mean and std
2025-07-10 09:22:05,025:INFO:Creating metrics dataframe
2025-07-10 09:22:05,035:INFO:Finalizing model
2025-07-10 09:22:05,585:INFO:Uploading results into container
2025-07-10 09:22:05,586:INFO:Uploading model into container now
2025-07-10 09:22:05,607:INFO:_master_model_container: 15
2025-07-10 09:22:05,607:INFO:_display_container: 3
2025-07-10 09:22:05,608:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 09:22:05,608:INFO:create_model() successfully completed......................................
2025-07-10 09:23:39,336:INFO:Initializing create_model()
2025-07-10 09:23:39,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:23:39,336:INFO:Checking exceptions
2025-07-10 09:23:39,369:INFO:Importing libraries
2025-07-10 09:23:39,369:INFO:Copying training dataset
2025-07-10 09:23:39,417:INFO:Defining folds
2025-07-10 09:23:39,417:INFO:Declaring metric variables
2025-07-10 09:23:39,421:INFO:Importing untrained model
2025-07-10 09:23:39,436:INFO:K Neighbors Classifier Imported successfully
2025-07-10 09:23:39,456:INFO:Starting cross validation
2025-07-10 09:23:39,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:23:41,945:INFO:Calculating mean and std
2025-07-10 09:23:41,945:INFO:Creating metrics dataframe
2025-07-10 09:23:41,958:INFO:Finalizing model
2025-07-10 09:23:42,000:INFO:Uploading results into container
2025-07-10 09:23:42,001:INFO:Uploading model into container now
2025-07-10 09:23:42,019:INFO:_master_model_container: 16
2025-07-10 09:23:42,019:INFO:_display_container: 4
2025-07-10 09:23:42,019:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-10 09:23:42,020:INFO:create_model() successfully completed......................................
2025-07-10 09:24:12,191:INFO:Initializing create_model()
2025-07-10 09:24:12,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:24:12,191:INFO:Checking exceptions
2025-07-10 09:24:12,235:INFO:Importing libraries
2025-07-10 09:24:12,236:INFO:Copying training dataset
2025-07-10 09:24:12,272:INFO:Defining folds
2025-07-10 09:24:12,272:INFO:Declaring metric variables
2025-07-10 09:24:12,292:INFO:Importing untrained model
2025-07-10 09:24:12,302:INFO:Random Forest Classifier Imported successfully
2025-07-10 09:24:12,322:INFO:Starting cross validation
2025-07-10 09:24:12,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:24:33,817:INFO:Calculating mean and std
2025-07-10 09:24:33,825:INFO:Creating metrics dataframe
2025-07-10 09:24:33,839:INFO:Finalizing model
2025-07-10 09:24:36,817:INFO:Uploading results into container
2025-07-10 09:24:36,820:INFO:Uploading model into container now
2025-07-10 09:24:36,850:INFO:_master_model_container: 17
2025-07-10 09:24:36,850:INFO:_display_container: 5
2025-07-10 09:24:36,852:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-10 09:24:36,852:INFO:create_model() successfully completed......................................
2025-07-10 09:25:23,631:INFO:Initializing tune_model()
2025-07-10 09:25:23,632:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-10 09:25:23,632:INFO:Checking exceptions
2025-07-10 09:25:23,684:INFO:Copying training dataset
2025-07-10 09:25:23,718:INFO:Checking base model
2025-07-10 09:25:23,718:INFO:Base model : Decision Tree Classifier
2025-07-10 09:25:23,725:INFO:Declaring metric variables
2025-07-10 09:25:23,734:INFO:Defining Hyperparameters
2025-07-10 09:25:23,854:INFO:Tuning with n_jobs=-1
2025-07-10 09:25:23,854:INFO:Initializing RandomizedSearchCV
2025-07-10 09:25:27,726:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2025-07-10 09:25:27,727:INFO:Hyperparameter search completed
2025-07-10 09:25:27,727:INFO:SubProcess create_model() called ==================================
2025-07-10 09:25:27,727:INFO:Initializing create_model()
2025-07-10 09:25:27,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B780CA7F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2025-07-10 09:25:27,728:INFO:Checking exceptions
2025-07-10 09:25:27,728:INFO:Importing libraries
2025-07-10 09:25:27,728:INFO:Copying training dataset
2025-07-10 09:25:27,754:INFO:Defining folds
2025-07-10 09:25:27,754:INFO:Declaring metric variables
2025-07-10 09:25:27,754:INFO:Importing untrained model
2025-07-10 09:25:27,754:INFO:Declaring custom model
2025-07-10 09:25:27,771:INFO:Decision Tree Classifier Imported successfully
2025-07-10 09:25:27,784:INFO:Starting cross validation
2025-07-10 09:25:27,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:25:28,232:INFO:Calculating mean and std
2025-07-10 09:25:28,232:INFO:Creating metrics dataframe
2025-07-10 09:25:28,244:INFO:Finalizing model
2025-07-10 09:25:28,302:INFO:Uploading results into container
2025-07-10 09:25:28,302:INFO:Uploading model into container now
2025-07-10 09:25:28,302:INFO:_master_model_container: 18
2025-07-10 09:25:28,302:INFO:_display_container: 6
2025-07-10 09:25:28,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 09:25:28,302:INFO:create_model() successfully completed......................................
2025-07-10 09:25:28,450:INFO:SubProcess create_model() end ==================================
2025-07-10 09:25:28,450:INFO:choose_better activated
2025-07-10 09:25:28,450:INFO:SubProcess create_model() called ==================================
2025-07-10 09:25:28,450:INFO:Initializing create_model()
2025-07-10 09:25:28,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:25:28,450:INFO:Checking exceptions
2025-07-10 09:25:28,466:INFO:Importing libraries
2025-07-10 09:25:28,466:INFO:Copying training dataset
2025-07-10 09:25:28,497:INFO:Defining folds
2025-07-10 09:25:28,497:INFO:Declaring metric variables
2025-07-10 09:25:28,498:INFO:Importing untrained model
2025-07-10 09:25:28,498:INFO:Declaring custom model
2025-07-10 09:25:28,499:INFO:Decision Tree Classifier Imported successfully
2025-07-10 09:25:28,499:INFO:Starting cross validation
2025-07-10 09:25:28,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:25:30,633:INFO:Calculating mean and std
2025-07-10 09:25:30,635:INFO:Creating metrics dataframe
2025-07-10 09:25:30,635:INFO:Finalizing model
2025-07-10 09:25:31,162:INFO:Uploading results into container
2025-07-10 09:25:31,178:INFO:Uploading model into container now
2025-07-10 09:25:31,178:INFO:_master_model_container: 19
2025-07-10 09:25:31,178:INFO:_display_container: 7
2025-07-10 09:25:31,178:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 09:25:31,178:INFO:create_model() successfully completed......................................
2025-07-10 09:25:31,278:INFO:SubProcess create_model() end ==================================
2025-07-10 09:25:31,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.7295
2025-07-10 09:25:31,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') result for Accuracy is 0.8225
2025-07-10 09:25:31,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best') is best model
2025-07-10 09:25:31,278:INFO:choose_better completed
2025-07-10 09:25:31,301:INFO:_master_model_container: 19
2025-07-10 09:25:31,301:INFO:_display_container: 6
2025-07-10 09:25:31,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 09:25:31,303:INFO:tune_model() successfully completed......................................
2025-07-10 09:26:00,991:INFO:Initializing tune_model()
2025-07-10 09:26:00,992:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid={'n_neighbors': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,
       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-10 09:26:00,992:INFO:Checking exceptions
2025-07-10 09:26:01,048:INFO:Copying training dataset
2025-07-10 09:26:01,087:INFO:Checking base model
2025-07-10 09:26:01,087:INFO:Base model : K Neighbors Classifier
2025-07-10 09:26:01,087:INFO:Declaring metric variables
2025-07-10 09:26:01,109:INFO:Defining Hyperparameters
2025-07-10 09:26:01,246:INFO:custom_grid: {'actual_estimator__n_neighbors': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,
       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])}
2025-07-10 09:26:01,246:INFO:Tuning with n_jobs=-1
2025-07-10 09:26:01,246:INFO:Initializing RandomizedSearchCV
2025-07-10 09:26:17,690:INFO:best_params: {'actual_estimator__n_neighbors': 42}
2025-07-10 09:26:17,690:INFO:Hyperparameter search completed
2025-07-10 09:26:17,690:INFO:SubProcess create_model() called ==================================
2025-07-10 09:26:17,690:INFO:Initializing create_model()
2025-07-10 09:26:17,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B787232990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_neighbors': 42})
2025-07-10 09:26:17,690:INFO:Checking exceptions
2025-07-10 09:26:17,690:INFO:Importing libraries
2025-07-10 09:26:17,690:INFO:Copying training dataset
2025-07-10 09:26:17,730:INFO:Defining folds
2025-07-10 09:26:17,730:INFO:Declaring metric variables
2025-07-10 09:26:17,734:INFO:Importing untrained model
2025-07-10 09:26:17,734:INFO:Declaring custom model
2025-07-10 09:26:17,740:INFO:K Neighbors Classifier Imported successfully
2025-07-10 09:26:17,751:INFO:Starting cross validation
2025-07-10 09:26:17,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:26:20,448:INFO:Calculating mean and std
2025-07-10 09:26:20,448:INFO:Creating metrics dataframe
2025-07-10 09:26:20,468:INFO:Finalizing model
2025-07-10 09:26:20,516:INFO:Uploading results into container
2025-07-10 09:26:20,518:INFO:Uploading model into container now
2025-07-10 09:26:20,519:INFO:_master_model_container: 20
2025-07-10 09:26:20,519:INFO:_display_container: 7
2025-07-10 09:26:20,520:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=42, p=2,
                     weights='uniform')
2025-07-10 09:26:20,520:INFO:create_model() successfully completed......................................
2025-07-10 09:26:20,645:INFO:SubProcess create_model() end ==================================
2025-07-10 09:26:20,645:INFO:choose_better activated
2025-07-10 09:26:20,645:INFO:SubProcess create_model() called ==================================
2025-07-10 09:26:20,645:INFO:Initializing create_model()
2025-07-10 09:26:20,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:26:20,645:INFO:Checking exceptions
2025-07-10 09:26:20,654:INFO:Importing libraries
2025-07-10 09:26:20,654:INFO:Copying training dataset
2025-07-10 09:26:20,681:INFO:Defining folds
2025-07-10 09:26:20,682:INFO:Declaring metric variables
2025-07-10 09:26:20,682:INFO:Importing untrained model
2025-07-10 09:26:20,682:INFO:Declaring custom model
2025-07-10 09:26:20,683:INFO:K Neighbors Classifier Imported successfully
2025-07-10 09:26:20,684:INFO:Starting cross validation
2025-07-10 09:26:20,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:26:23,238:INFO:Calculating mean and std
2025-07-10 09:26:23,238:INFO:Creating metrics dataframe
2025-07-10 09:26:23,238:INFO:Finalizing model
2025-07-10 09:26:23,284:INFO:Uploading results into container
2025-07-10 09:26:23,285:INFO:Uploading model into container now
2025-07-10 09:26:23,286:INFO:_master_model_container: 21
2025-07-10 09:26:23,286:INFO:_display_container: 8
2025-07-10 09:26:23,286:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-10 09:26:23,286:INFO:create_model() successfully completed......................................
2025-07-10 09:26:23,388:INFO:SubProcess create_model() end ==================================
2025-07-10 09:26:23,388:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.7504
2025-07-10 09:26:23,388:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=42, p=2,
                     weights='uniform') result for Accuracy is 0.7802
2025-07-10 09:26:23,388:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=42, p=2,
                     weights='uniform') is best model
2025-07-10 09:26:23,388:INFO:choose_better completed
2025-07-10 09:26:23,419:INFO:_master_model_container: 21
2025-07-10 09:26:23,419:INFO:_display_container: 7
2025-07-10 09:26:23,420:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=42, p=2,
                     weights='uniform')
2025-07-10 09:26:23,420:INFO:tune_model() successfully completed......................................
2025-07-10 09:27:23,758:INFO:Initializing tune_model()
2025-07-10 09:27:23,758:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-10 09:27:23,759:INFO:Checking exceptions
2025-07-10 09:27:23,805:INFO:Copying training dataset
2025-07-10 09:27:23,840:INFO:Checking base model
2025-07-10 09:27:23,840:INFO:Base model : Random Forest Classifier
2025-07-10 09:27:23,850:INFO:Declaring metric variables
2025-07-10 09:27:23,858:INFO:Defining Hyperparameters
2025-07-10 09:27:23,986:INFO:Tuning with n_jobs=-1
2025-07-10 09:27:23,986:INFO:Initializing RandomizedSearchCV
2025-07-10 09:32:15,821:INFO:best_params: {'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': True}
2025-07-10 09:32:15,823:INFO:Hyperparameter search completed
2025-07-10 09:32:15,823:INFO:SubProcess create_model() called ==================================
2025-07-10 09:32:15,825:INFO:Initializing create_model()
2025-07-10 09:32:15,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B786652990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 130, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': True})
2025-07-10 09:32:15,825:INFO:Checking exceptions
2025-07-10 09:32:15,825:INFO:Importing libraries
2025-07-10 09:32:15,825:INFO:Copying training dataset
2025-07-10 09:32:15,875:INFO:Defining folds
2025-07-10 09:32:15,875:INFO:Declaring metric variables
2025-07-10 09:32:15,886:INFO:Importing untrained model
2025-07-10 09:32:15,886:INFO:Declaring custom model
2025-07-10 09:32:15,896:INFO:Random Forest Classifier Imported successfully
2025-07-10 09:32:15,918:INFO:Starting cross validation
2025-07-10 09:32:15,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:32:29,041:INFO:Calculating mean and std
2025-07-10 09:32:29,043:INFO:Creating metrics dataframe
2025-07-10 09:32:29,053:INFO:Finalizing model
2025-07-10 09:32:31,106:INFO:Uploading results into container
2025-07-10 09:32:31,107:INFO:Uploading model into container now
2025-07-10 09:32:31,109:INFO:_master_model_container: 22
2025-07-10 09:32:31,109:INFO:_display_container: 8
2025-07-10 09:32:31,109:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-07-10 09:32:31,112:INFO:create_model() successfully completed......................................
2025-07-10 09:32:31,298:INFO:SubProcess create_model() end ==================================
2025-07-10 09:32:31,298:INFO:choose_better activated
2025-07-10 09:32:31,308:INFO:SubProcess create_model() called ==================================
2025-07-10 09:32:31,308:INFO:Initializing create_model()
2025-07-10 09:32:31,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 09:32:31,308:INFO:Checking exceptions
2025-07-10 09:32:31,315:INFO:Importing libraries
2025-07-10 09:32:31,315:INFO:Copying training dataset
2025-07-10 09:32:31,359:INFO:Defining folds
2025-07-10 09:32:31,359:INFO:Declaring metric variables
2025-07-10 09:32:31,359:INFO:Importing untrained model
2025-07-10 09:32:31,359:INFO:Declaring custom model
2025-07-10 09:32:31,367:INFO:Random Forest Classifier Imported successfully
2025-07-10 09:32:31,369:INFO:Starting cross validation
2025-07-10 09:32:31,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 09:32:52,878:INFO:Calculating mean and std
2025-07-10 09:32:52,878:INFO:Creating metrics dataframe
2025-07-10 09:32:52,888:INFO:Finalizing model
2025-07-10 09:32:55,597:INFO:Uploading results into container
2025-07-10 09:32:55,597:INFO:Uploading model into container now
2025-07-10 09:32:55,597:INFO:_master_model_container: 23
2025-07-10 09:32:55,597:INFO:_display_container: 9
2025-07-10 09:32:55,597:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-10 09:32:55,597:INFO:create_model() successfully completed......................................
2025-07-10 09:32:55,776:INFO:SubProcess create_model() end ==================================
2025-07-10 09:32:55,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for F1 is 0.4864
2025-07-10 09:32:55,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for F1 is 0.5513
2025-07-10 09:32:55,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2025-07-10 09:32:55,778:INFO:choose_better completed
2025-07-10 09:32:55,808:INFO:_master_model_container: 23
2025-07-10 09:32:55,808:INFO:_display_container: 8
2025-07-10 09:32:55,809:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-07-10 09:32:55,810:INFO:tune_model() successfully completed......................................
2025-07-10 09:32:56,001:INFO:Initializing plot_model()
2025-07-10 09:32:56,002:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 09:32:56,002:INFO:Checking exceptions
2025-07-10 09:32:56,080:INFO:Preloading libraries
2025-07-10 09:32:56,116:INFO:Copying training dataset
2025-07-10 09:32:56,116:INFO:Plot type: auc
2025-07-10 09:32:56,506:INFO:Fitting Model
2025-07-10 09:32:56,522:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 09:32:56,522:INFO:Scoring test/hold-out set
2025-07-10 09:32:57,192:INFO:Visual Rendered Successfully
2025-07-10 09:32:57,323:INFO:plot_model() successfully completed......................................
2025-07-10 09:32:57,355:INFO:Initializing plot_model()
2025-07-10 09:32:57,355:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 09:32:57,355:INFO:Checking exceptions
2025-07-10 09:32:57,423:INFO:Preloading libraries
2025-07-10 09:32:57,440:INFO:Copying training dataset
2025-07-10 09:32:57,440:INFO:Plot type: pr
2025-07-10 09:32:57,709:INFO:Fitting Model
2025-07-10 09:32:57,709:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 09:32:57,709:INFO:Scoring test/hold-out set
2025-07-10 09:32:58,079:INFO:Visual Rendered Successfully
2025-07-10 09:32:58,194:INFO:plot_model() successfully completed......................................
2025-07-10 09:32:58,217:INFO:Initializing plot_model()
2025-07-10 09:32:58,217:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 09:32:58,217:INFO:Checking exceptions
2025-07-10 09:32:58,278:INFO:Preloading libraries
2025-07-10 09:32:58,308:INFO:Copying training dataset
2025-07-10 09:32:58,308:INFO:Plot type: feature
2025-07-10 09:32:58,309:WARNING:No coef_ found. Trying feature_importances_
2025-07-10 09:32:58,762:INFO:Visual Rendered Successfully
2025-07-10 09:32:58,873:INFO:plot_model() successfully completed......................................
2025-07-10 09:32:58,896:INFO:Initializing plot_model()
2025-07-10 09:32:58,896:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 09:32:58,896:INFO:Checking exceptions
2025-07-10 09:32:58,954:INFO:Preloading libraries
2025-07-10 09:32:58,983:INFO:Copying training dataset
2025-07-10 09:32:58,984:INFO:Plot type: confusion_matrix
2025-07-10 09:32:59,271:INFO:Fitting Model
2025-07-10 09:32:59,271:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 09:32:59,271:INFO:Scoring test/hold-out set
2025-07-10 09:32:59,526:INFO:Visual Rendered Successfully
2025-07-10 09:32:59,643:INFO:plot_model() successfully completed......................................
2025-07-10 09:32:59,656:INFO:Initializing evaluate_model()
2025-07-10 09:32:59,656:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-07-10 09:32:59,701:INFO:Initializing plot_model()
2025-07-10 09:32:59,702:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 09:32:59,702:INFO:Checking exceptions
2025-07-10 09:32:59,739:INFO:Preloading libraries
2025-07-10 09:32:59,759:INFO:Copying training dataset
2025-07-10 09:32:59,759:INFO:Plot type: pipeline
2025-07-10 09:32:59,945:INFO:Visual Rendered Successfully
2025-07-10 09:33:00,059:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:24,595:INFO:Initializing plot_model()
2025-07-10 10:02:24,595:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:24,596:INFO:Checking exceptions
2025-07-10 10:02:24,648:INFO:Preloading libraries
2025-07-10 10:02:24,667:INFO:Copying training dataset
2025-07-10 10:02:24,667:INFO:Plot type: parameter
2025-07-10 10:02:24,669:INFO:Visual Rendered Successfully
2025-07-10 10:02:24,789:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:26,436:INFO:Initializing plot_model()
2025-07-10 10:02:26,437:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:26,437:INFO:Checking exceptions
2025-07-10 10:02:26,478:INFO:Preloading libraries
2025-07-10 10:02:26,494:INFO:Copying training dataset
2025-07-10 10:02:26,494:INFO:Plot type: auc
2025-07-10 10:02:26,709:INFO:Fitting Model
2025-07-10 10:02:26,709:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:02:26,709:INFO:Scoring test/hold-out set
2025-07-10 10:02:27,141:INFO:Visual Rendered Successfully
2025-07-10 10:02:27,257:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:28,399:INFO:Initializing plot_model()
2025-07-10 10:02:28,399:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:28,399:INFO:Checking exceptions
2025-07-10 10:02:28,440:INFO:Preloading libraries
2025-07-10 10:02:28,455:INFO:Copying training dataset
2025-07-10 10:02:28,456:INFO:Plot type: confusion_matrix
2025-07-10 10:02:28,663:INFO:Fitting Model
2025-07-10 10:02:28,663:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:02:28,663:INFO:Scoring test/hold-out set
2025-07-10 10:02:28,935:INFO:Visual Rendered Successfully
2025-07-10 10:02:29,061:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:31,181:INFO:Initializing plot_model()
2025-07-10 10:02:31,182:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=pr, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:31,182:INFO:Checking exceptions
2025-07-10 10:02:31,223:INFO:Preloading libraries
2025-07-10 10:02:31,242:INFO:Copying training dataset
2025-07-10 10:02:31,242:INFO:Plot type: pr
2025-07-10 10:02:31,459:INFO:Fitting Model
2025-07-10 10:02:31,459:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:02:31,459:INFO:Scoring test/hold-out set
2025-07-10 10:02:31,845:INFO:Visual Rendered Successfully
2025-07-10 10:02:31,968:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:32,904:INFO:Initializing plot_model()
2025-07-10 10:02:32,905:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:32,905:INFO:Checking exceptions
2025-07-10 10:02:33,022:INFO:Preloading libraries
2025-07-10 10:02:33,033:INFO:Copying training dataset
2025-07-10 10:02:33,033:INFO:Plot type: feature_all
2025-07-10 10:02:33,111:WARNING:No coef_ found. Trying feature_importances_
2025-07-10 10:02:33,746:INFO:Visual Rendered Successfully
2025-07-10 10:02:33,871:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:35,468:INFO:Initializing plot_model()
2025-07-10 10:02:35,469:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:35,469:INFO:Checking exceptions
2025-07-10 10:02:35,510:INFO:Preloading libraries
2025-07-10 10:02:35,526:INFO:Copying training dataset
2025-07-10 10:02:35,526:INFO:Plot type: boundary
2025-07-10 10:02:35,634:INFO:Fitting StandardScaler()
2025-07-10 10:02:35,649:INFO:Fitting PCA()
2025-07-10 10:02:35,886:INFO:Fitting Model
2025-07-10 10:02:39,530:INFO:Visual Rendered Successfully
2025-07-10 10:02:39,715:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:39,774:INFO:Initializing plot_model()
2025-07-10 10:02:39,774:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:39,774:INFO:Checking exceptions
2025-07-10 10:02:39,851:INFO:Preloading libraries
2025-07-10 10:02:39,871:INFO:Copying training dataset
2025-07-10 10:02:39,872:INFO:Plot type: lift
2025-07-10 10:02:39,872:INFO:Generating predictions / predict_proba on X_test
2025-07-10 10:02:40,425:INFO:Visual Rendered Successfully
2025-07-10 10:02:40,580:INFO:plot_model() successfully completed......................................
2025-07-10 10:02:55,745:INFO:Initializing evaluate_model()
2025-07-10 10:02:55,745:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-07-10 10:02:55,784:INFO:Initializing plot_model()
2025-07-10 10:02:55,785:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:02:55,785:INFO:Checking exceptions
2025-07-10 10:02:55,861:INFO:Preloading libraries
2025-07-10 10:02:55,880:INFO:Copying training dataset
2025-07-10 10:02:55,880:INFO:Plot type: pipeline
2025-07-10 10:02:56,012:INFO:Visual Rendered Successfully
2025-07-10 10:02:56,143:INFO:plot_model() successfully completed......................................
2025-07-10 10:03:02,020:INFO:Initializing predict_model()
2025-07-10 10:03:02,020:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B786752C00>)
2025-07-10 10:03:02,021:INFO:Checking exceptions
2025-07-10 10:03:02,021:INFO:Preloading libraries
2025-07-10 10:03:51,956:INFO:Initializing finalize_model()
2025-07-10 10:03:51,956:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-10 10:03:51,958:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-07-10 10:03:51,989:INFO:Initializing create_model()
2025-07-10 10:03:51,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=130, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:03:51,990:INFO:Checking exceptions
2025-07-10 10:03:51,994:INFO:Importing libraries
2025-07-10 10:03:51,994:INFO:Copying training dataset
2025-07-10 10:03:51,995:INFO:Defining folds
2025-07-10 10:03:51,995:INFO:Declaring metric variables
2025-07-10 10:03:51,995:INFO:Importing untrained model
2025-07-10 10:03:51,995:INFO:Declaring custom model
2025-07-10 10:03:51,995:INFO:Random Forest Classifier Imported successfully
2025-07-10 10:03:51,995:INFO:Cross validation set to False
2025-07-10 10:03:51,995:INFO:Fitting Model
2025-07-10 10:03:54,209:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-07-10 10:03:54,209:INFO:create_model() successfully completed......................................
2025-07-10 10:03:54,321:INFO:_master_model_container: 23
2025-07-10 10:03:54,321:INFO:_display_container: 9
2025-07-10 10:03:54,328:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-07-10 10:03:54,328:INFO:finalize_model() successfully completed......................................
2025-07-10 10:04:14,420:INFO:Initializing predict_model()
2025-07-10 10:04:14,420:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B7FA2FEA20>)
2025-07-10 10:04:14,421:INFO:Checking exceptions
2025-07-10 10:04:14,421:INFO:Preloading libraries
2025-07-10 10:04:46,915:INFO:Initializing predict_model()
2025-07-10 10:04:46,915:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B786922FC0>)
2025-07-10 10:04:46,915:INFO:Checking exceptions
2025-07-10 10:04:46,915:INFO:Preloading libraries
2025-07-10 10:04:46,919:INFO:Set up data.
2025-07-10 10:04:46,931:INFO:Set up index.
2025-07-10 10:05:03,177:INFO:Initializing save_model()
2025-07-10 10:05:03,177:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), model_name=Final RF Model 01Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-10 10:05:03,178:INFO:Adding model into prep_pipe
2025-07-10 10:05:03,178:WARNING:Only Model saved as it was a pipeline.
2025-07-10 10:05:03,337:INFO:Final RF Model 01Jun2022.pkl saved in current working directory
2025-07-10 10:05:03,352:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-07-10 10:05:03,352:INFO:save_model() successfully completed......................................
2025-07-10 10:05:12,755:INFO:Initializing load_model()
2025-07-10 10:05:12,755:INFO:load_model(model_name=Final RF Model 01Jun2022, platform=None, authentication=None, verbose=True)
2025-07-10 10:05:23,487:INFO:Initializing predict_model()
2025-07-10 10:05:23,487:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B786751C60>)
2025-07-10 10:05:23,488:INFO:Checking exceptions
2025-07-10 10:05:23,488:INFO:Preloading libraries
2025-07-10 10:05:23,491:INFO:Set up data.
2025-07-10 10:05:23,510:INFO:Set up index.
2025-07-10 10:13:49,346:INFO:Initializing save_model()
2025-07-10 10:13:49,346:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), model_name=Final RF Model 01Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-10 10:13:49,347:INFO:Adding model into prep_pipe
2025-07-10 10:13:49,347:WARNING:Only Model saved as it was a pipeline.
2025-07-10 10:13:49,449:INFO:Final RF Model 01Jun2022.pkl saved in current working directory
2025-07-10 10:13:49,456:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',
                                             'PAY_AMT4', 'PAY_AMT5',
                                             'PAY_AMT6'],
                                    transform...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-07-10 10:13:49,457:INFO:save_model() successfully completed......................................
2025-07-10 10:13:54,322:INFO:Initializing load_model()
2025-07-10 10:13:54,322:INFO:load_model(model_name=Final RF Model 01Jun2022, platform=None, authentication=None, verbose=True)
2025-07-10 10:13:57,607:INFO:Initializing predict_model()
2025-07-10 10:13:57,607:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B783584650>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['LIMIT_BAL', 'SEX', 'EDUCATION',
                                             'MARRIAGE', 'AGE', 'PAY_1',
                                             'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',
                                             'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
                                             'BILL_AMT3', 'BILL_AMT4',
                                             'BILL_AMT5', 'BILL_AMT6',
                                             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced_subsample',
                                        criterion='entropy', max_depth=4,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0002,
                                        min_samples_leaf=5, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=130,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B786B323E0>)
2025-07-10 10:13:57,608:INFO:Checking exceptions
2025-07-10 10:13:57,608:INFO:Preloading libraries
2025-07-10 10:13:57,611:INFO:Set up data.
2025-07-10 10:13:57,626:INFO:Set up index.
2025-07-10 10:18:55,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 10:18:55,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 10:18:55,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 10:18:55,698:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-10 10:18:59,872:INFO:PyCaret ClassificationExperiment
2025-07-10 10:18:59,873:INFO:Logging name: clf-default-name
2025-07-10 10:18:59,873:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-10 10:18:59,873:INFO:version 3.3.2
2025-07-10 10:18:59,874:INFO:Initializing setup()
2025-07-10 10:18:59,874:INFO:self.USI: 90c1
2025-07-10 10:18:59,874:INFO:self._variable_keys: {'pipeline', 'n_jobs_param', 'seed', 'fix_imbalance', 'log_plots_param', 'gpu_param', 'fold_groups_param', 'target_param', 'USI', 'idx', 'is_multiclass', 'data', 'y', 'X_test', 'memory', 'X', '_ml_usecase', '_available_plots', 'y_test', 'logging_param', 'exp_id', 'exp_name_log', 'y_train', 'fold_generator', 'X_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'html_param'}
2025-07-10 10:18:59,875:INFO:Checking environment
2025-07-10 10:18:59,875:INFO:python_version: 3.11.7
2025-07-10 10:18:59,875:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-10 10:18:59,875:INFO:machine: AMD64
2025-07-10 10:18:59,876:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-10 10:18:59,876:INFO:Memory: svmem(total=12698038272, available=5064515584, percent=60.1, used=7633522688, free=5064515584)
2025-07-10 10:18:59,876:INFO:Physical Core: 2
2025-07-10 10:18:59,877:INFO:Logical Core: 4
2025-07-10 10:18:59,877:INFO:Checking libraries
2025-07-10 10:18:59,877:INFO:System:
2025-07-10 10:18:59,877:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-10 10:18:59,878:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-10 10:18:59,878:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-10 10:18:59,878:INFO:PyCaret required dependencies:
2025-07-10 10:19:01,504:INFO:                 pip: 23.3.1
2025-07-10 10:19:01,504:INFO:          setuptools: 68.2.2
2025-07-10 10:19:01,504:INFO:             pycaret: 3.3.2
2025-07-10 10:19:01,504:INFO:             IPython: 8.20.0
2025-07-10 10:19:01,504:INFO:          ipywidgets: 7.7.2
2025-07-10 10:19:01,504:INFO:                tqdm: 4.65.0
2025-07-10 10:19:01,504:INFO:               numpy: 1.26.4
2025-07-10 10:19:01,505:INFO:              pandas: 2.1.4
2025-07-10 10:19:01,505:INFO:              jinja2: 3.1.3
2025-07-10 10:19:01,505:INFO:               scipy: 1.11.4
2025-07-10 10:19:01,505:INFO:              joblib: 1.2.0
2025-07-10 10:19:01,505:INFO:             sklearn: 1.4.2
2025-07-10 10:19:01,505:INFO:                pyod: 2.0.5
2025-07-10 10:19:01,505:INFO:            imblearn: 0.13.0
2025-07-10 10:19:01,505:INFO:   category_encoders: 2.7.0
2025-07-10 10:19:01,505:INFO:            lightgbm: 4.6.0
2025-07-10 10:19:01,505:INFO:               numba: 0.59.0
2025-07-10 10:19:01,505:INFO:            requests: 2.31.0
2025-07-10 10:19:01,505:INFO:          matplotlib: 3.7.5
2025-07-10 10:19:01,505:INFO:          scikitplot: 0.3.7
2025-07-10 10:19:01,505:INFO:         yellowbrick: 1.5
2025-07-10 10:19:01,506:INFO:              plotly: 5.24.1
2025-07-10 10:19:01,506:INFO:    plotly-resampler: Not installed
2025-07-10 10:19:01,506:INFO:             kaleido: 1.0.0
2025-07-10 10:19:01,506:INFO:           schemdraw: 0.15
2025-07-10 10:19:01,506:INFO:         statsmodels: 0.14.0
2025-07-10 10:19:01,506:INFO:              sktime: 0.26.0
2025-07-10 10:19:01,506:INFO:               tbats: 1.1.3
2025-07-10 10:19:01,506:INFO:            pmdarima: 2.0.4
2025-07-10 10:19:01,506:INFO:              psutil: 5.9.0
2025-07-10 10:19:01,506:INFO:          markupsafe: 2.1.3
2025-07-10 10:19:01,506:INFO:             pickle5: Not installed
2025-07-10 10:19:01,506:INFO:         cloudpickle: 2.2.1
2025-07-10 10:19:01,506:INFO:         deprecation: 2.1.0
2025-07-10 10:19:01,506:INFO:              xxhash: 3.5.0
2025-07-10 10:19:01,507:INFO:           wurlitzer: Not installed
2025-07-10 10:19:01,507:INFO:PyCaret optional dependencies:
2025-07-10 10:19:01,528:INFO:                shap: Not installed
2025-07-10 10:19:01,528:INFO:           interpret: Not installed
2025-07-10 10:19:01,528:INFO:                umap: Not installed
2025-07-10 10:19:01,528:INFO:     ydata_profiling: 4.7.0
2025-07-10 10:19:01,528:INFO:  explainerdashboard: Not installed
2025-07-10 10:19:01,528:INFO:             autoviz: Not installed
2025-07-10 10:19:01,528:INFO:           fairlearn: Not installed
2025-07-10 10:19:01,528:INFO:          deepchecks: Not installed
2025-07-10 10:19:01,528:INFO:             xgboost: Not installed
2025-07-10 10:19:01,528:INFO:            catboost: Not installed
2025-07-10 10:19:01,528:INFO:              kmodes: Not installed
2025-07-10 10:19:01,529:INFO:             mlxtend: Not installed
2025-07-10 10:19:01,529:INFO:       statsforecast: Not installed
2025-07-10 10:19:01,529:INFO:        tune_sklearn: Not installed
2025-07-10 10:19:01,529:INFO:                 ray: Not installed
2025-07-10 10:19:01,529:INFO:            hyperopt: Not installed
2025-07-10 10:19:01,529:INFO:              optuna: Not installed
2025-07-10 10:19:01,529:INFO:               skopt: Not installed
2025-07-10 10:19:01,529:INFO:              mlflow: Not installed
2025-07-10 10:19:01,529:INFO:              gradio: Not installed
2025-07-10 10:19:01,529:INFO:             fastapi: Not installed
2025-07-10 10:19:01,529:INFO:             uvicorn: Not installed
2025-07-10 10:19:01,529:INFO:              m2cgen: Not installed
2025-07-10 10:19:01,529:INFO:           evidently: Not installed
2025-07-10 10:19:01,529:INFO:               fugue: Not installed
2025-07-10 10:19:01,530:INFO:           streamlit: 1.46.1
2025-07-10 10:19:01,530:INFO:             prophet: Not installed
2025-07-10 10:19:01,530:INFO:None
2025-07-10 10:19:01,530:INFO:Set up data.
2025-07-10 10:19:01,569:INFO:Set up folding strategy.
2025-07-10 10:19:01,569:INFO:Set up train/test split.
2025-07-10 10:19:01,612:INFO:Set up index.
2025-07-10 10:19:01,612:INFO:Assigning column types.
2025-07-10 10:19:01,627:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-10 10:19:01,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 10:19:01,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:01,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:01,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:01,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 10:19:01,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:02,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,013:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-10 10:19:02,128:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:02,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,307:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:02,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,380:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-10 10:19:02,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:02,737:INFO:Preparing preprocessing pipeline...
2025-07-10 10:19:02,741:INFO:Set up simple imputation.
2025-07-10 10:19:02,758:INFO:Set up encoding of ordinal features.
2025-07-10 10:19:02,770:INFO:Set up encoding of categorical features.
2025-07-10 10:19:03,344:INFO:Finished creating preprocessing pipeline.
2025-07-10 10:19:03,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-10 10:19:03,390:INFO:Creating final display dataframe.
2025-07-10 10:19:04,295:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (47500, 13)
4        Transformed data shape       (47500, 30)
5   Transformed train set shape       (33250, 30)
6    Transformed test set shape       (14250, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              90c1
2025-07-10 10:19:04,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:04,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:04,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:04,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:04,696:INFO:setup() successfully completed in 4.83s...............
2025-07-10 10:19:53,007:INFO:PyCaret ClassificationExperiment
2025-07-10 10:19:53,007:INFO:Logging name: clf-default-name
2025-07-10 10:19:53,008:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-10 10:19:53,008:INFO:version 3.3.2
2025-07-10 10:19:53,008:INFO:Initializing setup()
2025-07-10 10:19:53,008:INFO:self.USI: bb48
2025-07-10 10:19:53,009:INFO:self._variable_keys: {'pipeline', 'n_jobs_param', 'seed', 'fix_imbalance', 'log_plots_param', 'gpu_param', 'fold_groups_param', 'target_param', 'USI', 'idx', 'is_multiclass', 'data', 'y', 'X_test', 'memory', 'X', '_ml_usecase', '_available_plots', 'y_test', 'logging_param', 'exp_id', 'exp_name_log', 'y_train', 'fold_generator', 'X_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'html_param'}
2025-07-10 10:19:53,009:INFO:Checking environment
2025-07-10 10:19:53,009:INFO:python_version: 3.11.7
2025-07-10 10:19:53,009:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-10 10:19:53,009:INFO:machine: AMD64
2025-07-10 10:19:53,009:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-10 10:19:53,010:INFO:Memory: svmem(total=12698038272, available=5023031296, percent=60.4, used=7675006976, free=5023031296)
2025-07-10 10:19:53,010:INFO:Physical Core: 2
2025-07-10 10:19:53,010:INFO:Logical Core: 4
2025-07-10 10:19:53,010:INFO:Checking libraries
2025-07-10 10:19:53,010:INFO:System:
2025-07-10 10:19:53,010:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-10 10:19:53,011:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-10 10:19:53,011:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-10 10:19:53,011:INFO:PyCaret required dependencies:
2025-07-10 10:19:53,011:INFO:                 pip: 23.3.1
2025-07-10 10:19:53,011:INFO:          setuptools: 68.2.2
2025-07-10 10:19:53,011:INFO:             pycaret: 3.3.2
2025-07-10 10:19:53,012:INFO:             IPython: 8.20.0
2025-07-10 10:19:53,012:INFO:          ipywidgets: 7.7.2
2025-07-10 10:19:53,012:INFO:                tqdm: 4.65.0
2025-07-10 10:19:53,012:INFO:               numpy: 1.26.4
2025-07-10 10:19:53,012:INFO:              pandas: 2.1.4
2025-07-10 10:19:53,012:INFO:              jinja2: 3.1.3
2025-07-10 10:19:53,013:INFO:               scipy: 1.11.4
2025-07-10 10:19:53,013:INFO:              joblib: 1.2.0
2025-07-10 10:19:53,013:INFO:             sklearn: 1.4.2
2025-07-10 10:19:53,013:INFO:                pyod: 2.0.5
2025-07-10 10:19:53,013:INFO:            imblearn: 0.13.0
2025-07-10 10:19:53,013:INFO:   category_encoders: 2.7.0
2025-07-10 10:19:53,013:INFO:            lightgbm: 4.6.0
2025-07-10 10:19:53,014:INFO:               numba: 0.59.0
2025-07-10 10:19:53,014:INFO:            requests: 2.31.0
2025-07-10 10:19:53,014:INFO:          matplotlib: 3.7.5
2025-07-10 10:19:53,014:INFO:          scikitplot: 0.3.7
2025-07-10 10:19:53,014:INFO:         yellowbrick: 1.5
2025-07-10 10:19:53,014:INFO:              plotly: 5.24.1
2025-07-10 10:19:53,015:INFO:    plotly-resampler: Not installed
2025-07-10 10:19:53,015:INFO:             kaleido: 1.0.0
2025-07-10 10:19:53,015:INFO:           schemdraw: 0.15
2025-07-10 10:19:53,016:INFO:         statsmodels: 0.14.0
2025-07-10 10:19:53,016:INFO:              sktime: 0.26.0
2025-07-10 10:19:53,016:INFO:               tbats: 1.1.3
2025-07-10 10:19:53,016:INFO:            pmdarima: 2.0.4
2025-07-10 10:19:53,016:INFO:              psutil: 5.9.0
2025-07-10 10:19:53,016:INFO:          markupsafe: 2.1.3
2025-07-10 10:19:53,016:INFO:             pickle5: Not installed
2025-07-10 10:19:53,017:INFO:         cloudpickle: 2.2.1
2025-07-10 10:19:53,017:INFO:         deprecation: 2.1.0
2025-07-10 10:19:53,017:INFO:              xxhash: 3.5.0
2025-07-10 10:19:53,017:INFO:           wurlitzer: Not installed
2025-07-10 10:19:53,017:INFO:PyCaret optional dependencies:
2025-07-10 10:19:53,017:INFO:                shap: Not installed
2025-07-10 10:19:53,017:INFO:           interpret: Not installed
2025-07-10 10:19:53,018:INFO:                umap: Not installed
2025-07-10 10:19:53,018:INFO:     ydata_profiling: 4.7.0
2025-07-10 10:19:53,018:INFO:  explainerdashboard: Not installed
2025-07-10 10:19:53,018:INFO:             autoviz: Not installed
2025-07-10 10:19:53,018:INFO:           fairlearn: Not installed
2025-07-10 10:19:53,018:INFO:          deepchecks: Not installed
2025-07-10 10:19:53,018:INFO:             xgboost: Not installed
2025-07-10 10:19:53,019:INFO:            catboost: Not installed
2025-07-10 10:19:53,019:INFO:              kmodes: Not installed
2025-07-10 10:19:53,019:INFO:             mlxtend: Not installed
2025-07-10 10:19:53,019:INFO:       statsforecast: Not installed
2025-07-10 10:19:53,019:INFO:        tune_sklearn: Not installed
2025-07-10 10:19:53,019:INFO:                 ray: Not installed
2025-07-10 10:19:53,019:INFO:            hyperopt: Not installed
2025-07-10 10:19:53,020:INFO:              optuna: Not installed
2025-07-10 10:19:53,020:INFO:               skopt: Not installed
2025-07-10 10:19:53,020:INFO:              mlflow: Not installed
2025-07-10 10:19:53,020:INFO:              gradio: Not installed
2025-07-10 10:19:53,020:INFO:             fastapi: Not installed
2025-07-10 10:19:53,020:INFO:             uvicorn: Not installed
2025-07-10 10:19:53,020:INFO:              m2cgen: Not installed
2025-07-10 10:19:53,021:INFO:           evidently: Not installed
2025-07-10 10:19:53,021:INFO:               fugue: Not installed
2025-07-10 10:19:53,021:INFO:           streamlit: 1.46.1
2025-07-10 10:19:53,021:INFO:             prophet: Not installed
2025-07-10 10:19:53,021:INFO:None
2025-07-10 10:19:53,021:INFO:Set up data.
2025-07-10 10:19:53,090:INFO:Set up folding strategy.
2025-07-10 10:19:53,090:INFO:Set up train/test split.
2025-07-10 10:19:53,117:INFO:Set up index.
2025-07-10 10:19:53,117:INFO:Assigning column types.
2025-07-10 10:19:53,124:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-10 10:19:53,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,486:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-10 10:19:53,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-10 10:19:53,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:53,852:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-10 10:19:54,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:54,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:54,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:54,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:54,221:INFO:Preparing preprocessing pipeline...
2025-07-10 10:19:54,231:INFO:Set up simple imputation.
2025-07-10 10:19:54,241:INFO:Set up encoding of ordinal features.
2025-07-10 10:19:54,251:INFO:Set up encoding of categorical features.
2025-07-10 10:19:54,572:INFO:Finished creating preprocessing pipeline.
2025-07-10 10:19:54,613:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-10 10:19:54,613:INFO:Creating final display dataframe.
2025-07-10 10:19:55,563:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (47500, 13)
4        Transformed data shape       (47500, 30)
5   Transformed train set shape       (33250, 30)
6    Transformed test set shape       (14250, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.8%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              bb48
2025-07-10 10:19:55,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:55,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:55,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:55,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:19:55,975:INFO:setup() successfully completed in 2.98s...............
2025-07-10 10:20:28,401:INFO:Initializing compare_models()
2025-07-10 10:20:28,402:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-10 10:20:28,402:INFO:Checking exceptions
2025-07-10 10:20:28,429:INFO:Preparing display monitor
2025-07-10 10:20:28,493:INFO:Initializing Logistic Regression
2025-07-10 10:20:28,494:INFO:Total runtime is 1.66932741800944e-05 minutes
2025-07-10 10:20:28,502:INFO:SubProcess create_model() called ==================================
2025-07-10 10:20:28,503:INFO:Initializing create_model()
2025-07-10 10:20:28,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:20:28,503:INFO:Checking exceptions
2025-07-10 10:20:28,503:INFO:Importing libraries
2025-07-10 10:20:28,503:INFO:Copying training dataset
2025-07-10 10:20:28,578:INFO:Defining folds
2025-07-10 10:20:28,578:INFO:Declaring metric variables
2025-07-10 10:20:28,585:INFO:Importing untrained model
2025-07-10 10:20:28,592:INFO:Logistic Regression Imported successfully
2025-07-10 10:20:28,605:INFO:Starting cross validation
2025-07-10 10:20:28,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:20:54,340:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:20:54,592:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:20:54,624:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:20:54,700:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:20:54,860:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:20:55,087:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:20:55,484:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:20:55,654:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:04,941:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:04,990:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:05,160:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:05,184:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:05,244:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:05,404:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:05,800:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:05,993:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:12,154:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:12,265:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:12,345:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:21:12,426:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:12,436:INFO:Calculating mean and std
2025-07-10 10:21:12,436:INFO:Creating metrics dataframe
2025-07-10 10:21:12,446:INFO:Uploading results into container
2025-07-10 10:21:12,446:INFO:Uploading model into container now
2025-07-10 10:21:12,446:INFO:_master_model_container: 1
2025-07-10 10:21:12,446:INFO:_display_container: 2
2025-07-10 10:21:12,446:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-10 10:21:12,446:INFO:create_model() successfully completed......................................
2025-07-10 10:21:12,557:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:12,565:INFO:Creating metrics dataframe
2025-07-10 10:21:12,576:INFO:Initializing K Neighbors Classifier
2025-07-10 10:21:12,576:INFO:Total runtime is 0.7347258687019348 minutes
2025-07-10 10:21:12,582:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:12,583:INFO:Initializing create_model()
2025-07-10 10:21:12,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:12,583:INFO:Checking exceptions
2025-07-10 10:21:12,583:INFO:Importing libraries
2025-07-10 10:21:12,583:INFO:Copying training dataset
2025-07-10 10:21:12,618:INFO:Defining folds
2025-07-10 10:21:12,618:INFO:Declaring metric variables
2025-07-10 10:21:12,624:INFO:Importing untrained model
2025-07-10 10:21:12,632:INFO:K Neighbors Classifier Imported successfully
2025-07-10 10:21:12,646:INFO:Starting cross validation
2025-07-10 10:21:12,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:21:25,911:INFO:Calculating mean and std
2025-07-10 10:21:25,919:INFO:Creating metrics dataframe
2025-07-10 10:21:25,921:INFO:Uploading results into container
2025-07-10 10:21:25,921:INFO:Uploading model into container now
2025-07-10 10:21:25,921:INFO:_master_model_container: 2
2025-07-10 10:21:25,921:INFO:_display_container: 2
2025-07-10 10:21:25,921:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-10 10:21:25,921:INFO:create_model() successfully completed......................................
2025-07-10 10:21:26,042:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:26,042:INFO:Creating metrics dataframe
2025-07-10 10:21:26,064:INFO:Initializing Naive Bayes
2025-07-10 10:21:26,064:INFO:Total runtime is 0.9595316648483276 minutes
2025-07-10 10:21:26,069:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:26,069:INFO:Initializing create_model()
2025-07-10 10:21:26,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:26,070:INFO:Checking exceptions
2025-07-10 10:21:26,070:INFO:Importing libraries
2025-07-10 10:21:26,071:INFO:Copying training dataset
2025-07-10 10:21:26,139:INFO:Defining folds
2025-07-10 10:21:26,139:INFO:Declaring metric variables
2025-07-10 10:21:26,144:INFO:Importing untrained model
2025-07-10 10:21:26,154:INFO:Naive Bayes Imported successfully
2025-07-10 10:21:26,176:INFO:Starting cross validation
2025-07-10 10:21:26,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:21:29,084:INFO:Calculating mean and std
2025-07-10 10:21:29,084:INFO:Creating metrics dataframe
2025-07-10 10:21:29,084:INFO:Uploading results into container
2025-07-10 10:21:29,084:INFO:Uploading model into container now
2025-07-10 10:21:29,084:INFO:_master_model_container: 3
2025-07-10 10:21:29,084:INFO:_display_container: 2
2025-07-10 10:21:29,084:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-10 10:21:29,084:INFO:create_model() successfully completed......................................
2025-07-10 10:21:29,185:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:29,185:INFO:Creating metrics dataframe
2025-07-10 10:21:29,211:INFO:Initializing Decision Tree Classifier
2025-07-10 10:21:29,211:INFO:Total runtime is 1.011971116065979 minutes
2025-07-10 10:21:29,216:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:29,216:INFO:Initializing create_model()
2025-07-10 10:21:29,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:29,217:INFO:Checking exceptions
2025-07-10 10:21:29,217:INFO:Importing libraries
2025-07-10 10:21:29,217:INFO:Copying training dataset
2025-07-10 10:21:29,244:INFO:Defining folds
2025-07-10 10:21:29,245:INFO:Declaring metric variables
2025-07-10 10:21:29,251:INFO:Importing untrained model
2025-07-10 10:21:29,259:INFO:Decision Tree Classifier Imported successfully
2025-07-10 10:21:29,271:INFO:Starting cross validation
2025-07-10 10:21:29,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:21:33,481:INFO:Calculating mean and std
2025-07-10 10:21:33,483:INFO:Creating metrics dataframe
2025-07-10 10:21:33,483:INFO:Uploading results into container
2025-07-10 10:21:33,488:INFO:Uploading model into container now
2025-07-10 10:21:33,488:INFO:_master_model_container: 4
2025-07-10 10:21:33,488:INFO:_display_container: 2
2025-07-10 10:21:33,488:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 10:21:33,488:INFO:create_model() successfully completed......................................
2025-07-10 10:21:33,620:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:33,620:INFO:Creating metrics dataframe
2025-07-10 10:21:33,635:INFO:Initializing SVM - Linear Kernel
2025-07-10 10:21:33,635:INFO:Total runtime is 1.0857098857561747 minutes
2025-07-10 10:21:33,651:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:33,651:INFO:Initializing create_model()
2025-07-10 10:21:33,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:33,652:INFO:Checking exceptions
2025-07-10 10:21:33,652:INFO:Importing libraries
2025-07-10 10:21:33,652:INFO:Copying training dataset
2025-07-10 10:21:33,694:INFO:Defining folds
2025-07-10 10:21:33,694:INFO:Declaring metric variables
2025-07-10 10:21:33,701:INFO:Importing untrained model
2025-07-10 10:21:33,712:INFO:SVM - Linear Kernel Imported successfully
2025-07-10 10:21:33,735:INFO:Starting cross validation
2025-07-10 10:21:33,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:21:34,781:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:35,913:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:36,038:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:36,912:INFO:Calculating mean and std
2025-07-10 10:21:36,912:INFO:Creating metrics dataframe
2025-07-10 10:21:36,922:INFO:Uploading results into container
2025-07-10 10:21:36,922:INFO:Uploading model into container now
2025-07-10 10:21:36,922:INFO:_master_model_container: 5
2025-07-10 10:21:36,922:INFO:_display_container: 2
2025-07-10 10:21:36,922:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-10 10:21:36,922:INFO:create_model() successfully completed......................................
2025-07-10 10:21:37,057:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:37,057:INFO:Creating metrics dataframe
2025-07-10 10:21:37,063:INFO:Initializing Ridge Classifier
2025-07-10 10:21:37,063:INFO:Total runtime is 1.1428337216377258 minutes
2025-07-10 10:21:37,063:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:37,063:INFO:Initializing create_model()
2025-07-10 10:21:37,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:37,078:INFO:Checking exceptions
2025-07-10 10:21:37,078:INFO:Importing libraries
2025-07-10 10:21:37,078:INFO:Copying training dataset
2025-07-10 10:21:37,123:INFO:Defining folds
2025-07-10 10:21:37,123:INFO:Declaring metric variables
2025-07-10 10:21:37,133:INFO:Importing untrained model
2025-07-10 10:21:37,143:INFO:Ridge Classifier Imported successfully
2025-07-10 10:21:37,153:INFO:Starting cross validation
2025-07-10 10:21:37,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:21:38,184:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:38,225:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:38,243:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:38,255:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:39,203:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:39,266:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:39,286:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:39,326:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:40,060:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:40,062:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:21:40,080:INFO:Calculating mean and std
2025-07-10 10:21:40,080:INFO:Creating metrics dataframe
2025-07-10 10:21:40,089:INFO:Uploading results into container
2025-07-10 10:21:40,090:INFO:Uploading model into container now
2025-07-10 10:21:40,090:INFO:_master_model_container: 6
2025-07-10 10:21:40,090:INFO:_display_container: 2
2025-07-10 10:21:40,093:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-10 10:21:40,093:INFO:create_model() successfully completed......................................
2025-07-10 10:21:40,206:INFO:SubProcess create_model() end ==================================
2025-07-10 10:21:40,206:INFO:Creating metrics dataframe
2025-07-10 10:21:40,222:INFO:Initializing Random Forest Classifier
2025-07-10 10:21:40,222:INFO:Total runtime is 1.1954864660898843 minutes
2025-07-10 10:21:40,222:INFO:SubProcess create_model() called ==================================
2025-07-10 10:21:40,222:INFO:Initializing create_model()
2025-07-10 10:21:40,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:21:40,222:INFO:Checking exceptions
2025-07-10 10:21:40,222:INFO:Importing libraries
2025-07-10 10:21:40,222:INFO:Copying training dataset
2025-07-10 10:21:40,277:INFO:Defining folds
2025-07-10 10:21:40,277:INFO:Declaring metric variables
2025-07-10 10:21:40,286:INFO:Importing untrained model
2025-07-10 10:21:40,298:INFO:Random Forest Classifier Imported successfully
2025-07-10 10:21:40,313:INFO:Starting cross validation
2025-07-10 10:21:40,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:22:02,360:INFO:Calculating mean and std
2025-07-10 10:22:02,360:INFO:Creating metrics dataframe
2025-07-10 10:22:02,376:INFO:Uploading results into container
2025-07-10 10:22:02,377:INFO:Uploading model into container now
2025-07-10 10:22:02,378:INFO:_master_model_container: 7
2025-07-10 10:22:02,378:INFO:_display_container: 2
2025-07-10 10:22:02,379:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-10 10:22:02,380:INFO:create_model() successfully completed......................................
2025-07-10 10:22:02,502:INFO:SubProcess create_model() end ==================================
2025-07-10 10:22:02,502:INFO:Creating metrics dataframe
2025-07-10 10:22:02,533:INFO:Initializing Quadratic Discriminant Analysis
2025-07-10 10:22:02,533:INFO:Total runtime is 1.5673367698987324 minutes
2025-07-10 10:22:02,545:INFO:SubProcess create_model() called ==================================
2025-07-10 10:22:02,545:INFO:Initializing create_model()
2025-07-10 10:22:02,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:22:02,545:INFO:Checking exceptions
2025-07-10 10:22:02,545:INFO:Importing libraries
2025-07-10 10:22:02,545:INFO:Copying training dataset
2025-07-10 10:22:02,596:INFO:Defining folds
2025-07-10 10:22:02,597:INFO:Declaring metric variables
2025-07-10 10:22:02,603:INFO:Importing untrained model
2025-07-10 10:22:02,611:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-10 10:22:02,623:INFO:Starting cross validation
2025-07-10 10:22:02,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:22:03,688:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:03,738:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:03,756:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:03,789:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:04,911:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:05,021:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:05,033:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:05,073:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:05,913:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:05,993:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:22:06,159:INFO:Calculating mean and std
2025-07-10 10:22:06,161:INFO:Creating metrics dataframe
2025-07-10 10:22:06,169:INFO:Uploading results into container
2025-07-10 10:22:06,170:INFO:Uploading model into container now
2025-07-10 10:22:06,171:INFO:_master_model_container: 8
2025-07-10 10:22:06,172:INFO:_display_container: 2
2025-07-10 10:22:06,172:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-10 10:22:06,173:INFO:create_model() successfully completed......................................
2025-07-10 10:22:06,297:INFO:SubProcess create_model() end ==================================
2025-07-10 10:22:06,297:INFO:Creating metrics dataframe
2025-07-10 10:22:06,297:INFO:Initializing Ada Boost Classifier
2025-07-10 10:22:06,297:INFO:Total runtime is 1.6300744732220966 minutes
2025-07-10 10:22:06,313:INFO:SubProcess create_model() called ==================================
2025-07-10 10:22:06,313:INFO:Initializing create_model()
2025-07-10 10:22:06,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:22:06,318:INFO:Checking exceptions
2025-07-10 10:22:06,318:INFO:Importing libraries
2025-07-10 10:22:06,318:INFO:Copying training dataset
2025-07-10 10:22:06,360:INFO:Defining folds
2025-07-10 10:22:06,360:INFO:Declaring metric variables
2025-07-10 10:22:06,371:INFO:Importing untrained model
2025-07-10 10:22:06,378:INFO:Ada Boost Classifier Imported successfully
2025-07-10 10:22:06,389:INFO:Starting cross validation
2025-07-10 10:22:06,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:22:07,146:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:07,156:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:07,176:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:07,197:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:11,108:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:11,118:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:11,149:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:11,239:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:14,804:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:14,824:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:22:16,922:INFO:Calculating mean and std
2025-07-10 10:22:16,930:INFO:Creating metrics dataframe
2025-07-10 10:22:16,930:INFO:Uploading results into container
2025-07-10 10:22:16,930:INFO:Uploading model into container now
2025-07-10 10:22:16,930:INFO:_master_model_container: 9
2025-07-10 10:22:16,930:INFO:_display_container: 2
2025-07-10 10:22:16,930:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-10 10:22:16,930:INFO:create_model() successfully completed......................................
2025-07-10 10:22:17,040:INFO:SubProcess create_model() end ==================================
2025-07-10 10:22:17,040:INFO:Creating metrics dataframe
2025-07-10 10:22:17,056:INFO:Initializing Gradient Boosting Classifier
2025-07-10 10:22:17,056:INFO:Total runtime is 1.809396429856618 minutes
2025-07-10 10:22:17,061:INFO:SubProcess create_model() called ==================================
2025-07-10 10:22:17,061:INFO:Initializing create_model()
2025-07-10 10:22:17,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:22:17,062:INFO:Checking exceptions
2025-07-10 10:22:17,063:INFO:Importing libraries
2025-07-10 10:22:17,063:INFO:Copying training dataset
2025-07-10 10:22:17,128:INFO:Defining folds
2025-07-10 10:22:17,129:INFO:Declaring metric variables
2025-07-10 10:22:17,138:INFO:Importing untrained model
2025-07-10 10:22:17,159:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:22:17,179:INFO:Starting cross validation
2025-07-10 10:22:17,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:22:45,909:INFO:Calculating mean and std
2025-07-10 10:22:45,909:INFO:Creating metrics dataframe
2025-07-10 10:22:45,917:INFO:Uploading results into container
2025-07-10 10:22:45,917:INFO:Uploading model into container now
2025-07-10 10:22:45,917:INFO:_master_model_container: 10
2025-07-10 10:22:45,917:INFO:_display_container: 2
2025-07-10 10:22:45,917:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:22:45,917:INFO:create_model() successfully completed......................................
2025-07-10 10:22:46,027:INFO:SubProcess create_model() end ==================================
2025-07-10 10:22:46,027:INFO:Creating metrics dataframe
2025-07-10 10:22:46,043:INFO:Initializing Linear Discriminant Analysis
2025-07-10 10:22:46,043:INFO:Total runtime is 2.2925140778223674 minutes
2025-07-10 10:22:46,047:INFO:SubProcess create_model() called ==================================
2025-07-10 10:22:46,048:INFO:Initializing create_model()
2025-07-10 10:22:46,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:22:46,048:INFO:Checking exceptions
2025-07-10 10:22:46,049:INFO:Importing libraries
2025-07-10 10:22:46,049:INFO:Copying training dataset
2025-07-10 10:22:46,081:INFO:Defining folds
2025-07-10 10:22:46,081:INFO:Declaring metric variables
2025-07-10 10:22:46,088:INFO:Importing untrained model
2025-07-10 10:22:46,097:INFO:Linear Discriminant Analysis Imported successfully
2025-07-10 10:22:46,110:INFO:Starting cross validation
2025-07-10 10:22:46,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:22:47,261:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:47,289:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:47,320:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:47,332:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:48,414:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:48,476:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:48,505:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:49,171:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:49,202:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:22:49,212:INFO:Calculating mean and std
2025-07-10 10:22:49,212:INFO:Creating metrics dataframe
2025-07-10 10:22:49,220:INFO:Uploading results into container
2025-07-10 10:22:49,220:INFO:Uploading model into container now
2025-07-10 10:22:49,220:INFO:_master_model_container: 11
2025-07-10 10:22:49,220:INFO:_display_container: 2
2025-07-10 10:22:49,220:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-10 10:22:49,224:INFO:create_model() successfully completed......................................
2025-07-10 10:22:49,330:INFO:SubProcess create_model() end ==================================
2025-07-10 10:22:49,330:INFO:Creating metrics dataframe
2025-07-10 10:22:49,330:INFO:Initializing Extra Trees Classifier
2025-07-10 10:22:49,330:INFO:Total runtime is 2.3472836017608643 minutes
2025-07-10 10:22:49,351:INFO:SubProcess create_model() called ==================================
2025-07-10 10:22:49,351:INFO:Initializing create_model()
2025-07-10 10:22:49,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:22:49,352:INFO:Checking exceptions
2025-07-10 10:22:49,352:INFO:Importing libraries
2025-07-10 10:22:49,352:INFO:Copying training dataset
2025-07-10 10:22:49,384:INFO:Defining folds
2025-07-10 10:22:49,384:INFO:Declaring metric variables
2025-07-10 10:22:49,390:INFO:Importing untrained model
2025-07-10 10:22:49,398:INFO:Extra Trees Classifier Imported successfully
2025-07-10 10:22:49,411:INFO:Starting cross validation
2025-07-10 10:22:49,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:23:13,107:INFO:Calculating mean and std
2025-07-10 10:23:13,107:INFO:Creating metrics dataframe
2025-07-10 10:23:13,115:INFO:Uploading results into container
2025-07-10 10:23:13,117:INFO:Uploading model into container now
2025-07-10 10:23:13,117:INFO:_master_model_container: 12
2025-07-10 10:23:13,117:INFO:_display_container: 2
2025-07-10 10:23:13,117:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-10 10:23:13,117:INFO:create_model() successfully completed......................................
2025-07-10 10:23:13,289:INFO:SubProcess create_model() end ==================================
2025-07-10 10:23:13,289:INFO:Creating metrics dataframe
2025-07-10 10:23:13,309:INFO:Initializing Light Gradient Boosting Machine
2025-07-10 10:23:13,309:INFO:Total runtime is 2.746946946779887 minutes
2025-07-10 10:23:13,319:INFO:SubProcess create_model() called ==================================
2025-07-10 10:23:13,319:INFO:Initializing create_model()
2025-07-10 10:23:13,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:13,319:INFO:Checking exceptions
2025-07-10 10:23:13,319:INFO:Importing libraries
2025-07-10 10:23:13,319:INFO:Copying training dataset
2025-07-10 10:23:13,383:INFO:Defining folds
2025-07-10 10:23:13,383:INFO:Declaring metric variables
2025-07-10 10:23:13,395:INFO:Importing untrained model
2025-07-10 10:23:13,408:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-10 10:23:13,426:INFO:Starting cross validation
2025-07-10 10:23:13,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:23:19,250:INFO:Calculating mean and std
2025-07-10 10:23:19,250:INFO:Creating metrics dataframe
2025-07-10 10:23:19,258:INFO:Uploading results into container
2025-07-10 10:23:19,260:INFO:Uploading model into container now
2025-07-10 10:23:19,260:INFO:_master_model_container: 13
2025-07-10 10:23:19,260:INFO:_display_container: 2
2025-07-10 10:23:19,260:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-10 10:23:19,260:INFO:create_model() successfully completed......................................
2025-07-10 10:23:19,387:INFO:SubProcess create_model() end ==================================
2025-07-10 10:23:19,388:INFO:Creating metrics dataframe
2025-07-10 10:23:19,403:INFO:Initializing Dummy Classifier
2025-07-10 10:23:19,404:INFO:Total runtime is 2.8485196749369304 minutes
2025-07-10 10:23:19,410:INFO:SubProcess create_model() called ==================================
2025-07-10 10:23:19,410:INFO:Initializing create_model()
2025-07-10 10:23:19,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E3C3410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:19,410:INFO:Checking exceptions
2025-07-10 10:23:19,410:INFO:Importing libraries
2025-07-10 10:23:19,410:INFO:Copying training dataset
2025-07-10 10:23:19,471:INFO:Defining folds
2025-07-10 10:23:19,471:INFO:Declaring metric variables
2025-07-10 10:23:19,471:INFO:Importing untrained model
2025-07-10 10:23:19,490:INFO:Dummy Classifier Imported successfully
2025-07-10 10:23:19,509:INFO:Starting cross validation
2025-07-10 10:23:19,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:23:20,389:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:20,407:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:20,417:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:20,419:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,258:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,278:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,278:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,299:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,872:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,902:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:21,914:INFO:Calculating mean and std
2025-07-10 10:23:21,914:INFO:Creating metrics dataframe
2025-07-10 10:23:21,922:INFO:Uploading results into container
2025-07-10 10:23:21,923:INFO:Uploading model into container now
2025-07-10 10:23:21,924:INFO:_master_model_container: 14
2025-07-10 10:23:21,924:INFO:_display_container: 2
2025-07-10 10:23:21,924:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-10 10:23:21,924:INFO:create_model() successfully completed......................................
2025-07-10 10:23:22,035:INFO:SubProcess create_model() end ==================================
2025-07-10 10:23:22,035:INFO:Creating metrics dataframe
2025-07-10 10:23:22,056:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-10 10:23:22,070:INFO:Initializing create_model()
2025-07-10 10:23:22,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:22,070:INFO:Checking exceptions
2025-07-10 10:23:22,074:INFO:Importing libraries
2025-07-10 10:23:22,074:INFO:Copying training dataset
2025-07-10 10:23:22,108:INFO:Defining folds
2025-07-10 10:23:22,108:INFO:Declaring metric variables
2025-07-10 10:23:22,108:INFO:Importing untrained model
2025-07-10 10:23:22,108:INFO:Declaring custom model
2025-07-10 10:23:22,109:INFO:Ada Boost Classifier Imported successfully
2025-07-10 10:23:22,111:INFO:Cross validation set to False
2025-07-10 10:23:22,111:INFO:Fitting Model
2025-07-10 10:23:22,514:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:23:24,009:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-10 10:23:24,009:INFO:create_model() successfully completed......................................
2025-07-10 10:23:24,168:INFO:_master_model_container: 14
2025-07-10 10:23:24,168:INFO:_display_container: 2
2025-07-10 10:23:24,169:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-10 10:23:24,169:INFO:compare_models() successfully completed......................................
2025-07-10 10:23:24,181:INFO:Initializing compare_models()
2025-07-10 10:23:24,181:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-10 10:23:24,182:INFO:Checking exceptions
2025-07-10 10:23:24,199:INFO:Preparing display monitor
2025-07-10 10:23:24,278:INFO:Initializing Logistic Regression
2025-07-10 10:23:24,279:INFO:Total runtime is 1.6649564107259113e-05 minutes
2025-07-10 10:23:24,285:INFO:SubProcess create_model() called ==================================
2025-07-10 10:23:24,285:INFO:Initializing create_model()
2025-07-10 10:23:24,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:24,286:INFO:Checking exceptions
2025-07-10 10:23:24,286:INFO:Importing libraries
2025-07-10 10:23:24,286:INFO:Copying training dataset
2025-07-10 10:23:24,304:INFO:Defining folds
2025-07-10 10:23:24,304:INFO:Declaring metric variables
2025-07-10 10:23:24,324:INFO:Importing untrained model
2025-07-10 10:23:24,329:INFO:Logistic Regression Imported successfully
2025-07-10 10:23:24,340:INFO:Starting cross validation
2025-07-10 10:23:24,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:23:32,893:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:33,014:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:33,034:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:33,095:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:33,183:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:33,216:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:33,216:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:33,377:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:41,726:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:41,827:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:41,865:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:41,898:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:41,956:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:41,997:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:42,009:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:42,059:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:47,783:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:47,894:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:48,084:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-10 10:23:48,171:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:23:48,171:INFO:Calculating mean and std
2025-07-10 10:23:48,171:INFO:Creating metrics dataframe
2025-07-10 10:23:48,188:INFO:Uploading results into container
2025-07-10 10:23:48,190:INFO:Uploading model into container now
2025-07-10 10:23:48,190:INFO:_master_model_container: 15
2025-07-10 10:23:48,190:INFO:_display_container: 3
2025-07-10 10:23:48,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-10 10:23:48,192:INFO:create_model() successfully completed......................................
2025-07-10 10:23:48,309:INFO:SubProcess create_model() end ==================================
2025-07-10 10:23:48,309:INFO:Creating metrics dataframe
2025-07-10 10:23:48,318:INFO:Initializing K Neighbors Classifier
2025-07-10 10:23:48,318:INFO:Total runtime is 0.4006785670916239 minutes
2025-07-10 10:23:48,321:INFO:SubProcess create_model() called ==================================
2025-07-10 10:23:48,324:INFO:Initializing create_model()
2025-07-10 10:23:48,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:48,324:INFO:Checking exceptions
2025-07-10 10:23:48,324:INFO:Importing libraries
2025-07-10 10:23:48,324:INFO:Copying training dataset
2025-07-10 10:23:48,352:INFO:Defining folds
2025-07-10 10:23:48,352:INFO:Declaring metric variables
2025-07-10 10:23:48,360:INFO:Importing untrained model
2025-07-10 10:23:48,369:INFO:K Neighbors Classifier Imported successfully
2025-07-10 10:23:48,382:INFO:Starting cross validation
2025-07-10 10:23:48,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:23:58,702:INFO:Calculating mean and std
2025-07-10 10:23:58,710:INFO:Creating metrics dataframe
2025-07-10 10:23:58,715:INFO:Uploading results into container
2025-07-10 10:23:58,716:INFO:Uploading model into container now
2025-07-10 10:23:58,717:INFO:_master_model_container: 16
2025-07-10 10:23:58,717:INFO:_display_container: 3
2025-07-10 10:23:58,717:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-10 10:23:58,717:INFO:create_model() successfully completed......................................
2025-07-10 10:23:58,820:INFO:SubProcess create_model() end ==================================
2025-07-10 10:23:58,820:INFO:Creating metrics dataframe
2025-07-10 10:23:58,842:INFO:Initializing Naive Bayes
2025-07-10 10:23:58,842:INFO:Total runtime is 0.5760652383168539 minutes
2025-07-10 10:23:58,844:INFO:SubProcess create_model() called ==================================
2025-07-10 10:23:58,844:INFO:Initializing create_model()
2025-07-10 10:23:58,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:23:58,844:INFO:Checking exceptions
2025-07-10 10:23:58,844:INFO:Importing libraries
2025-07-10 10:23:58,844:INFO:Copying training dataset
2025-07-10 10:23:58,883:INFO:Defining folds
2025-07-10 10:23:58,883:INFO:Declaring metric variables
2025-07-10 10:23:58,889:INFO:Importing untrained model
2025-07-10 10:23:58,899:INFO:Naive Bayes Imported successfully
2025-07-10 10:23:58,914:INFO:Starting cross validation
2025-07-10 10:23:58,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:01,879:INFO:Calculating mean and std
2025-07-10 10:24:01,879:INFO:Creating metrics dataframe
2025-07-10 10:24:01,887:INFO:Uploading results into container
2025-07-10 10:24:01,887:INFO:Uploading model into container now
2025-07-10 10:24:01,889:INFO:_master_model_container: 17
2025-07-10 10:24:01,890:INFO:_display_container: 3
2025-07-10 10:24:01,891:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-10 10:24:01,891:INFO:create_model() successfully completed......................................
2025-07-10 10:24:02,021:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:02,021:INFO:Creating metrics dataframe
2025-07-10 10:24:02,032:INFO:Initializing Decision Tree Classifier
2025-07-10 10:24:02,032:INFO:Total runtime is 0.6292440891265869 minutes
2025-07-10 10:24:02,036:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:02,036:INFO:Initializing create_model()
2025-07-10 10:24:02,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:02,036:INFO:Checking exceptions
2025-07-10 10:24:02,036:INFO:Importing libraries
2025-07-10 10:24:02,036:INFO:Copying training dataset
2025-07-10 10:24:02,126:INFO:Defining folds
2025-07-10 10:24:02,127:INFO:Declaring metric variables
2025-07-10 10:24:02,135:INFO:Importing untrained model
2025-07-10 10:24:02,148:INFO:Decision Tree Classifier Imported successfully
2025-07-10 10:24:02,171:INFO:Starting cross validation
2025-07-10 10:24:02,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:06,434:INFO:Calculating mean and std
2025-07-10 10:24:06,434:INFO:Creating metrics dataframe
2025-07-10 10:24:06,434:INFO:Uploading results into container
2025-07-10 10:24:06,442:INFO:Uploading model into container now
2025-07-10 10:24:06,443:INFO:_master_model_container: 18
2025-07-10 10:24:06,443:INFO:_display_container: 3
2025-07-10 10:24:06,444:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-10 10:24:06,444:INFO:create_model() successfully completed......................................
2025-07-10 10:24:06,574:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:06,575:INFO:Creating metrics dataframe
2025-07-10 10:24:06,585:INFO:Initializing SVM - Linear Kernel
2025-07-10 10:24:06,585:INFO:Total runtime is 0.7051256020863851 minutes
2025-07-10 10:24:06,601:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:06,601:INFO:Initializing create_model()
2025-07-10 10:24:06,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:06,603:INFO:Checking exceptions
2025-07-10 10:24:06,603:INFO:Importing libraries
2025-07-10 10:24:06,603:INFO:Copying training dataset
2025-07-10 10:24:06,644:INFO:Defining folds
2025-07-10 10:24:06,644:INFO:Declaring metric variables
2025-07-10 10:24:06,649:INFO:Importing untrained model
2025-07-10 10:24:06,659:INFO:SVM - Linear Kernel Imported successfully
2025-07-10 10:24:06,672:INFO:Starting cross validation
2025-07-10 10:24:06,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:07,767:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:08,766:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:08,978:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:09,589:INFO:Calculating mean and std
2025-07-10 10:24:09,591:INFO:Creating metrics dataframe
2025-07-10 10:24:09,591:INFO:Uploading results into container
2025-07-10 10:24:09,591:INFO:Uploading model into container now
2025-07-10 10:24:09,591:INFO:_master_model_container: 19
2025-07-10 10:24:09,591:INFO:_display_container: 3
2025-07-10 10:24:09,591:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-10 10:24:09,591:INFO:create_model() successfully completed......................................
2025-07-10 10:24:09,724:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:09,724:INFO:Creating metrics dataframe
2025-07-10 10:24:09,735:INFO:Initializing Ridge Classifier
2025-07-10 10:24:09,735:INFO:Total runtime is 0.7576254487037659 minutes
2025-07-10 10:24:09,740:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:09,740:INFO:Initializing create_model()
2025-07-10 10:24:09,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:09,742:INFO:Checking exceptions
2025-07-10 10:24:09,742:INFO:Importing libraries
2025-07-10 10:24:09,742:INFO:Copying training dataset
2025-07-10 10:24:09,781:INFO:Defining folds
2025-07-10 10:24:09,781:INFO:Declaring metric variables
2025-07-10 10:24:09,786:INFO:Importing untrained model
2025-07-10 10:24:09,794:INFO:Ridge Classifier Imported successfully
2025-07-10 10:24:09,808:INFO:Starting cross validation
2025-07-10 10:24:09,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:10,710:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:10,733:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:10,753:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:10,753:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:11,673:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:11,683:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:11,691:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:11,704:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:12,309:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:12,339:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:24:12,349:INFO:Calculating mean and std
2025-07-10 10:24:12,349:INFO:Creating metrics dataframe
2025-07-10 10:24:12,349:INFO:Uploading results into container
2025-07-10 10:24:12,349:INFO:Uploading model into container now
2025-07-10 10:24:12,349:INFO:_master_model_container: 20
2025-07-10 10:24:12,349:INFO:_display_container: 3
2025-07-10 10:24:12,358:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-10 10:24:12,358:INFO:create_model() successfully completed......................................
2025-07-10 10:24:12,464:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:12,464:INFO:Creating metrics dataframe
2025-07-10 10:24:12,478:INFO:Initializing Random Forest Classifier
2025-07-10 10:24:12,478:INFO:Total runtime is 0.8033338109652202 minutes
2025-07-10 10:24:12,484:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:12,484:INFO:Initializing create_model()
2025-07-10 10:24:12,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:12,484:INFO:Checking exceptions
2025-07-10 10:24:12,484:INFO:Importing libraries
2025-07-10 10:24:12,484:INFO:Copying training dataset
2025-07-10 10:24:12,517:INFO:Defining folds
2025-07-10 10:24:12,517:INFO:Declaring metric variables
2025-07-10 10:24:12,523:INFO:Importing untrained model
2025-07-10 10:24:12,523:INFO:Random Forest Classifier Imported successfully
2025-07-10 10:24:12,542:INFO:Starting cross validation
2025-07-10 10:24:12,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:34,173:INFO:Calculating mean and std
2025-07-10 10:24:34,175:INFO:Creating metrics dataframe
2025-07-10 10:24:34,183:INFO:Uploading results into container
2025-07-10 10:24:34,183:INFO:Uploading model into container now
2025-07-10 10:24:34,185:INFO:_master_model_container: 21
2025-07-10 10:24:34,185:INFO:_display_container: 3
2025-07-10 10:24:34,185:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-10 10:24:34,187:INFO:create_model() successfully completed......................................
2025-07-10 10:24:34,378:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:34,378:INFO:Creating metrics dataframe
2025-07-10 10:24:34,398:INFO:Initializing Quadratic Discriminant Analysis
2025-07-10 10:24:34,398:INFO:Total runtime is 1.1686689933141072 minutes
2025-07-10 10:24:34,408:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:34,408:INFO:Initializing create_model()
2025-07-10 10:24:34,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:34,416:INFO:Checking exceptions
2025-07-10 10:24:34,416:INFO:Importing libraries
2025-07-10 10:24:34,417:INFO:Copying training dataset
2025-07-10 10:24:34,479:INFO:Defining folds
2025-07-10 10:24:34,479:INFO:Declaring metric variables
2025-07-10 10:24:34,500:INFO:Importing untrained model
2025-07-10 10:24:34,511:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-10 10:24:34,539:INFO:Starting cross validation
2025-07-10 10:24:34,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:35,623:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:35,664:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:35,775:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:35,806:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:36,979:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:37,019:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:37,050:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:37,139:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:38,060:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:38,101:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-10 10:24:38,262:INFO:Calculating mean and std
2025-07-10 10:24:38,270:INFO:Creating metrics dataframe
2025-07-10 10:24:38,270:INFO:Uploading results into container
2025-07-10 10:24:38,270:INFO:Uploading model into container now
2025-07-10 10:24:38,270:INFO:_master_model_container: 22
2025-07-10 10:24:38,270:INFO:_display_container: 3
2025-07-10 10:24:38,270:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-10 10:24:38,270:INFO:create_model() successfully completed......................................
2025-07-10 10:24:38,397:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:38,398:INFO:Creating metrics dataframe
2025-07-10 10:24:38,413:INFO:Initializing Ada Boost Classifier
2025-07-10 10:24:38,413:INFO:Total runtime is 1.2355870842933654 minutes
2025-07-10 10:24:38,419:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:38,419:INFO:Initializing create_model()
2025-07-10 10:24:38,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:38,419:INFO:Checking exceptions
2025-07-10 10:24:38,419:INFO:Importing libraries
2025-07-10 10:24:38,419:INFO:Copying training dataset
2025-07-10 10:24:38,473:INFO:Defining folds
2025-07-10 10:24:38,474:INFO:Declaring metric variables
2025-07-10 10:24:38,481:INFO:Importing untrained model
2025-07-10 10:24:38,491:INFO:Ada Boost Classifier Imported successfully
2025-07-10 10:24:38,505:INFO:Starting cross validation
2025-07-10 10:24:38,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:24:39,308:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:39,349:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:39,359:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:39,409:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:42,995:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:43,015:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:43,035:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:43,116:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:46,257:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:46,315:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-10 10:24:48,289:INFO:Calculating mean and std
2025-07-10 10:24:48,289:INFO:Creating metrics dataframe
2025-07-10 10:24:48,297:INFO:Uploading results into container
2025-07-10 10:24:48,298:INFO:Uploading model into container now
2025-07-10 10:24:48,299:INFO:_master_model_container: 23
2025-07-10 10:24:48,299:INFO:_display_container: 3
2025-07-10 10:24:48,300:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-10 10:24:48,300:INFO:create_model() successfully completed......................................
2025-07-10 10:24:48,427:INFO:SubProcess create_model() end ==================================
2025-07-10 10:24:48,428:INFO:Creating metrics dataframe
2025-07-10 10:24:48,443:INFO:Initializing Gradient Boosting Classifier
2025-07-10 10:24:48,443:INFO:Total runtime is 1.4027474800745645 minutes
2025-07-10 10:24:48,443:INFO:SubProcess create_model() called ==================================
2025-07-10 10:24:48,443:INFO:Initializing create_model()
2025-07-10 10:24:48,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:24:48,453:INFO:Checking exceptions
2025-07-10 10:24:48,453:INFO:Importing libraries
2025-07-10 10:24:48,453:INFO:Copying training dataset
2025-07-10 10:24:48,528:INFO:Defining folds
2025-07-10 10:24:48,528:INFO:Declaring metric variables
2025-07-10 10:24:48,532:INFO:Importing untrained model
2025-07-10 10:24:48,557:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:24:48,581:INFO:Starting cross validation
2025-07-10 10:24:48,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:25:15,787:INFO:Calculating mean and std
2025-07-10 10:25:15,795:INFO:Creating metrics dataframe
2025-07-10 10:25:15,797:INFO:Uploading results into container
2025-07-10 10:25:15,805:INFO:Uploading model into container now
2025-07-10 10:25:15,805:INFO:_master_model_container: 24
2025-07-10 10:25:15,805:INFO:_display_container: 3
2025-07-10 10:25:15,807:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:25:15,807:INFO:create_model() successfully completed......................................
2025-07-10 10:25:15,926:INFO:SubProcess create_model() end ==================================
2025-07-10 10:25:15,926:INFO:Creating metrics dataframe
2025-07-10 10:25:15,938:INFO:Initializing Linear Discriminant Analysis
2025-07-10 10:25:15,938:INFO:Total runtime is 1.8610046545664467 minutes
2025-07-10 10:25:15,938:INFO:SubProcess create_model() called ==================================
2025-07-10 10:25:15,938:INFO:Initializing create_model()
2025-07-10 10:25:15,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:15,946:INFO:Checking exceptions
2025-07-10 10:25:15,946:INFO:Importing libraries
2025-07-10 10:25:15,946:INFO:Copying training dataset
2025-07-10 10:25:15,968:INFO:Defining folds
2025-07-10 10:25:15,968:INFO:Declaring metric variables
2025-07-10 10:25:15,968:INFO:Importing untrained model
2025-07-10 10:25:15,976:INFO:Linear Discriminant Analysis Imported successfully
2025-07-10 10:25:15,986:INFO:Starting cross validation
2025-07-10 10:25:15,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:25:17,129:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:17,149:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:17,160:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:17,178:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:18,301:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:18,331:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:18,331:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:18,350:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:19,066:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:19,068:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:19,086:INFO:Calculating mean and std
2025-07-10 10:25:19,088:INFO:Creating metrics dataframe
2025-07-10 10:25:19,088:INFO:Uploading results into container
2025-07-10 10:25:19,088:INFO:Uploading model into container now
2025-07-10 10:25:19,088:INFO:_master_model_container: 25
2025-07-10 10:25:19,088:INFO:_display_container: 3
2025-07-10 10:25:19,088:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-10 10:25:19,096:INFO:create_model() successfully completed......................................
2025-07-10 10:25:19,206:INFO:SubProcess create_model() end ==================================
2025-07-10 10:25:19,206:INFO:Creating metrics dataframe
2025-07-10 10:25:19,222:INFO:Initializing Extra Trees Classifier
2025-07-10 10:25:19,222:INFO:Total runtime is 1.9157332777976988 minutes
2025-07-10 10:25:19,222:INFO:SubProcess create_model() called ==================================
2025-07-10 10:25:19,222:INFO:Initializing create_model()
2025-07-10 10:25:19,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:19,222:INFO:Checking exceptions
2025-07-10 10:25:19,222:INFO:Importing libraries
2025-07-10 10:25:19,222:INFO:Copying training dataset
2025-07-10 10:25:19,253:INFO:Defining folds
2025-07-10 10:25:19,253:INFO:Declaring metric variables
2025-07-10 10:25:19,253:INFO:Importing untrained model
2025-07-10 10:25:19,253:INFO:Extra Trees Classifier Imported successfully
2025-07-10 10:25:19,269:INFO:Starting cross validation
2025-07-10 10:25:19,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:25:44,179:INFO:Calculating mean and std
2025-07-10 10:25:44,179:INFO:Creating metrics dataframe
2025-07-10 10:25:44,189:INFO:Uploading results into container
2025-07-10 10:25:44,189:INFO:Uploading model into container now
2025-07-10 10:25:44,189:INFO:_master_model_container: 26
2025-07-10 10:25:44,189:INFO:_display_container: 3
2025-07-10 10:25:44,189:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-10 10:25:44,189:INFO:create_model() successfully completed......................................
2025-07-10 10:25:44,370:INFO:SubProcess create_model() end ==================================
2025-07-10 10:25:44,370:INFO:Creating metrics dataframe
2025-07-10 10:25:44,401:INFO:Initializing Light Gradient Boosting Machine
2025-07-10 10:25:44,401:INFO:Total runtime is 2.3353797554969784 minutes
2025-07-10 10:25:44,411:INFO:SubProcess create_model() called ==================================
2025-07-10 10:25:44,411:INFO:Initializing create_model()
2025-07-10 10:25:44,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:44,411:INFO:Checking exceptions
2025-07-10 10:25:44,411:INFO:Importing libraries
2025-07-10 10:25:44,411:INFO:Copying training dataset
2025-07-10 10:25:44,461:INFO:Defining folds
2025-07-10 10:25:44,469:INFO:Declaring metric variables
2025-07-10 10:25:44,471:INFO:Importing untrained model
2025-07-10 10:25:44,481:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-10 10:25:44,501:INFO:Starting cross validation
2025-07-10 10:25:44,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:25:49,902:INFO:Calculating mean and std
2025-07-10 10:25:49,904:INFO:Creating metrics dataframe
2025-07-10 10:25:49,904:INFO:Uploading results into container
2025-07-10 10:25:49,904:INFO:Uploading model into container now
2025-07-10 10:25:49,904:INFO:_master_model_container: 27
2025-07-10 10:25:49,904:INFO:_display_container: 3
2025-07-10 10:25:49,912:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-10 10:25:49,912:INFO:create_model() successfully completed......................................
2025-07-10 10:25:50,044:INFO:SubProcess create_model() end ==================================
2025-07-10 10:25:50,044:INFO:Creating metrics dataframe
2025-07-10 10:25:50,056:INFO:Initializing Dummy Classifier
2025-07-10 10:25:50,056:INFO:Total runtime is 2.4296352585156753 minutes
2025-07-10 10:25:50,066:INFO:SubProcess create_model() called ==================================
2025-07-10 10:25:50,066:INFO:Initializing create_model()
2025-07-10 10:25:50,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E32AC50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:50,066:INFO:Checking exceptions
2025-07-10 10:25:50,066:INFO:Importing libraries
2025-07-10 10:25:50,066:INFO:Copying training dataset
2025-07-10 10:25:50,096:INFO:Defining folds
2025-07-10 10:25:50,096:INFO:Declaring metric variables
2025-07-10 10:25:50,104:INFO:Importing untrained model
2025-07-10 10:25:50,106:INFO:Dummy Classifier Imported successfully
2025-07-10 10:25:50,116:INFO:Starting cross validation
2025-07-10 10:25:50,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:25:50,964:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:50,974:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:50,974:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:50,995:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:51,833:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:51,833:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:51,843:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:51,883:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:52,656:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:52,669:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-10 10:25:52,689:INFO:Calculating mean and std
2025-07-10 10:25:52,689:INFO:Creating metrics dataframe
2025-07-10 10:25:52,689:INFO:Uploading results into container
2025-07-10 10:25:52,697:INFO:Uploading model into container now
2025-07-10 10:25:52,697:INFO:_master_model_container: 28
2025-07-10 10:25:52,697:INFO:_display_container: 3
2025-07-10 10:25:52,697:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-10 10:25:52,697:INFO:create_model() successfully completed......................................
2025-07-10 10:25:52,829:INFO:SubProcess create_model() end ==================================
2025-07-10 10:25:52,829:INFO:Creating metrics dataframe
2025-07-10 10:25:52,850:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-10 10:25:52,868:INFO:Initializing create_model()
2025-07-10 10:25:52,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:52,868:INFO:Checking exceptions
2025-07-10 10:25:52,868:INFO:Importing libraries
2025-07-10 10:25:52,868:INFO:Copying training dataset
2025-07-10 10:25:52,899:INFO:Defining folds
2025-07-10 10:25:52,899:INFO:Declaring metric variables
2025-07-10 10:25:52,899:INFO:Importing untrained model
2025-07-10 10:25:52,899:INFO:Declaring custom model
2025-07-10 10:25:52,899:INFO:SVM - Linear Kernel Imported successfully
2025-07-10 10:25:52,915:INFO:Cross validation set to False
2025-07-10 10:25:52,915:INFO:Fitting Model
2025-07-10 10:25:53,492:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-10 10:25:53,492:INFO:create_model() successfully completed......................................
2025-07-10 10:25:53,663:INFO:_master_model_container: 28
2025-07-10 10:25:53,663:INFO:_display_container: 3
2025-07-10 10:25:53,663:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-10 10:25:53,663:INFO:compare_models() successfully completed......................................
2025-07-10 10:25:53,682:INFO:gpu_param set to False
2025-07-10 10:25:53,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:25:53,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:25:54,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:25:54,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-10 10:25:54,140:INFO:Initializing create_model()
2025-07-10 10:25:54,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:25:54,140:INFO:Checking exceptions
2025-07-10 10:25:54,193:INFO:Importing libraries
2025-07-10 10:25:54,193:INFO:Copying training dataset
2025-07-10 10:25:54,229:INFO:Defining folds
2025-07-10 10:25:54,229:INFO:Declaring metric variables
2025-07-10 10:25:54,244:INFO:Importing untrained model
2025-07-10 10:25:54,244:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:25:54,276:INFO:Starting cross validation
2025-07-10 10:25:54,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:26:20,012:INFO:Calculating mean and std
2025-07-10 10:26:20,012:INFO:Creating metrics dataframe
2025-07-10 10:26:20,020:INFO:Finalizing model
2025-07-10 10:26:25,912:INFO:Uploading results into container
2025-07-10 10:26:25,912:INFO:Uploading model into container now
2025-07-10 10:26:25,934:INFO:_master_model_container: 29
2025-07-10 10:26:25,934:INFO:_display_container: 4
2025-07-10 10:26:25,934:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:26:25,934:INFO:create_model() successfully completed......................................
2025-07-10 10:26:26,069:INFO:Initializing tune_model()
2025-07-10 10:26:26,069:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-10 10:26:26,069:INFO:Checking exceptions
2025-07-10 10:26:26,134:INFO:Copying training dataset
2025-07-10 10:26:26,157:INFO:Checking base model
2025-07-10 10:26:26,157:INFO:Base model : Gradient Boosting Classifier
2025-07-10 10:26:26,173:INFO:Declaring metric variables
2025-07-10 10:26:26,173:INFO:Defining Hyperparameters
2025-07-10 10:26:26,337:INFO:Tuning with n_jobs=-1
2025-07-10 10:26:26,337:INFO:Initializing RandomizedSearchCV
2025-07-10 10:32:05,610:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.4}
2025-07-10 10:32:05,610:INFO:Hyperparameter search completed
2025-07-10 10:32:05,610:INFO:SubProcess create_model() called ==================================
2025-07-10 10:32:05,610:INFO:Initializing create_model()
2025-07-10 10:32:05,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001636E2F2E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'n_estimators': 30, 'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 8, 'learning_rate': 0.4})
2025-07-10 10:32:05,610:INFO:Checking exceptions
2025-07-10 10:32:05,610:INFO:Importing libraries
2025-07-10 10:32:05,610:INFO:Copying training dataset
2025-07-10 10:32:05,651:INFO:Defining folds
2025-07-10 10:32:05,651:INFO:Declaring metric variables
2025-07-10 10:32:05,651:INFO:Importing untrained model
2025-07-10 10:32:05,651:INFO:Declaring custom model
2025-07-10 10:32:05,666:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:32:05,682:INFO:Starting cross validation
2025-07-10 10:32:05,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:32:10,489:INFO:Calculating mean and std
2025-07-10 10:32:10,491:INFO:Creating metrics dataframe
2025-07-10 10:32:10,491:INFO:Finalizing model
2025-07-10 10:32:11,418:INFO:Uploading results into container
2025-07-10 10:32:11,426:INFO:Uploading model into container now
2025-07-10 10:32:11,426:INFO:_master_model_container: 30
2025-07-10 10:32:11,426:INFO:_display_container: 5
2025-07-10 10:32:11,426:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:32:11,426:INFO:create_model() successfully completed......................................
2025-07-10 10:32:11,537:INFO:SubProcess create_model() end ==================================
2025-07-10 10:32:11,537:INFO:choose_better activated
2025-07-10 10:32:11,537:INFO:SubProcess create_model() called ==================================
2025-07-10 10:32:11,537:INFO:Initializing create_model()
2025-07-10 10:32:11,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:32:11,537:INFO:Checking exceptions
2025-07-10 10:32:11,537:INFO:Importing libraries
2025-07-10 10:32:11,537:INFO:Copying training dataset
2025-07-10 10:32:11,568:INFO:Defining folds
2025-07-10 10:32:11,568:INFO:Declaring metric variables
2025-07-10 10:32:11,568:INFO:Importing untrained model
2025-07-10 10:32:11,568:INFO:Declaring custom model
2025-07-10 10:32:11,568:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:32:11,568:INFO:Starting cross validation
2025-07-10 10:32:11,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-10 10:32:37,800:INFO:Calculating mean and std
2025-07-10 10:32:37,808:INFO:Creating metrics dataframe
2025-07-10 10:32:37,810:INFO:Finalizing model
2025-07-10 10:32:43,166:INFO:Uploading results into container
2025-07-10 10:32:43,166:INFO:Uploading model into container now
2025-07-10 10:32:43,166:INFO:_master_model_container: 31
2025-07-10 10:32:43,166:INFO:_display_container: 6
2025-07-10 10:32:43,166:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:32:43,166:INFO:create_model() successfully completed......................................
2025-07-10 10:32:43,277:INFO:SubProcess create_model() end ==================================
2025-07-10 10:32:43,277:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.0544
2025-07-10 10:32:43,277:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.1567
2025-07-10 10:32:43,277:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-07-10 10:32:43,277:INFO:choose_better completed
2025-07-10 10:32:43,285:INFO:_master_model_container: 31
2025-07-10 10:32:43,285:INFO:_display_container: 5
2025-07-10 10:32:43,295:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:32:43,295:INFO:tune_model() successfully completed......................................
2025-07-10 10:32:43,406:INFO:Initializing plot_model()
2025-07-10 10:32:43,406:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 10:32:43,406:INFO:Checking exceptions
2025-07-10 10:32:43,427:INFO:Preloading libraries
2025-07-10 10:32:43,427:INFO:Copying training dataset
2025-07-10 10:32:43,427:INFO:Plot type: auc
2025-07-10 10:32:43,660:INFO:Fitting Model
2025-07-10 10:32:43,663:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:32:43,664:INFO:Scoring test/hold-out set
2025-07-10 10:32:44,053:INFO:Visual Rendered Successfully
2025-07-10 10:32:44,169:INFO:plot_model() successfully completed......................................
2025-07-10 10:32:44,187:INFO:Initializing plot_model()
2025-07-10 10:32:44,187:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 10:32:44,187:INFO:Checking exceptions
2025-07-10 10:32:44,207:INFO:Preloading libraries
2025-07-10 10:32:44,213:INFO:Copying training dataset
2025-07-10 10:32:44,213:INFO:Plot type: pr
2025-07-10 10:32:44,431:INFO:Fitting Model
2025-07-10 10:32:44,433:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:32:44,433:INFO:Scoring test/hold-out set
2025-07-10 10:32:44,739:INFO:Visual Rendered Successfully
2025-07-10 10:32:44,839:INFO:plot_model() successfully completed......................................
2025-07-10 10:32:44,849:INFO:Initializing plot_model()
2025-07-10 10:32:44,849:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 10:32:44,849:INFO:Checking exceptions
2025-07-10 10:32:44,870:INFO:Preloading libraries
2025-07-10 10:32:44,870:INFO:Copying training dataset
2025-07-10 10:32:44,870:INFO:Plot type: feature
2025-07-10 10:32:44,870:WARNING:No coef_ found. Trying feature_importances_
2025-07-10 10:32:45,163:INFO:Visual Rendered Successfully
2025-07-10 10:32:45,283:INFO:plot_model() successfully completed......................................
2025-07-10 10:32:45,290:INFO:Initializing plot_model()
2025-07-10 10:32:45,290:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-10 10:32:45,290:INFO:Checking exceptions
2025-07-10 10:32:45,307:INFO:Preloading libraries
2025-07-10 10:32:45,318:INFO:Copying training dataset
2025-07-10 10:32:45,318:INFO:Plot type: confusion_matrix
2025-07-10 10:32:45,528:INFO:Fitting Model
2025-07-10 10:32:45,529:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-07-10 10:32:45,529:INFO:Scoring test/hold-out set
2025-07-10 10:32:45,722:INFO:Visual Rendered Successfully
2025-07-10 10:32:45,869:INFO:plot_model() successfully completed......................................
2025-07-10 10:32:45,881:INFO:Initializing evaluate_model()
2025-07-10 10:32:45,881:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-07-10 10:32:45,922:INFO:Initializing plot_model()
2025-07-10 10:32:45,923:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-07-10 10:32:45,923:INFO:Checking exceptions
2025-07-10 10:32:45,933:INFO:Preloading libraries
2025-07-10 10:32:45,938:INFO:Copying training dataset
2025-07-10 10:32:45,939:INFO:Plot type: pipeline
2025-07-10 10:32:46,191:INFO:Visual Rendered Successfully
2025-07-10 10:32:46,307:INFO:plot_model() successfully completed......................................
2025-07-10 10:32:46,316:INFO:Initializing predict_model()
2025-07-10 10:32:46,316:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001636EA149A0>)
2025-07-10 10:32:46,316:INFO:Checking exceptions
2025-07-10 10:32:46,316:INFO:Preloading libraries
2025-07-10 10:32:46,650:INFO:Initializing finalize_model()
2025-07-10 10:32:46,650:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-10 10:32:46,650:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-10 10:32:46,672:INFO:Initializing create_model()
2025-07-10 10:32:46,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-10 10:32:46,672:INFO:Checking exceptions
2025-07-10 10:32:46,672:INFO:Importing libraries
2025-07-10 10:32:46,672:INFO:Copying training dataset
2025-07-10 10:32:46,672:INFO:Defining folds
2025-07-10 10:32:46,672:INFO:Declaring metric variables
2025-07-10 10:32:46,672:INFO:Importing untrained model
2025-07-10 10:32:46,672:INFO:Declaring custom model
2025-07-10 10:32:46,672:INFO:Gradient Boosting Classifier Imported successfully
2025-07-10 10:32:46,672:INFO:Cross validation set to False
2025-07-10 10:32:46,672:INFO:Fitting Model
2025-07-10 10:32:47,877:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-10 10:32:47,877:INFO:create_model() successfully completed......................................
2025-07-10 10:32:47,979:INFO:_master_model_container: 31
2025-07-10 10:32:47,979:INFO:_display_container: 6
2025-07-10 10:32:48,020:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-10 10:32:48,020:INFO:finalize_model() successfully completed......................................
2025-07-10 10:32:48,334:INFO:Initializing predict_model()
2025-07-10 10:32:48,334:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001636E562840>)
2025-07-10 10:32:48,334:INFO:Checking exceptions
2025-07-10 10:32:48,334:INFO:Preloading libraries
2025-07-10 10:32:48,813:INFO:Initializing predict_model()
2025-07-10 10:32:48,813:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001636E42A250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001636EA156C0>)
2025-07-10 10:32:48,813:INFO:Checking exceptions
2025-07-10 10:32:48,813:INFO:Preloading libraries
2025-07-10 10:32:48,813:INFO:Set up data.
2025-07-10 10:32:48,828:INFO:Set up index.
2025-07-11 09:36:15,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 09:36:15,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 09:36:15,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 09:36:15,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 09:36:18,785:INFO:Initializing load_model()
2025-07-11 09:36:18,786:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-11 10:03:57,968:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:486: UserWarning: X has feature names, but PCA was fitted without feature names
  warnings.warn(

2025-07-11 10:03:58,726:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:486: UserWarning: X has feature names, but PCA was fitted without feature names
  warnings.warn(

2025-07-11 10:07:46,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 10:07:46,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 10:07:46,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 10:07:46,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-11 10:11:17,893:INFO:PyCaret ClassificationExperiment
2025-07-11 10:11:17,893:INFO:Logging name: credit_1
2025-07-11 10:11:17,893:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-11 10:11:17,893:INFO:version 3.3.2
2025-07-11 10:11:17,893:INFO:Initializing setup()
2025-07-11 10:11:17,893:INFO:self.USI: 8128
2025-07-11 10:11:17,893:INFO:self._variable_keys: {'USI', 'X_train', 'is_multiclass', 'seed', '_ml_usecase', 'exp_id', 'log_plots_param', 'idx', 'gpu_n_jobs_param', 'X_test', 'fix_imbalance', 'n_jobs_param', 'exp_name_log', 'y', 'target_param', 'y_test', 'data', '_available_plots', 'gpu_param', 'y_train', 'html_param', 'logging_param', 'fold_groups_param', 'X', 'fold_generator', 'memory', 'fold_shuffle_param', 'pipeline'}
2025-07-11 10:11:17,893:INFO:Checking environment
2025-07-11 10:11:17,894:INFO:python_version: 3.11.7
2025-07-11 10:11:17,894:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-11 10:11:17,894:INFO:machine: AMD64
2025-07-11 10:11:17,894:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-11 10:11:17,894:INFO:Memory: svmem(total=12698038272, available=5919047680, percent=53.4, used=6778990592, free=5919047680)
2025-07-11 10:11:17,894:INFO:Physical Core: 2
2025-07-11 10:11:17,895:INFO:Logical Core: 4
2025-07-11 10:11:17,895:INFO:Checking libraries
2025-07-11 10:11:17,895:INFO:System:
2025-07-11 10:11:17,895:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-11 10:11:17,895:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-11 10:11:17,895:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-11 10:11:17,895:INFO:PyCaret required dependencies:
2025-07-11 10:11:19,692:INFO:                 pip: 23.3.1
2025-07-11 10:11:19,692:INFO:          setuptools: 68.2.2
2025-07-11 10:11:19,692:INFO:             pycaret: 3.3.2
2025-07-11 10:11:19,692:INFO:             IPython: 8.20.0
2025-07-11 10:11:19,692:INFO:          ipywidgets: 7.7.2
2025-07-11 10:11:19,692:INFO:                tqdm: 4.65.0
2025-07-11 10:11:19,692:INFO:               numpy: 1.26.4
2025-07-11 10:11:19,692:INFO:              pandas: 2.1.4
2025-07-11 10:11:19,707:INFO:              jinja2: 3.1.3
2025-07-11 10:11:19,707:INFO:               scipy: 1.11.4
2025-07-11 10:11:19,707:INFO:              joblib: 1.2.0
2025-07-11 10:11:19,707:INFO:             sklearn: 1.4.2
2025-07-11 10:11:19,707:INFO:                pyod: 2.0.5
2025-07-11 10:11:19,707:INFO:            imblearn: 0.13.0
2025-07-11 10:11:19,707:INFO:   category_encoders: 2.7.0
2025-07-11 10:11:19,707:INFO:            lightgbm: 4.6.0
2025-07-11 10:11:19,707:INFO:               numba: 0.59.0
2025-07-11 10:11:19,707:INFO:            requests: 2.31.0
2025-07-11 10:11:19,707:INFO:          matplotlib: 3.7.5
2025-07-11 10:11:19,707:INFO:          scikitplot: 0.3.7
2025-07-11 10:11:19,707:INFO:         yellowbrick: 1.5
2025-07-11 10:11:19,707:INFO:              plotly: 5.24.1
2025-07-11 10:11:19,707:INFO:    plotly-resampler: Not installed
2025-07-11 10:11:19,707:INFO:             kaleido: 1.0.0
2025-07-11 10:11:19,707:INFO:           schemdraw: 0.15
2025-07-11 10:11:19,707:INFO:         statsmodels: 0.14.0
2025-07-11 10:11:19,707:INFO:              sktime: 0.26.0
2025-07-11 10:11:19,707:INFO:               tbats: 1.1.3
2025-07-11 10:11:19,707:INFO:            pmdarima: 2.0.4
2025-07-11 10:11:19,707:INFO:              psutil: 5.9.0
2025-07-11 10:11:19,707:INFO:          markupsafe: 2.1.3
2025-07-11 10:11:19,707:INFO:             pickle5: Not installed
2025-07-11 10:11:19,707:INFO:         cloudpickle: 2.2.1
2025-07-11 10:11:19,707:INFO:         deprecation: 2.1.0
2025-07-11 10:11:19,707:INFO:              xxhash: 3.5.0
2025-07-11 10:11:19,707:INFO:           wurlitzer: Not installed
2025-07-11 10:11:19,707:INFO:PyCaret optional dependencies:
2025-07-11 10:11:19,738:INFO:                shap: Not installed
2025-07-11 10:11:19,738:INFO:           interpret: Not installed
2025-07-11 10:11:19,738:INFO:                umap: Not installed
2025-07-11 10:11:19,738:INFO:     ydata_profiling: 4.7.0
2025-07-11 10:11:19,738:INFO:  explainerdashboard: Not installed
2025-07-11 10:11:19,738:INFO:             autoviz: Not installed
2025-07-11 10:11:19,738:INFO:           fairlearn: Not installed
2025-07-11 10:11:19,738:INFO:          deepchecks: Not installed
2025-07-11 10:11:19,738:INFO:             xgboost: Not installed
2025-07-11 10:11:19,738:INFO:            catboost: Not installed
2025-07-11 10:11:19,738:INFO:              kmodes: Not installed
2025-07-11 10:11:19,738:INFO:             mlxtend: Not installed
2025-07-11 10:11:19,738:INFO:       statsforecast: Not installed
2025-07-11 10:11:19,738:INFO:        tune_sklearn: Not installed
2025-07-11 10:11:19,738:INFO:                 ray: Not installed
2025-07-11 10:11:19,738:INFO:            hyperopt: Not installed
2025-07-11 10:11:19,738:INFO:              optuna: Not installed
2025-07-11 10:11:19,738:INFO:               skopt: Not installed
2025-07-11 10:11:19,738:INFO:              mlflow: Not installed
2025-07-11 10:11:19,738:INFO:              gradio: Not installed
2025-07-11 10:11:19,738:INFO:             fastapi: Not installed
2025-07-11 10:11:19,738:INFO:             uvicorn: Not installed
2025-07-11 10:11:19,738:INFO:              m2cgen: Not installed
2025-07-11 10:11:19,738:INFO:           evidently: Not installed
2025-07-11 10:11:19,738:INFO:               fugue: Not installed
2025-07-11 10:11:19,738:INFO:           streamlit: 1.46.1
2025-07-11 10:11:19,738:INFO:             prophet: Not installed
2025-07-11 10:11:19,738:INFO:None
2025-07-11 10:11:19,738:INFO:Set up data.
2025-07-11 10:11:19,792:INFO:Set up folding strategy.
2025-07-11 10:11:19,792:INFO:Set up train/test split.
2025-07-11 10:11:19,823:INFO:Set up index.
2025-07-11 10:11:19,823:INFO:Assigning column types.
2025-07-11 10:11:19,839:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-11 10:11:19,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:11:19,973:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:11:20,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:11:20,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:11:20,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,294:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-11 10:11:20,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:11:20,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:11:20,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:20,773:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-11 10:11:21,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:21,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:21,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:21,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:21,240:INFO:Preparing preprocessing pipeline...
2025-07-11 10:11:21,240:INFO:Set up simple imputation.
2025-07-11 10:11:21,256:INFO:Set up encoding of ordinal features.
2025-07-11 10:11:21,278:INFO:Set up encoding of categorical features.
2025-07-11 10:11:21,278:INFO:Set up imbalanced handling.
2025-07-11 10:11:21,278:INFO:Set up column transformation.
2025-07-11 10:11:21,278:INFO:Set up feature normalization.
2025-07-11 10:11:22,105:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
[WinError 2] O sistema não pode encontrar o arquivo especificado
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-07-11 10:11:22,784:INFO:Finished creating preprocessing pipeline.
2025-07-11 10:11:22,838:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=4994,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-07-11 10:11:22,838:INFO:Creating final display dataframe.
2025-07-11 10:11:24,274:INFO:Setup _display_container:                     Description            Value
0                    Session id             4994
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60412, 30)
5   Transformed train set shape      (49012, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.4%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             8128
2025-07-11 10:11:24,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:24,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:24,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:24,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:11:24,653:INFO:setup() successfully completed in 6.77s...............
2025-07-11 10:13:15,627:INFO:PyCaret ClassificationExperiment
2025-07-11 10:13:15,627:INFO:Logging name: credit_1
2025-07-11 10:13:15,627:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-11 10:13:15,627:INFO:version 3.3.2
2025-07-11 10:13:15,627:INFO:Initializing setup()
2025-07-11 10:13:15,627:INFO:self.USI: ca09
2025-07-11 10:13:15,627:INFO:self._variable_keys: {'USI', 'X_train', 'is_multiclass', 'seed', '_ml_usecase', 'exp_id', 'log_plots_param', 'idx', 'gpu_n_jobs_param', 'X_test', 'fix_imbalance', 'n_jobs_param', 'exp_name_log', 'y', 'target_param', 'y_test', 'data', '_available_plots', 'gpu_param', 'y_train', 'html_param', 'logging_param', 'fold_groups_param', 'X', 'fold_generator', 'memory', 'fold_shuffle_param', 'pipeline'}
2025-07-11 10:13:15,627:INFO:Checking environment
2025-07-11 10:13:15,628:INFO:python_version: 3.11.7
2025-07-11 10:13:15,628:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-11 10:13:15,628:INFO:machine: AMD64
2025-07-11 10:13:15,628:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-11 10:13:15,628:INFO:Memory: svmem(total=12698038272, available=5832581120, percent=54.1, used=6865457152, free=5832581120)
2025-07-11 10:13:15,628:INFO:Physical Core: 2
2025-07-11 10:13:15,628:INFO:Logical Core: 4
2025-07-11 10:13:15,628:INFO:Checking libraries
2025-07-11 10:13:15,628:INFO:System:
2025-07-11 10:13:15,628:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-11 10:13:15,628:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-11 10:13:15,629:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-11 10:13:15,629:INFO:PyCaret required dependencies:
2025-07-11 10:13:15,629:INFO:                 pip: 23.3.1
2025-07-11 10:13:15,629:INFO:          setuptools: 68.2.2
2025-07-11 10:13:15,629:INFO:             pycaret: 3.3.2
2025-07-11 10:13:15,629:INFO:             IPython: 8.20.0
2025-07-11 10:13:15,629:INFO:          ipywidgets: 7.7.2
2025-07-11 10:13:15,629:INFO:                tqdm: 4.65.0
2025-07-11 10:13:15,629:INFO:               numpy: 1.26.4
2025-07-11 10:13:15,629:INFO:              pandas: 2.1.4
2025-07-11 10:13:15,629:INFO:              jinja2: 3.1.3
2025-07-11 10:13:15,630:INFO:               scipy: 1.11.4
2025-07-11 10:13:15,630:INFO:              joblib: 1.2.0
2025-07-11 10:13:15,630:INFO:             sklearn: 1.4.2
2025-07-11 10:13:15,630:INFO:                pyod: 2.0.5
2025-07-11 10:13:15,630:INFO:            imblearn: 0.13.0
2025-07-11 10:13:15,630:INFO:   category_encoders: 2.7.0
2025-07-11 10:13:15,630:INFO:            lightgbm: 4.6.0
2025-07-11 10:13:15,630:INFO:               numba: 0.59.0
2025-07-11 10:13:15,630:INFO:            requests: 2.31.0
2025-07-11 10:13:15,630:INFO:          matplotlib: 3.7.5
2025-07-11 10:13:15,631:INFO:          scikitplot: 0.3.7
2025-07-11 10:13:15,631:INFO:         yellowbrick: 1.5
2025-07-11 10:13:15,631:INFO:              plotly: 5.24.1
2025-07-11 10:13:15,631:INFO:    plotly-resampler: Not installed
2025-07-11 10:13:15,631:INFO:             kaleido: 1.0.0
2025-07-11 10:13:15,631:INFO:           schemdraw: 0.15
2025-07-11 10:13:15,631:INFO:         statsmodels: 0.14.0
2025-07-11 10:13:15,631:INFO:              sktime: 0.26.0
2025-07-11 10:13:15,632:INFO:               tbats: 1.1.3
2025-07-11 10:13:15,632:INFO:            pmdarima: 2.0.4
2025-07-11 10:13:15,632:INFO:              psutil: 5.9.0
2025-07-11 10:13:15,632:INFO:          markupsafe: 2.1.3
2025-07-11 10:13:15,632:INFO:             pickle5: Not installed
2025-07-11 10:13:15,632:INFO:         cloudpickle: 2.2.1
2025-07-11 10:13:15,632:INFO:         deprecation: 2.1.0
2025-07-11 10:13:15,632:INFO:              xxhash: 3.5.0
2025-07-11 10:13:15,633:INFO:           wurlitzer: Not installed
2025-07-11 10:13:15,633:INFO:PyCaret optional dependencies:
2025-07-11 10:13:15,633:INFO:                shap: Not installed
2025-07-11 10:13:15,633:INFO:           interpret: Not installed
2025-07-11 10:13:15,633:INFO:                umap: Not installed
2025-07-11 10:13:15,633:INFO:     ydata_profiling: 4.7.0
2025-07-11 10:13:15,633:INFO:  explainerdashboard: Not installed
2025-07-11 10:13:15,634:INFO:             autoviz: Not installed
2025-07-11 10:13:15,634:INFO:           fairlearn: Not installed
2025-07-11 10:13:15,634:INFO:          deepchecks: Not installed
2025-07-11 10:13:15,634:INFO:             xgboost: Not installed
2025-07-11 10:13:15,634:INFO:            catboost: Not installed
2025-07-11 10:13:15,634:INFO:              kmodes: Not installed
2025-07-11 10:13:15,634:INFO:             mlxtend: Not installed
2025-07-11 10:13:15,634:INFO:       statsforecast: Not installed
2025-07-11 10:13:15,635:INFO:        tune_sklearn: Not installed
2025-07-11 10:13:15,635:INFO:                 ray: Not installed
2025-07-11 10:13:15,635:INFO:            hyperopt: Not installed
2025-07-11 10:13:15,635:INFO:              optuna: Not installed
2025-07-11 10:13:15,635:INFO:               skopt: Not installed
2025-07-11 10:13:15,635:INFO:              mlflow: Not installed
2025-07-11 10:13:15,635:INFO:              gradio: Not installed
2025-07-11 10:13:15,635:INFO:             fastapi: Not installed
2025-07-11 10:13:15,635:INFO:             uvicorn: Not installed
2025-07-11 10:13:15,636:INFO:              m2cgen: Not installed
2025-07-11 10:13:15,636:INFO:           evidently: Not installed
2025-07-11 10:13:15,636:INFO:               fugue: Not installed
2025-07-11 10:13:15,636:INFO:           streamlit: 1.46.1
2025-07-11 10:13:15,636:INFO:             prophet: Not installed
2025-07-11 10:13:15,636:INFO:None
2025-07-11 10:13:15,636:INFO:Set up data.
2025-07-11 10:13:15,741:INFO:Set up folding strategy.
2025-07-11 10:13:15,741:INFO:Set up train/test split.
2025-07-11 10:13:15,764:INFO:Set up index.
2025-07-11 10:13:15,764:INFO:Assigning column types.
2025-07-11 10:13:15,764:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-11 10:13:15,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:13:15,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:13:15,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:15,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:13:16,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:13:16,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,140:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-11 10:13:16,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:13:16,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:13:16,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,533:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-11 10:13:16,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:16,888:INFO:Preparing preprocessing pipeline...
2025-07-11 10:13:16,896:INFO:Set up simple imputation.
2025-07-11 10:13:16,908:INFO:Set up encoding of ordinal features.
2025-07-11 10:13:16,918:INFO:Set up encoding of categorical features.
2025-07-11 10:13:16,918:INFO:Set up imbalanced handling.
2025-07-11 10:13:16,918:INFO:Set up column transformation.
2025-07-11 10:13:16,918:INFO:Set up feature normalization.
2025-07-11 10:13:18,201:INFO:Finished creating preprocessing pipeline.
2025-07-11 10:13:18,259:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=6840,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-07-11 10:13:18,259:INFO:Creating final display dataframe.
2025-07-11 10:13:19,752:INFO:Setup _display_container:                     Description            Value
0                    Session id             6840
1                        Target              mau
2                   Target type           Binary
3           Original data shape      (38000, 13)
4        Transformed data shape      (60412, 30)
5   Transformed train set shape      (49012, 30)
6    Transformed test set shape      (11400, 30)
7              Numeric features                5
8          Categorical features                7
9      Rows with missing values            16.4%
10                   Preprocess             True
11              Imputation type           simple
12           Numeric imputation             mean
13       Categorical imputation             mode
14     Maximum one-hot encoding               25
15              Encoding method             None
16                Fix imbalance             True
17         Fix imbalance method            SMOTE
18               Transformation             True
19        Transformation method         quantile
20                    Normalize             True
21             Normalize method           zscore
22               Fold Generator  StratifiedKFold
23                  Fold Number               10
24                     CPU Jobs               -1
25                      Use GPU            False
26               Log Experiment            False
27              Experiment Name         credit_1
28                          USI             ca09
2025-07-11 10:13:19,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:19,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:20,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:20,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:13:20,128:INFO:setup() successfully completed in 4.52s...............
2025-07-11 10:13:20,159:INFO:Initializing compare_models()
2025-07-11 10:13:20,159:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, include=None, exclude=None, fold=4, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, 'include': None, 'exclude': None, 'fold': 4, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-11 10:13:20,159:INFO:Checking exceptions
2025-07-11 10:13:20,182:INFO:Preparing display monitor
2025-07-11 10:13:20,241:INFO:Initializing Logistic Regression
2025-07-11 10:13:20,242:INFO:Total runtime is 1.6645590464274088e-05 minutes
2025-07-11 10:13:20,253:INFO:SubProcess create_model() called ==================================
2025-07-11 10:13:20,254:INFO:Initializing create_model()
2025-07-11 10:13:20,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:13:20,254:INFO:Checking exceptions
2025-07-11 10:13:20,255:INFO:Importing libraries
2025-07-11 10:13:20,255:INFO:Copying training dataset
2025-07-11 10:13:20,276:INFO:Defining folds
2025-07-11 10:13:20,276:INFO:Declaring metric variables
2025-07-11 10:13:20,282:INFO:Importing untrained model
2025-07-11 10:13:20,290:INFO:Logistic Regression Imported successfully
2025-07-11 10:13:20,299:INFO:Starting cross validation
2025-07-11 10:13:20,318:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:13:43,077:INFO:Calculating mean and std
2025-07-11 10:13:43,079:INFO:Creating metrics dataframe
2025-07-11 10:13:43,079:INFO:Uploading results into container
2025-07-11 10:13:43,087:INFO:Uploading model into container now
2025-07-11 10:13:43,087:INFO:_master_model_container: 1
2025-07-11 10:13:43,087:INFO:_display_container: 2
2025-07-11 10:13:43,089:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-11 10:13:43,089:INFO:create_model() successfully completed......................................
2025-07-11 10:13:43,320:INFO:SubProcess create_model() end ==================================
2025-07-11 10:13:43,320:INFO:Creating metrics dataframe
2025-07-11 10:13:43,345:INFO:Initializing K Neighbors Classifier
2025-07-11 10:13:43,345:INFO:Total runtime is 0.3850645224253337 minutes
2025-07-11 10:13:43,351:INFO:SubProcess create_model() called ==================================
2025-07-11 10:13:43,351:INFO:Initializing create_model()
2025-07-11 10:13:43,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:13:43,351:INFO:Checking exceptions
2025-07-11 10:13:43,351:INFO:Importing libraries
2025-07-11 10:13:43,351:INFO:Copying training dataset
2025-07-11 10:13:43,398:INFO:Defining folds
2025-07-11 10:13:43,399:INFO:Declaring metric variables
2025-07-11 10:13:43,409:INFO:Importing untrained model
2025-07-11 10:13:43,421:INFO:K Neighbors Classifier Imported successfully
2025-07-11 10:13:43,440:INFO:Starting cross validation
2025-07-11 10:13:43,444:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:13:55,554:INFO:Calculating mean and std
2025-07-11 10:13:55,554:INFO:Creating metrics dataframe
2025-07-11 10:13:55,562:INFO:Uploading results into container
2025-07-11 10:13:55,564:INFO:Uploading model into container now
2025-07-11 10:13:55,564:INFO:_master_model_container: 2
2025-07-11 10:13:55,564:INFO:_display_container: 2
2025-07-11 10:13:55,564:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-11 10:13:55,564:INFO:create_model() successfully completed......................................
2025-07-11 10:13:55,807:INFO:SubProcess create_model() end ==================================
2025-07-11 10:13:55,807:INFO:Creating metrics dataframe
2025-07-11 10:13:55,830:INFO:Initializing Naive Bayes
2025-07-11 10:13:55,830:INFO:Total runtime is 0.5931433320045472 minutes
2025-07-11 10:13:55,839:INFO:SubProcess create_model() called ==================================
2025-07-11 10:13:55,839:INFO:Initializing create_model()
2025-07-11 10:13:55,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:13:55,840:INFO:Checking exceptions
2025-07-11 10:13:55,840:INFO:Importing libraries
2025-07-11 10:13:55,841:INFO:Copying training dataset
2025-07-11 10:13:55,885:INFO:Defining folds
2025-07-11 10:13:55,885:INFO:Declaring metric variables
2025-07-11 10:13:55,895:INFO:Importing untrained model
2025-07-11 10:13:55,906:INFO:Naive Bayes Imported successfully
2025-07-11 10:13:55,928:INFO:Starting cross validation
2025-07-11 10:13:55,941:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:13:58,151:INFO:Calculating mean and std
2025-07-11 10:13:58,159:INFO:Creating metrics dataframe
2025-07-11 10:13:58,161:INFO:Uploading results into container
2025-07-11 10:13:58,161:INFO:Uploading model into container now
2025-07-11 10:13:58,161:INFO:_master_model_container: 3
2025-07-11 10:13:58,161:INFO:_display_container: 2
2025-07-11 10:13:58,166:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-11 10:13:58,166:INFO:create_model() successfully completed......................................
2025-07-11 10:13:58,391:INFO:SubProcess create_model() end ==================================
2025-07-11 10:13:58,391:INFO:Creating metrics dataframe
2025-07-11 10:13:58,403:INFO:Initializing Decision Tree Classifier
2025-07-11 10:13:58,403:INFO:Total runtime is 0.6360281626383464 minutes
2025-07-11 10:13:58,413:INFO:SubProcess create_model() called ==================================
2025-07-11 10:13:58,417:INFO:Initializing create_model()
2025-07-11 10:13:58,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:13:58,418:INFO:Checking exceptions
2025-07-11 10:13:58,418:INFO:Importing libraries
2025-07-11 10:13:58,418:INFO:Copying training dataset
2025-07-11 10:13:58,453:INFO:Defining folds
2025-07-11 10:13:58,453:INFO:Declaring metric variables
2025-07-11 10:13:58,464:INFO:Importing untrained model
2025-07-11 10:13:58,474:INFO:Decision Tree Classifier Imported successfully
2025-07-11 10:13:58,495:INFO:Starting cross validation
2025-07-11 10:13:58,504:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:01,068:INFO:Calculating mean and std
2025-07-11 10:14:01,068:INFO:Creating metrics dataframe
2025-07-11 10:14:01,068:INFO:Uploading results into container
2025-07-11 10:14:01,076:INFO:Uploading model into container now
2025-07-11 10:14:01,076:INFO:_master_model_container: 4
2025-07-11 10:14:01,076:INFO:_display_container: 2
2025-07-11 10:14:01,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6840, splitter='best')
2025-07-11 10:14:01,078:INFO:create_model() successfully completed......................................
2025-07-11 10:14:01,299:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:01,299:INFO:Creating metrics dataframe
2025-07-11 10:14:01,330:INFO:Initializing SVM - Linear Kernel
2025-07-11 10:14:01,330:INFO:Total runtime is 0.684804387887319 minutes
2025-07-11 10:14:01,341:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:01,342:INFO:Initializing create_model()
2025-07-11 10:14:01,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:01,343:INFO:Checking exceptions
2025-07-11 10:14:01,344:INFO:Importing libraries
2025-07-11 10:14:01,344:INFO:Copying training dataset
2025-07-11 10:14:01,381:INFO:Defining folds
2025-07-11 10:14:01,381:INFO:Declaring metric variables
2025-07-11 10:14:01,397:INFO:Importing untrained model
2025-07-11 10:14:01,409:INFO:SVM - Linear Kernel Imported successfully
2025-07-11 10:14:01,427:INFO:Starting cross validation
2025-07-11 10:14:01,431:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:03,971:INFO:Calculating mean and std
2025-07-11 10:14:03,973:INFO:Creating metrics dataframe
2025-07-11 10:14:03,973:INFO:Uploading results into container
2025-07-11 10:14:03,973:INFO:Uploading model into container now
2025-07-11 10:14:03,973:INFO:_master_model_container: 5
2025-07-11 10:14:03,981:INFO:_display_container: 2
2025-07-11 10:14:03,981:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6840, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-11 10:14:03,981:INFO:create_model() successfully completed......................................
2025-07-11 10:14:04,195:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:04,195:INFO:Creating metrics dataframe
2025-07-11 10:14:04,216:INFO:Initializing Ridge Classifier
2025-07-11 10:14:04,216:INFO:Total runtime is 0.7329023639361064 minutes
2025-07-11 10:14:04,226:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:04,226:INFO:Initializing create_model()
2025-07-11 10:14:04,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:04,226:INFO:Checking exceptions
2025-07-11 10:14:04,226:INFO:Importing libraries
2025-07-11 10:14:04,226:INFO:Copying training dataset
2025-07-11 10:14:04,285:INFO:Defining folds
2025-07-11 10:14:04,285:INFO:Declaring metric variables
2025-07-11 10:14:04,296:INFO:Importing untrained model
2025-07-11 10:14:04,320:INFO:Ridge Classifier Imported successfully
2025-07-11 10:14:04,338:INFO:Starting cross validation
2025-07-11 10:14:04,346:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:06,377:INFO:Calculating mean and std
2025-07-11 10:14:06,377:INFO:Creating metrics dataframe
2025-07-11 10:14:06,387:INFO:Uploading results into container
2025-07-11 10:14:06,387:INFO:Uploading model into container now
2025-07-11 10:14:06,387:INFO:_master_model_container: 6
2025-07-11 10:14:06,387:INFO:_display_container: 2
2025-07-11 10:14:06,387:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6840, solver='auto',
                tol=0.0001)
2025-07-11 10:14:06,387:INFO:create_model() successfully completed......................................
2025-07-11 10:14:06,599:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:06,599:INFO:Creating metrics dataframe
2025-07-11 10:14:06,630:INFO:Initializing Random Forest Classifier
2025-07-11 10:14:06,630:INFO:Total runtime is 0.7731356819470724 minutes
2025-07-11 10:14:06,638:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:06,641:INFO:Initializing create_model()
2025-07-11 10:14:06,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:06,641:INFO:Checking exceptions
2025-07-11 10:14:06,642:INFO:Importing libraries
2025-07-11 10:14:06,642:INFO:Copying training dataset
2025-07-11 10:14:06,683:INFO:Defining folds
2025-07-11 10:14:06,683:INFO:Declaring metric variables
2025-07-11 10:14:06,693:INFO:Importing untrained model
2025-07-11 10:14:06,701:INFO:Random Forest Classifier Imported successfully
2025-07-11 10:14:06,719:INFO:Starting cross validation
2025-07-11 10:14:06,730:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:18,593:INFO:Calculating mean and std
2025-07-11 10:14:18,595:INFO:Creating metrics dataframe
2025-07-11 10:14:18,595:INFO:Uploading results into container
2025-07-11 10:14:18,595:INFO:Uploading model into container now
2025-07-11 10:14:18,603:INFO:_master_model_container: 7
2025-07-11 10:14:18,603:INFO:_display_container: 2
2025-07-11 10:14:18,603:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6840, verbose=0,
                       warm_start=False)
2025-07-11 10:14:18,603:INFO:create_model() successfully completed......................................
2025-07-11 10:14:18,826:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:18,826:INFO:Creating metrics dataframe
2025-07-11 10:14:18,855:INFO:Initializing Quadratic Discriminant Analysis
2025-07-11 10:14:18,856:INFO:Total runtime is 0.9768890778223673 minutes
2025-07-11 10:14:18,863:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:18,863:INFO:Initializing create_model()
2025-07-11 10:14:18,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:18,864:INFO:Checking exceptions
2025-07-11 10:14:18,864:INFO:Importing libraries
2025-07-11 10:14:18,865:INFO:Copying training dataset
2025-07-11 10:14:18,903:INFO:Defining folds
2025-07-11 10:14:18,904:INFO:Declaring metric variables
2025-07-11 10:14:18,911:INFO:Importing untrained model
2025-07-11 10:14:18,922:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-11 10:14:18,937:INFO:Starting cross validation
2025-07-11 10:14:18,951:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:20,583:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-11 10:14:20,658:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-11 10:14:20,734:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-11 10:14:20,765:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-11 10:14:21,077:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:14:21,136:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:14:21,148:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:14:21,208:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:14:21,228:INFO:Calculating mean and std
2025-07-11 10:14:21,236:INFO:Creating metrics dataframe
2025-07-11 10:14:21,238:INFO:Uploading results into container
2025-07-11 10:14:21,238:INFO:Uploading model into container now
2025-07-11 10:14:21,238:INFO:_master_model_container: 8
2025-07-11 10:14:21,238:INFO:_display_container: 2
2025-07-11 10:14:21,238:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-11 10:14:21,238:INFO:create_model() successfully completed......................................
2025-07-11 10:14:21,473:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:21,473:INFO:Creating metrics dataframe
2025-07-11 10:14:21,492:INFO:Initializing Ada Boost Classifier
2025-07-11 10:14:21,492:INFO:Total runtime is 1.0208484729131062 minutes
2025-07-11 10:14:21,500:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:21,501:INFO:Initializing create_model()
2025-07-11 10:14:21,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:21,502:INFO:Checking exceptions
2025-07-11 10:14:21,502:INFO:Importing libraries
2025-07-11 10:14:21,502:INFO:Copying training dataset
2025-07-11 10:14:21,551:INFO:Defining folds
2025-07-11 10:14:21,551:INFO:Declaring metric variables
2025-07-11 10:14:21,561:INFO:Importing untrained model
2025-07-11 10:14:21,570:INFO:Ada Boost Classifier Imported successfully
2025-07-11 10:14:21,595:INFO:Starting cross validation
2025-07-11 10:14:21,602:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:23,065:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-11 10:14:23,138:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-11 10:14:23,209:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-11 10:14:23,239:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-11 10:14:29,532:INFO:Calculating mean and std
2025-07-11 10:14:29,532:INFO:Creating metrics dataframe
2025-07-11 10:14:29,542:INFO:Uploading results into container
2025-07-11 10:14:29,542:INFO:Uploading model into container now
2025-07-11 10:14:29,542:INFO:_master_model_container: 9
2025-07-11 10:14:29,542:INFO:_display_container: 2
2025-07-11 10:14:29,542:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6840)
2025-07-11 10:14:29,542:INFO:create_model() successfully completed......................................
2025-07-11 10:14:29,724:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:29,724:INFO:Creating metrics dataframe
2025-07-11 10:14:29,751:INFO:Initializing Gradient Boosting Classifier
2025-07-11 10:14:29,751:INFO:Total runtime is 1.1584846337636312 minutes
2025-07-11 10:14:29,757:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:29,757:INFO:Initializing create_model()
2025-07-11 10:14:29,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:29,757:INFO:Checking exceptions
2025-07-11 10:14:29,757:INFO:Importing libraries
2025-07-11 10:14:29,757:INFO:Copying training dataset
2025-07-11 10:14:29,822:INFO:Defining folds
2025-07-11 10:14:29,822:INFO:Declaring metric variables
2025-07-11 10:14:29,837:INFO:Importing untrained model
2025-07-11 10:14:29,848:INFO:Gradient Boosting Classifier Imported successfully
2025-07-11 10:14:29,874:INFO:Starting cross validation
2025-07-11 10:14:29,876:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:52,498:INFO:Calculating mean and std
2025-07-11 10:14:52,498:INFO:Creating metrics dataframe
2025-07-11 10:14:52,498:INFO:Uploading results into container
2025-07-11 10:14:52,498:INFO:Uploading model into container now
2025-07-11 10:14:52,498:INFO:_master_model_container: 10
2025-07-11 10:14:52,498:INFO:_display_container: 2
2025-07-11 10:14:52,509:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-11 10:14:52,511:INFO:create_model() successfully completed......................................
2025-07-11 10:14:52,684:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:52,684:INFO:Creating metrics dataframe
2025-07-11 10:14:52,715:INFO:Initializing Linear Discriminant Analysis
2025-07-11 10:14:52,715:INFO:Total runtime is 1.541224225362142 minutes
2025-07-11 10:14:52,731:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:52,731:INFO:Initializing create_model()
2025-07-11 10:14:52,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:52,731:INFO:Checking exceptions
2025-07-11 10:14:52,733:INFO:Importing libraries
2025-07-11 10:14:52,733:INFO:Copying training dataset
2025-07-11 10:14:52,779:INFO:Defining folds
2025-07-11 10:14:52,779:INFO:Declaring metric variables
2025-07-11 10:14:52,788:INFO:Importing untrained model
2025-07-11 10:14:52,794:INFO:Linear Discriminant Analysis Imported successfully
2025-07-11 10:14:52,806:INFO:Starting cross validation
2025-07-11 10:14:52,822:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:14:54,932:INFO:Calculating mean and std
2025-07-11 10:14:54,934:INFO:Creating metrics dataframe
2025-07-11 10:14:54,934:INFO:Uploading results into container
2025-07-11 10:14:54,942:INFO:Uploading model into container now
2025-07-11 10:14:54,942:INFO:_master_model_container: 11
2025-07-11 10:14:54,942:INFO:_display_container: 2
2025-07-11 10:14:54,942:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-11 10:14:54,945:INFO:create_model() successfully completed......................................
2025-07-11 10:14:55,130:INFO:SubProcess create_model() end ==================================
2025-07-11 10:14:55,130:INFO:Creating metrics dataframe
2025-07-11 10:14:55,152:INFO:Initializing Extra Trees Classifier
2025-07-11 10:14:55,152:INFO:Total runtime is 1.5818454106648763 minutes
2025-07-11 10:14:55,175:INFO:SubProcess create_model() called ==================================
2025-07-11 10:14:55,176:INFO:Initializing create_model()
2025-07-11 10:14:55,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:14:55,177:INFO:Checking exceptions
2025-07-11 10:14:55,177:INFO:Importing libraries
2025-07-11 10:14:55,177:INFO:Copying training dataset
2025-07-11 10:14:55,212:INFO:Defining folds
2025-07-11 10:14:55,212:INFO:Declaring metric variables
2025-07-11 10:14:55,225:INFO:Importing untrained model
2025-07-11 10:14:55,229:INFO:Extra Trees Classifier Imported successfully
2025-07-11 10:14:55,252:INFO:Starting cross validation
2025-07-11 10:14:55,261:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:15:04,788:INFO:Calculating mean and std
2025-07-11 10:15:04,788:INFO:Creating metrics dataframe
2025-07-11 10:15:04,803:INFO:Uploading results into container
2025-07-11 10:15:04,803:INFO:Uploading model into container now
2025-07-11 10:15:04,803:INFO:_master_model_container: 12
2025-07-11 10:15:04,803:INFO:_display_container: 2
2025-07-11 10:15:04,803:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6840, verbose=0,
                     warm_start=False)
2025-07-11 10:15:04,803:INFO:create_model() successfully completed......................................
2025-07-11 10:15:05,003:INFO:SubProcess create_model() end ==================================
2025-07-11 10:15:05,003:INFO:Creating metrics dataframe
2025-07-11 10:15:05,019:INFO:Initializing Light Gradient Boosting Machine
2025-07-11 10:15:05,019:INFO:Total runtime is 1.7462929646174112 minutes
2025-07-11 10:15:05,035:INFO:SubProcess create_model() called ==================================
2025-07-11 10:15:05,036:INFO:Initializing create_model()
2025-07-11 10:15:05,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:15:05,036:INFO:Checking exceptions
2025-07-11 10:15:05,036:INFO:Importing libraries
2025-07-11 10:15:05,036:INFO:Copying training dataset
2025-07-11 10:15:05,071:INFO:Defining folds
2025-07-11 10:15:05,071:INFO:Declaring metric variables
2025-07-11 10:15:05,088:INFO:Importing untrained model
2025-07-11 10:15:05,097:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-11 10:15:05,117:INFO:Starting cross validation
2025-07-11 10:15:05,117:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:15:09,661:INFO:Calculating mean and std
2025-07-11 10:15:09,664:INFO:Creating metrics dataframe
2025-07-11 10:15:09,669:INFO:Uploading results into container
2025-07-11 10:15:09,670:INFO:Uploading model into container now
2025-07-11 10:15:09,671:INFO:_master_model_container: 13
2025-07-11 10:15:09,672:INFO:_display_container: 2
2025-07-11 10:15:09,672:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6840, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-11 10:15:09,672:INFO:create_model() successfully completed......................................
2025-07-11 10:15:09,911:INFO:SubProcess create_model() end ==================================
2025-07-11 10:15:09,911:INFO:Creating metrics dataframe
2025-07-11 10:15:09,931:INFO:Initializing Dummy Classifier
2025-07-11 10:15:09,931:INFO:Total runtime is 1.8281561414400735 minutes
2025-07-11 10:15:09,931:INFO:SubProcess create_model() called ==================================
2025-07-11 10:15:09,939:INFO:Initializing create_model()
2025-07-11 10:15:09,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D3D3626B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:15:09,939:INFO:Checking exceptions
2025-07-11 10:15:09,939:INFO:Importing libraries
2025-07-11 10:15:09,939:INFO:Copying training dataset
2025-07-11 10:15:09,971:INFO:Defining folds
2025-07-11 10:15:09,971:INFO:Declaring metric variables
2025-07-11 10:15:09,976:INFO:Importing untrained model
2025-07-11 10:15:09,988:INFO:Dummy Classifier Imported successfully
2025-07-11 10:15:10,001:INFO:Starting cross validation
2025-07-11 10:15:10,001:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2025-07-11 10:15:11,475:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:15:11,497:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:15:11,517:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:15:11,535:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-11 10:15:11,547:INFO:Calculating mean and std
2025-07-11 10:15:11,547:INFO:Creating metrics dataframe
2025-07-11 10:15:11,555:INFO:Uploading results into container
2025-07-11 10:15:11,555:INFO:Uploading model into container now
2025-07-11 10:15:11,555:INFO:_master_model_container: 14
2025-07-11 10:15:11,555:INFO:_display_container: 2
2025-07-11 10:15:11,555:INFO:DummyClassifier(constant=None, random_state=6840, strategy='prior')
2025-07-11 10:15:11,555:INFO:create_model() successfully completed......................................
2025-07-11 10:15:11,716:INFO:SubProcess create_model() end ==================================
2025-07-11 10:15:11,716:INFO:Creating metrics dataframe
2025-07-11 10:15:11,755:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-11 10:15:11,771:INFO:Initializing create_model()
2025-07-11 10:15:11,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-11 10:15:11,772:INFO:Checking exceptions
2025-07-11 10:15:11,772:INFO:Importing libraries
2025-07-11 10:15:11,772:INFO:Copying training dataset
2025-07-11 10:15:11,848:INFO:Defining folds
2025-07-11 10:15:11,848:INFO:Declaring metric variables
2025-07-11 10:15:11,848:INFO:Importing untrained model
2025-07-11 10:15:11,848:INFO:Declaring custom model
2025-07-11 10:15:11,849:INFO:Gradient Boosting Classifier Imported successfully
2025-07-11 10:15:11,852:INFO:Cross validation set to False
2025-07-11 10:15:11,852:INFO:Fitting Model
2025-07-11 10:15:28,819:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-11 10:15:28,819:INFO:create_model() successfully completed......................................
2025-07-11 10:15:29,035:INFO:_master_model_container: 14
2025-07-11 10:15:29,036:INFO:_display_container: 2
2025-07-11 10:15:29,037:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-11 10:15:29,037:INFO:compare_models() successfully completed......................................
2025-07-11 10:15:33,476:INFO:Initializing plot_model()
2025-07-11 10:15:33,476:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-11 10:15:33,477:INFO:Checking exceptions
2025-07-11 10:15:33,497:INFO:Preloading libraries
2025-07-11 10:15:33,523:INFO:Copying training dataset
2025-07-11 10:15:33,523:INFO:Plot type: feature
2025-07-11 10:15:33,524:WARNING:No coef_ found. Trying feature_importances_
2025-07-11 10:15:33,921:INFO:Visual Rendered Successfully
2025-07-11 10:15:34,068:INFO:plot_model() successfully completed......................................
2025-07-11 10:15:34,280:INFO:Initializing plot_model()
2025-07-11 10:15:34,296:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D3CEEF14D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-11 10:15:34,296:INFO:Checking exceptions
2025-07-11 10:15:34,322:INFO:Preloading libraries
2025-07-11 10:15:34,348:INFO:Copying training dataset
2025-07-11 10:15:34,348:INFO:Plot type: auc
2025-07-11 10:15:34,586:INFO:Fitting Model
2025-07-11 10:15:34,588:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-07-11 10:15:34,589:INFO:Scoring test/hold-out set
2025-07-11 10:15:34,941:INFO:Visual Rendered Successfully
2025-07-11 10:15:35,110:INFO:plot_model() successfully completed......................................
2025-07-11 10:15:39,020:INFO:Initializing save_model()
2025-07-11 10:15:39,020:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=LR Model Aula 5 062022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=QuantileTransformer(copy=True,
                                                                    ignore_implicit_zeros=False,
                                                                    n_quantiles=1000,
                                                                    output_distribution='normal',
                                                                    random_state=6840,
                                                                    subsample=10000))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-11 10:15:39,021:INFO:Adding model into prep_pipe
2025-07-11 10:15:39,047:INFO:LR Model Aula 5 062022.pkl saved in current working directory
2025-07-11 10:15:39,097:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=6840, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-11 10:15:39,097:INFO:save_model() successfully completed......................................
2025-07-11 10:15:40,927:INFO:Initializing load_model()
2025-07-11 10:15:40,928:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2025-07-11 10:15:47,193:INFO:PyCaret ClassificationExperiment
2025-07-11 10:15:47,193:INFO:Logging name: clf-default-name
2025-07-11 10:15:47,193:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-11 10:15:47,193:INFO:version 3.3.2
2025-07-11 10:15:47,193:INFO:Initializing setup()
2025-07-11 10:15:47,193:INFO:self.USI: 5b76
2025-07-11 10:15:47,193:INFO:self._variable_keys: {'USI', 'X_train', 'is_multiclass', 'seed', '_ml_usecase', 'exp_id', 'log_plots_param', 'idx', 'gpu_n_jobs_param', 'X_test', 'fix_imbalance', 'n_jobs_param', 'exp_name_log', 'y', 'target_param', 'y_test', 'data', '_available_plots', 'gpu_param', 'y_train', 'html_param', 'logging_param', 'fold_groups_param', 'X', 'fold_generator', 'memory', 'fold_shuffle_param', 'pipeline'}
2025-07-11 10:15:47,194:INFO:Checking environment
2025-07-11 10:15:47,194:INFO:python_version: 3.11.7
2025-07-11 10:15:47,194:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-11 10:15:47,194:INFO:machine: AMD64
2025-07-11 10:15:47,194:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-11 10:15:47,194:INFO:Memory: svmem(total=12698038272, available=5193342976, percent=59.1, used=7504695296, free=5193342976)
2025-07-11 10:15:47,194:INFO:Physical Core: 2
2025-07-11 10:15:47,194:INFO:Logical Core: 4
2025-07-11 10:15:47,195:INFO:Checking libraries
2025-07-11 10:15:47,195:INFO:System:
2025-07-11 10:15:47,195:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-11 10:15:47,195:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-11 10:15:47,195:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-11 10:15:47,195:INFO:PyCaret required dependencies:
2025-07-11 10:15:47,195:INFO:                 pip: 23.3.1
2025-07-11 10:15:47,195:INFO:          setuptools: 68.2.2
2025-07-11 10:15:47,196:INFO:             pycaret: 3.3.2
2025-07-11 10:15:47,196:INFO:             IPython: 8.20.0
2025-07-11 10:15:47,196:INFO:          ipywidgets: 7.7.2
2025-07-11 10:15:47,196:INFO:                tqdm: 4.65.0
2025-07-11 10:15:47,196:INFO:               numpy: 1.26.4
2025-07-11 10:15:47,196:INFO:              pandas: 2.1.4
2025-07-11 10:15:47,196:INFO:              jinja2: 3.1.3
2025-07-11 10:15:47,196:INFO:               scipy: 1.11.4
2025-07-11 10:15:47,196:INFO:              joblib: 1.2.0
2025-07-11 10:15:47,196:INFO:             sklearn: 1.4.2
2025-07-11 10:15:47,196:INFO:                pyod: 2.0.5
2025-07-11 10:15:47,196:INFO:            imblearn: 0.13.0
2025-07-11 10:15:47,196:INFO:   category_encoders: 2.7.0
2025-07-11 10:15:47,196:INFO:            lightgbm: 4.6.0
2025-07-11 10:15:47,196:INFO:               numba: 0.59.0
2025-07-11 10:15:47,196:INFO:            requests: 2.31.0
2025-07-11 10:15:47,196:INFO:          matplotlib: 3.7.5
2025-07-11 10:15:47,196:INFO:          scikitplot: 0.3.7
2025-07-11 10:15:47,196:INFO:         yellowbrick: 1.5
2025-07-11 10:15:47,196:INFO:              plotly: 5.24.1
2025-07-11 10:15:47,196:INFO:    plotly-resampler: Not installed
2025-07-11 10:15:47,196:INFO:             kaleido: 1.0.0
2025-07-11 10:15:47,196:INFO:           schemdraw: 0.15
2025-07-11 10:15:47,196:INFO:         statsmodels: 0.14.0
2025-07-11 10:15:47,196:INFO:              sktime: 0.26.0
2025-07-11 10:15:47,196:INFO:               tbats: 1.1.3
2025-07-11 10:15:47,196:INFO:            pmdarima: 2.0.4
2025-07-11 10:15:47,196:INFO:              psutil: 5.9.0
2025-07-11 10:15:47,196:INFO:          markupsafe: 2.1.3
2025-07-11 10:15:47,196:INFO:             pickle5: Not installed
2025-07-11 10:15:47,196:INFO:         cloudpickle: 2.2.1
2025-07-11 10:15:47,196:INFO:         deprecation: 2.1.0
2025-07-11 10:15:47,196:INFO:              xxhash: 3.5.0
2025-07-11 10:15:47,196:INFO:           wurlitzer: Not installed
2025-07-11 10:15:47,196:INFO:PyCaret optional dependencies:
2025-07-11 10:15:47,196:INFO:                shap: Not installed
2025-07-11 10:15:47,196:INFO:           interpret: Not installed
2025-07-11 10:15:47,196:INFO:                umap: Not installed
2025-07-11 10:15:47,196:INFO:     ydata_profiling: 4.7.0
2025-07-11 10:15:47,196:INFO:  explainerdashboard: Not installed
2025-07-11 10:15:47,196:INFO:             autoviz: Not installed
2025-07-11 10:15:47,196:INFO:           fairlearn: Not installed
2025-07-11 10:15:47,196:INFO:          deepchecks: Not installed
2025-07-11 10:15:47,196:INFO:             xgboost: Not installed
2025-07-11 10:15:47,196:INFO:            catboost: Not installed
2025-07-11 10:15:47,196:INFO:              kmodes: Not installed
2025-07-11 10:15:47,196:INFO:             mlxtend: Not installed
2025-07-11 10:15:47,196:INFO:       statsforecast: Not installed
2025-07-11 10:15:47,196:INFO:        tune_sklearn: Not installed
2025-07-11 10:15:47,196:INFO:                 ray: Not installed
2025-07-11 10:15:47,196:INFO:            hyperopt: Not installed
2025-07-11 10:15:47,196:INFO:              optuna: Not installed
2025-07-11 10:15:47,196:INFO:               skopt: Not installed
2025-07-11 10:15:47,196:INFO:              mlflow: Not installed
2025-07-11 10:15:47,196:INFO:              gradio: Not installed
2025-07-11 10:15:47,196:INFO:             fastapi: Not installed
2025-07-11 10:15:47,196:INFO:             uvicorn: Not installed
2025-07-11 10:15:47,196:INFO:              m2cgen: Not installed
2025-07-11 10:15:47,196:INFO:           evidently: Not installed
2025-07-11 10:15:47,196:INFO:               fugue: Not installed
2025-07-11 10:15:47,196:INFO:           streamlit: 1.46.1
2025-07-11 10:15:47,196:INFO:             prophet: Not installed
2025-07-11 10:15:47,196:INFO:None
2025-07-11 10:15:47,196:INFO:Set up data.
2025-07-11 10:15:47,250:INFO:Set up folding strategy.
2025-07-11 10:15:47,250:INFO:Set up train/test split.
2025-07-11 10:15:47,277:INFO:Set up index.
2025-07-11 10:15:47,278:INFO:Assigning column types.
2025-07-11 10:15:47,288:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-11 10:15:47,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:15:47,391:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:15:47,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-11 10:15:47,576:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:15:47,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,639:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-11 10:15:47,752:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:15:47,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:47,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-11 10:15:48,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,014:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-11 10:15:48,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:48,380:INFO:Preparing preprocessing pipeline...
2025-07-11 10:15:48,382:INFO:Set up simple imputation.
2025-07-11 10:15:48,395:INFO:Set up encoding of ordinal features.
2025-07-11 10:15:48,407:INFO:Set up encoding of categorical features.
2025-07-11 10:15:48,407:INFO:Set up removing multicollinearity.
2025-07-11 10:15:48,408:INFO:Set up binning of numerical features.
2025-07-11 10:15:48,410:INFO:Set up column transformation.
2025-07-11 10:15:48,410:INFO:Set up feature normalization.
2025-07-11 10:15:49,063:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-07-11 10:15:50,017:INFO:Finished creating preprocessing pipeline.
2025-07-11 10:15:50,051:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                                 n_bins=5,
                                                                 random_state=None,
                                                                 strategy='kmeans',
                                                                 subsample='warn'))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-07-11 10:15:50,051:INFO:Creating final display dataframe.
2025-07-11 10:15:51,060:INFO:Setup _display_container:                     Description             Value
0                    Session id              1360
1                        Target               mau
2                   Target type            Binary
3           Original data shape       (38000, 13)
4        Transformed data shape       (38000, 30)
5   Transformed train set shape       (26600, 30)
6    Transformed test set shape       (11400, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.4%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              5b76
2025-07-11 10:15:51,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:51,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:51,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:51,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-11 10:15:51,438:INFO:setup() successfully completed in 4.27s...............
2025-07-12 11:51:11,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-12 11:51:11,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-12 11:51:11,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-12 11:51:11,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-12 11:55:05,841:INFO:PyCaret ClassificationExperiment
2025-07-12 11:55:05,842:INFO:Logging name: clf-default-name
2025-07-12 11:55:05,842:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-12 11:55:05,842:INFO:version 3.3.2
2025-07-12 11:55:05,842:INFO:Initializing setup()
2025-07-12 11:55:05,842:INFO:self.USI: 5230
2025-07-12 11:55:05,842:INFO:self._variable_keys: {'y', 'is_multiclass', 'X_test', 'html_param', 'logging_param', 'fold_groups_param', 'seed', 'X', 'log_plots_param', 'y_train', 'fold_shuffle_param', 'memory', 'pipeline', '_available_plots', 'gpu_n_jobs_param', 'y_test', '_ml_usecase', 'fold_generator', 'idx', 'exp_name_log', 'target_param', 'USI', 'gpu_param', 'X_train', 'n_jobs_param', 'exp_id', 'data', 'fix_imbalance'}
2025-07-12 11:55:05,842:INFO:Checking environment
2025-07-12 11:55:05,842:INFO:python_version: 3.11.7
2025-07-12 11:55:05,842:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-12 11:55:05,843:INFO:machine: AMD64
2025-07-12 11:55:05,843:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-12 11:55:05,843:INFO:Memory: svmem(total=12698038272, available=6538186752, percent=48.5, used=6159851520, free=6538186752)
2025-07-12 11:55:05,843:INFO:Physical Core: 2
2025-07-12 11:55:05,843:INFO:Logical Core: 4
2025-07-12 11:55:05,843:INFO:Checking libraries
2025-07-12 11:55:05,843:INFO:System:
2025-07-12 11:55:05,843:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-12 11:55:05,843:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-12 11:55:05,843:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-12 11:55:05,844:INFO:PyCaret required dependencies:
2025-07-12 11:55:07,621:INFO:                 pip: 23.3.1
2025-07-12 11:55:07,621:INFO:          setuptools: 68.2.2
2025-07-12 11:55:07,621:INFO:             pycaret: 3.3.2
2025-07-12 11:55:07,621:INFO:             IPython: 8.20.0
2025-07-12 11:55:07,621:INFO:          ipywidgets: 7.7.2
2025-07-12 11:55:07,621:INFO:                tqdm: 4.65.0
2025-07-12 11:55:07,621:INFO:               numpy: 1.26.4
2025-07-12 11:55:07,621:INFO:              pandas: 2.1.4
2025-07-12 11:55:07,621:INFO:              jinja2: 3.1.3
2025-07-12 11:55:07,621:INFO:               scipy: 1.11.4
2025-07-12 11:55:07,621:INFO:              joblib: 1.2.0
2025-07-12 11:55:07,621:INFO:             sklearn: 1.4.2
2025-07-12 11:55:07,621:INFO:                pyod: 2.0.5
2025-07-12 11:55:07,621:INFO:            imblearn: 0.13.0
2025-07-12 11:55:07,621:INFO:   category_encoders: 2.7.0
2025-07-12 11:55:07,621:INFO:            lightgbm: 4.6.0
2025-07-12 11:55:07,621:INFO:               numba: 0.59.0
2025-07-12 11:55:07,621:INFO:            requests: 2.31.0
2025-07-12 11:55:07,621:INFO:          matplotlib: 3.7.5
2025-07-12 11:55:07,621:INFO:          scikitplot: 0.3.7
2025-07-12 11:55:07,621:INFO:         yellowbrick: 1.5
2025-07-12 11:55:07,621:INFO:              plotly: 5.24.1
2025-07-12 11:55:07,621:INFO:    plotly-resampler: Not installed
2025-07-12 11:55:07,621:INFO:             kaleido: 1.0.0
2025-07-12 11:55:07,621:INFO:           schemdraw: 0.15
2025-07-12 11:55:07,621:INFO:         statsmodels: 0.14.0
2025-07-12 11:55:07,621:INFO:              sktime: 0.26.0
2025-07-12 11:55:07,621:INFO:               tbats: 1.1.3
2025-07-12 11:55:07,621:INFO:            pmdarima: 2.0.4
2025-07-12 11:55:07,621:INFO:              psutil: 5.9.0
2025-07-12 11:55:07,621:INFO:          markupsafe: 2.1.3
2025-07-12 11:55:07,621:INFO:             pickle5: Not installed
2025-07-12 11:55:07,621:INFO:         cloudpickle: 2.2.1
2025-07-12 11:55:07,621:INFO:         deprecation: 2.1.0
2025-07-12 11:55:07,621:INFO:              xxhash: 3.5.0
2025-07-12 11:55:07,621:INFO:           wurlitzer: Not installed
2025-07-12 11:55:07,621:INFO:PyCaret optional dependencies:
2025-07-12 11:55:07,638:INFO:                shap: Not installed
2025-07-12 11:55:07,653:INFO:           interpret: Not installed
2025-07-12 11:55:07,653:INFO:                umap: Not installed
2025-07-12 11:55:07,653:INFO:     ydata_profiling: 4.7.0
2025-07-12 11:55:07,653:INFO:  explainerdashboard: Not installed
2025-07-12 11:55:07,653:INFO:             autoviz: Not installed
2025-07-12 11:55:07,653:INFO:           fairlearn: Not installed
2025-07-12 11:55:07,653:INFO:          deepchecks: Not installed
2025-07-12 11:55:07,653:INFO:             xgboost: Not installed
2025-07-12 11:55:07,653:INFO:            catboost: Not installed
2025-07-12 11:55:07,653:INFO:              kmodes: Not installed
2025-07-12 11:55:07,653:INFO:             mlxtend: Not installed
2025-07-12 11:55:07,653:INFO:       statsforecast: Not installed
2025-07-12 11:55:07,654:INFO:        tune_sklearn: Not installed
2025-07-12 11:55:07,654:INFO:                 ray: Not installed
2025-07-12 11:55:07,654:INFO:            hyperopt: Not installed
2025-07-12 11:55:07,654:INFO:              optuna: Not installed
2025-07-12 11:55:07,654:INFO:               skopt: Not installed
2025-07-12 11:55:07,654:INFO:              mlflow: Not installed
2025-07-12 11:55:07,654:INFO:              gradio: Not installed
2025-07-12 11:55:07,654:INFO:             fastapi: Not installed
2025-07-12 11:55:07,654:INFO:             uvicorn: Not installed
2025-07-12 11:55:07,654:INFO:              m2cgen: Not installed
2025-07-12 11:55:07,654:INFO:           evidently: Not installed
2025-07-12 11:55:07,655:INFO:               fugue: Not installed
2025-07-12 11:55:07,655:INFO:           streamlit: 1.46.1
2025-07-12 11:55:07,655:INFO:             prophet: Not installed
2025-07-12 11:55:07,655:INFO:None
2025-07-12 11:55:07,655:INFO:Set up data.
2025-07-12 11:55:07,673:INFO:Set up folding strategy.
2025-07-12 11:55:07,673:INFO:Set up train/test split.
2025-07-12 11:55:07,687:INFO:Set up index.
2025-07-12 11:55:07,687:INFO:Assigning column types.
2025-07-12 11:55:07,693:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-12 11:55:07,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-12 11:55:07,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 11:55:07,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:07,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-12 11:55:08,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 11:55:08,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-12 11:55:08,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 11:55:08,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,448:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 11:55:08,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,506:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-12 11:55:08,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:08,865:INFO:Preparing preprocessing pipeline...
2025-07-12 11:55:08,865:INFO:Set up simple imputation.
2025-07-12 11:55:08,880:INFO:Set up encoding of ordinal features.
2025-07-12 11:55:08,880:INFO:Set up encoding of categorical features.
2025-07-12 11:55:09,128:INFO:Finished creating preprocessing pipeline.
2025-07-12 11:55:09,190:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-12 11:55:09,190:INFO:Creating final display dataframe.
2025-07-12 11:55:09,846:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5230
2025-07-12 11:55:10,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:10,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:10,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:10,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 11:55:10,253:INFO:setup() successfully completed in 4.44s...............
2025-07-12 12:04:09,119:INFO:PyCaret ClassificationExperiment
2025-07-12 12:04:09,119:INFO:Logging name: clf-default-name
2025-07-12 12:04:09,119:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-12 12:04:09,119:INFO:version 3.3.2
2025-07-12 12:04:09,119:INFO:Initializing setup()
2025-07-12 12:04:09,119:INFO:self.USI: fc7c
2025-07-12 12:04:09,119:INFO:self._variable_keys: {'y', 'is_multiclass', 'X_test', 'html_param', 'logging_param', 'fold_groups_param', 'seed', 'X', 'log_plots_param', 'y_train', 'fold_shuffle_param', 'memory', 'pipeline', '_available_plots', 'gpu_n_jobs_param', 'y_test', '_ml_usecase', 'fold_generator', 'idx', 'exp_name_log', 'target_param', 'USI', 'gpu_param', 'X_train', 'n_jobs_param', 'exp_id', 'data', 'fix_imbalance'}
2025-07-12 12:04:09,119:INFO:Checking environment
2025-07-12 12:04:09,119:INFO:python_version: 3.11.7
2025-07-12 12:04:09,119:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-12 12:04:09,119:INFO:machine: AMD64
2025-07-12 12:04:09,119:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-12 12:04:09,119:INFO:Memory: svmem(total=12698038272, available=6579572736, percent=48.2, used=6118465536, free=6579572736)
2025-07-12 12:04:09,119:INFO:Physical Core: 2
2025-07-12 12:04:09,119:INFO:Logical Core: 4
2025-07-12 12:04:09,119:INFO:Checking libraries
2025-07-12 12:04:09,119:INFO:System:
2025-07-12 12:04:09,119:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-12 12:04:09,119:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-12 12:04:09,119:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-12 12:04:09,119:INFO:PyCaret required dependencies:
2025-07-12 12:04:09,119:INFO:                 pip: 23.3.1
2025-07-12 12:04:09,119:INFO:          setuptools: 68.2.2
2025-07-12 12:04:09,119:INFO:             pycaret: 3.3.2
2025-07-12 12:04:09,119:INFO:             IPython: 8.20.0
2025-07-12 12:04:09,119:INFO:          ipywidgets: 7.7.2
2025-07-12 12:04:09,119:INFO:                tqdm: 4.65.0
2025-07-12 12:04:09,119:INFO:               numpy: 1.26.4
2025-07-12 12:04:09,119:INFO:              pandas: 2.1.4
2025-07-12 12:04:09,119:INFO:              jinja2: 3.1.3
2025-07-12 12:04:09,119:INFO:               scipy: 1.11.4
2025-07-12 12:04:09,119:INFO:              joblib: 1.2.0
2025-07-12 12:04:09,119:INFO:             sklearn: 1.4.2
2025-07-12 12:04:09,119:INFO:                pyod: 2.0.5
2025-07-12 12:04:09,119:INFO:            imblearn: 0.13.0
2025-07-12 12:04:09,119:INFO:   category_encoders: 2.7.0
2025-07-12 12:04:09,119:INFO:            lightgbm: 4.6.0
2025-07-12 12:04:09,119:INFO:               numba: 0.59.0
2025-07-12 12:04:09,119:INFO:            requests: 2.31.0
2025-07-12 12:04:09,119:INFO:          matplotlib: 3.7.5
2025-07-12 12:04:09,119:INFO:          scikitplot: 0.3.7
2025-07-12 12:04:09,119:INFO:         yellowbrick: 1.5
2025-07-12 12:04:09,119:INFO:              plotly: 5.24.1
2025-07-12 12:04:09,119:INFO:    plotly-resampler: Not installed
2025-07-12 12:04:09,119:INFO:             kaleido: 1.0.0
2025-07-12 12:04:09,119:INFO:           schemdraw: 0.15
2025-07-12 12:04:09,119:INFO:         statsmodels: 0.14.0
2025-07-12 12:04:09,119:INFO:              sktime: 0.26.0
2025-07-12 12:04:09,119:INFO:               tbats: 1.1.3
2025-07-12 12:04:09,119:INFO:            pmdarima: 2.0.4
2025-07-12 12:04:09,119:INFO:              psutil: 5.9.0
2025-07-12 12:04:09,119:INFO:          markupsafe: 2.1.3
2025-07-12 12:04:09,132:INFO:             pickle5: Not installed
2025-07-12 12:04:09,132:INFO:         cloudpickle: 2.2.1
2025-07-12 12:04:09,132:INFO:         deprecation: 2.1.0
2025-07-12 12:04:09,132:INFO:              xxhash: 3.5.0
2025-07-12 12:04:09,133:INFO:           wurlitzer: Not installed
2025-07-12 12:04:09,133:INFO:PyCaret optional dependencies:
2025-07-12 12:04:09,133:INFO:                shap: Not installed
2025-07-12 12:04:09,133:INFO:           interpret: Not installed
2025-07-12 12:04:09,133:INFO:                umap: Not installed
2025-07-12 12:04:09,133:INFO:     ydata_profiling: 4.7.0
2025-07-12 12:04:09,133:INFO:  explainerdashboard: Not installed
2025-07-12 12:04:09,134:INFO:             autoviz: Not installed
2025-07-12 12:04:09,134:INFO:           fairlearn: Not installed
2025-07-12 12:04:09,134:INFO:          deepchecks: Not installed
2025-07-12 12:04:09,134:INFO:             xgboost: Not installed
2025-07-12 12:04:09,134:INFO:            catboost: Not installed
2025-07-12 12:04:09,134:INFO:              kmodes: Not installed
2025-07-12 12:04:09,135:INFO:             mlxtend: Not installed
2025-07-12 12:04:09,135:INFO:       statsforecast: Not installed
2025-07-12 12:04:09,135:INFO:        tune_sklearn: Not installed
2025-07-12 12:04:09,135:INFO:                 ray: Not installed
2025-07-12 12:04:09,136:INFO:            hyperopt: Not installed
2025-07-12 12:04:09,136:INFO:              optuna: Not installed
2025-07-12 12:04:09,136:INFO:               skopt: Not installed
2025-07-12 12:04:09,136:INFO:              mlflow: Not installed
2025-07-12 12:04:09,136:INFO:              gradio: Not installed
2025-07-12 12:04:09,136:INFO:             fastapi: Not installed
2025-07-12 12:04:09,136:INFO:             uvicorn: Not installed
2025-07-12 12:04:09,137:INFO:              m2cgen: Not installed
2025-07-12 12:04:09,137:INFO:           evidently: Not installed
2025-07-12 12:04:09,137:INFO:               fugue: Not installed
2025-07-12 12:04:09,137:INFO:           streamlit: 1.46.1
2025-07-12 12:04:09,137:INFO:             prophet: Not installed
2025-07-12 12:04:09,138:INFO:None
2025-07-12 12:04:09,138:INFO:Set up data.
2025-07-12 12:04:09,161:INFO:Set up folding strategy.
2025-07-12 12:04:09,161:INFO:Set up train/test split.
2025-07-12 12:04:09,175:INFO:Set up index.
2025-07-12 12:04:09,176:INFO:Assigning column types.
2025-07-12 12:04:09,183:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-12 12:04:09,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-12 12:04:09,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 12:04:09,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:09,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:09,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-12 12:04:09,531:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 12:04:09,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:09,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:09,616:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-12 12:04:09,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 12:04:09,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:09,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-12 12:04:10,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,101:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-12 12:04:10,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:10,564:INFO:Preparing preprocessing pipeline...
2025-07-12 12:04:10,564:INFO:Set up simple imputation.
2025-07-12 12:04:10,580:INFO:Set up encoding of ordinal features.
2025-07-12 12:04:10,586:INFO:Set up encoding of categorical features.
2025-07-12 12:04:10,927:INFO:Finished creating preprocessing pipeline.
2025-07-12 12:04:11,012:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-12 12:04:11,013:INFO:Creating final display dataframe.
2025-07-12 12:04:11,915:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              fc7c
2025-07-12 12:04:12,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:12,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:12,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:12,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:04:12,394:INFO:setup() successfully completed in 3.3s...............
2025-07-12 12:04:52,635:INFO:Initializing compare_models()
2025-07-12 12:04:52,650:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-12 12:04:52,650:INFO:Checking exceptions
2025-07-12 12:04:52,668:INFO:Preparing display monitor
2025-07-12 12:04:52,718:INFO:Initializing Logistic Regression
2025-07-12 12:04:52,718:INFO:Total runtime is 0.0 minutes
2025-07-12 12:04:52,722:INFO:SubProcess create_model() called ==================================
2025-07-12 12:04:52,722:INFO:Initializing create_model()
2025-07-12 12:04:52,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:04:52,722:INFO:Checking exceptions
2025-07-12 12:04:52,722:INFO:Importing libraries
2025-07-12 12:04:52,722:INFO:Copying training dataset
2025-07-12 12:04:52,745:INFO:Defining folds
2025-07-12 12:04:52,746:INFO:Declaring metric variables
2025-07-12 12:04:52,754:INFO:Importing untrained model
2025-07-12 12:04:52,765:INFO:Logistic Regression Imported successfully
2025-07-12 12:04:52,778:INFO:Starting cross validation
2025-07-12 12:04:52,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:12,826:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:12,846:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:12,917:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:12,967:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:12,987:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:13,016:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:13,088:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:13,149:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:15,964:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:16,073:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:16,166:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:16,246:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:16,254:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:16,287:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:16,357:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:16,407:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:18,196:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:18,241:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:05:18,334:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:18,367:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:18,390:INFO:Calculating mean and std
2025-07-12 12:05:18,392:INFO:Creating metrics dataframe
2025-07-12 12:05:18,403:INFO:Uploading results into container
2025-07-12 12:05:18,404:INFO:Uploading model into container now
2025-07-12 12:05:18,405:INFO:_master_model_container: 1
2025-07-12 12:05:18,405:INFO:_display_container: 2
2025-07-12 12:05:18,406:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-12 12:05:18,407:INFO:create_model() successfully completed......................................
2025-07-12 12:05:18,807:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:18,807:INFO:Creating metrics dataframe
2025-07-12 12:05:18,828:INFO:Initializing K Neighbors Classifier
2025-07-12 12:05:18,828:INFO:Total runtime is 0.43515454133351644 minutes
2025-07-12 12:05:18,842:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:18,842:INFO:Initializing create_model()
2025-07-12 12:05:18,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:18,843:INFO:Checking exceptions
2025-07-12 12:05:18,843:INFO:Importing libraries
2025-07-12 12:05:18,844:INFO:Copying training dataset
2025-07-12 12:05:18,865:INFO:Defining folds
2025-07-12 12:05:18,865:INFO:Declaring metric variables
2025-07-12 12:05:18,869:INFO:Importing untrained model
2025-07-12 12:05:18,882:INFO:K Neighbors Classifier Imported successfully
2025-07-12 12:05:18,899:INFO:Starting cross validation
2025-07-12 12:05:18,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:21,125:INFO:Calculating mean and std
2025-07-12 12:05:21,125:INFO:Creating metrics dataframe
2025-07-12 12:05:21,133:INFO:Uploading results into container
2025-07-12 12:05:21,133:INFO:Uploading model into container now
2025-07-12 12:05:21,137:INFO:_master_model_container: 2
2025-07-12 12:05:21,137:INFO:_display_container: 2
2025-07-12 12:05:21,138:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-12 12:05:21,138:INFO:create_model() successfully completed......................................
2025-07-12 12:05:21,391:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:21,391:INFO:Creating metrics dataframe
2025-07-12 12:05:21,406:INFO:Initializing Naive Bayes
2025-07-12 12:05:21,406:INFO:Total runtime is 0.47813065846761066 minutes
2025-07-12 12:05:21,419:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:21,420:INFO:Initializing create_model()
2025-07-12 12:05:21,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:21,420:INFO:Checking exceptions
2025-07-12 12:05:21,420:INFO:Importing libraries
2025-07-12 12:05:21,420:INFO:Copying training dataset
2025-07-12 12:05:21,429:INFO:Defining folds
2025-07-12 12:05:21,429:INFO:Declaring metric variables
2025-07-12 12:05:21,441:INFO:Importing untrained model
2025-07-12 12:05:21,449:INFO:Naive Bayes Imported successfully
2025-07-12 12:05:21,466:INFO:Starting cross validation
2025-07-12 12:05:21,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:21,953:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:21,963:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:21,973:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,477:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,477:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,497:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,801:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,871:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:22,881:INFO:Calculating mean and std
2025-07-12 12:05:22,881:INFO:Creating metrics dataframe
2025-07-12 12:05:22,881:INFO:Uploading results into container
2025-07-12 12:05:22,881:INFO:Uploading model into container now
2025-07-12 12:05:22,889:INFO:_master_model_container: 3
2025-07-12 12:05:22,889:INFO:_display_container: 2
2025-07-12 12:05:22,890:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-12 12:05:22,890:INFO:create_model() successfully completed......................................
2025-07-12 12:05:23,151:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:23,151:INFO:Creating metrics dataframe
2025-07-12 12:05:23,163:INFO:Initializing Decision Tree Classifier
2025-07-12 12:05:23,163:INFO:Total runtime is 0.507414710521698 minutes
2025-07-12 12:05:23,170:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:23,170:INFO:Initializing create_model()
2025-07-12 12:05:23,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:23,171:INFO:Checking exceptions
2025-07-12 12:05:23,171:INFO:Importing libraries
2025-07-12 12:05:23,171:INFO:Copying training dataset
2025-07-12 12:05:23,185:INFO:Defining folds
2025-07-12 12:05:23,185:INFO:Declaring metric variables
2025-07-12 12:05:23,195:INFO:Importing untrained model
2025-07-12 12:05:23,208:INFO:Decision Tree Classifier Imported successfully
2025-07-12 12:05:23,226:INFO:Starting cross validation
2025-07-12 12:05:23,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:24,901:INFO:Calculating mean and std
2025-07-12 12:05:24,903:INFO:Creating metrics dataframe
2025-07-12 12:05:24,906:INFO:Uploading results into container
2025-07-12 12:05:24,908:INFO:Uploading model into container now
2025-07-12 12:05:24,909:INFO:_master_model_container: 4
2025-07-12 12:05:24,909:INFO:_display_container: 2
2025-07-12 12:05:24,911:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-12 12:05:24,911:INFO:create_model() successfully completed......................................
2025-07-12 12:05:25,184:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:25,184:INFO:Creating metrics dataframe
2025-07-12 12:05:25,197:INFO:Initializing SVM - Linear Kernel
2025-07-12 12:05:25,197:INFO:Total runtime is 0.5413102428118387 minutes
2025-07-12 12:05:25,199:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:25,203:INFO:Initializing create_model()
2025-07-12 12:05:25,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:25,204:INFO:Checking exceptions
2025-07-12 12:05:25,204:INFO:Importing libraries
2025-07-12 12:05:25,204:INFO:Copying training dataset
2025-07-12 12:05:25,219:INFO:Defining folds
2025-07-12 12:05:25,220:INFO:Declaring metric variables
2025-07-12 12:05:25,224:INFO:Importing untrained model
2025-07-12 12:05:25,237:INFO:SVM - Linear Kernel Imported successfully
2025-07-12 12:05:25,249:INFO:Starting cross validation
2025-07-12 12:05:25,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:25,859:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:26,437:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:26,471:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:26,524:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:26,912:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:26,964:INFO:Calculating mean and std
2025-07-12 12:05:26,972:INFO:Creating metrics dataframe
2025-07-12 12:05:26,974:INFO:Uploading results into container
2025-07-12 12:05:26,974:INFO:Uploading model into container now
2025-07-12 12:05:26,974:INFO:_master_model_container: 5
2025-07-12 12:05:26,974:INFO:_display_container: 2
2025-07-12 12:05:26,974:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-12 12:05:26,974:INFO:create_model() successfully completed......................................
2025-07-12 12:05:27,288:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:27,288:INFO:Creating metrics dataframe
2025-07-12 12:05:27,316:INFO:Initializing Ridge Classifier
2025-07-12 12:05:27,317:INFO:Total runtime is 0.5766416311264038 minutes
2025-07-12 12:05:27,325:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:27,326:INFO:Initializing create_model()
2025-07-12 12:05:27,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:27,326:INFO:Checking exceptions
2025-07-12 12:05:27,327:INFO:Importing libraries
2025-07-12 12:05:27,327:INFO:Copying training dataset
2025-07-12 12:05:27,357:INFO:Defining folds
2025-07-12 12:05:27,357:INFO:Declaring metric variables
2025-07-12 12:05:27,387:INFO:Importing untrained model
2025-07-12 12:05:27,406:INFO:Ridge Classifier Imported successfully
2025-07-12 12:05:27,420:INFO:Starting cross validation
2025-07-12 12:05:27,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:28,199:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:28,199:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:28,207:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:28,280:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:28,931:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:28,993:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:29,054:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:29,367:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:29,385:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:29,405:INFO:Calculating mean and std
2025-07-12 12:05:29,407:INFO:Creating metrics dataframe
2025-07-12 12:05:29,412:INFO:Uploading results into container
2025-07-12 12:05:29,412:INFO:Uploading model into container now
2025-07-12 12:05:29,412:INFO:_master_model_container: 6
2025-07-12 12:05:29,412:INFO:_display_container: 2
2025-07-12 12:05:29,412:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-12 12:05:29,415:INFO:create_model() successfully completed......................................
2025-07-12 12:05:29,737:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:29,737:INFO:Creating metrics dataframe
2025-07-12 12:05:29,759:INFO:Initializing Random Forest Classifier
2025-07-12 12:05:29,759:INFO:Total runtime is 0.6173423846562703 minutes
2025-07-12 12:05:29,769:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:29,769:INFO:Initializing create_model()
2025-07-12 12:05:29,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:29,771:INFO:Checking exceptions
2025-07-12 12:05:29,771:INFO:Importing libraries
2025-07-12 12:05:29,771:INFO:Copying training dataset
2025-07-12 12:05:29,792:INFO:Defining folds
2025-07-12 12:05:29,792:INFO:Declaring metric variables
2025-07-12 12:05:29,802:INFO:Importing untrained model
2025-07-12 12:05:29,812:INFO:Random Forest Classifier Imported successfully
2025-07-12 12:05:29,830:INFO:Starting cross validation
2025-07-12 12:05:29,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:35,635:INFO:Calculating mean and std
2025-07-12 12:05:35,643:INFO:Creating metrics dataframe
2025-07-12 12:05:35,645:INFO:Uploading results into container
2025-07-12 12:05:35,645:INFO:Uploading model into container now
2025-07-12 12:05:35,645:INFO:_master_model_container: 7
2025-07-12 12:05:35,645:INFO:_display_container: 2
2025-07-12 12:05:35,645:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-12 12:05:35,645:INFO:create_model() successfully completed......................................
2025-07-12 12:05:35,957:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:35,957:INFO:Creating metrics dataframe
2025-07-12 12:05:35,975:INFO:Initializing Quadratic Discriminant Analysis
2025-07-12 12:05:35,975:INFO:Total runtime is 0.7209410548210144 minutes
2025-07-12 12:05:35,986:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:35,987:INFO:Initializing create_model()
2025-07-12 12:05:35,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:35,987:INFO:Checking exceptions
2025-07-12 12:05:35,987:INFO:Importing libraries
2025-07-12 12:05:35,987:INFO:Copying training dataset
2025-07-12 12:05:36,003:INFO:Defining folds
2025-07-12 12:05:36,003:INFO:Declaring metric variables
2025-07-12 12:05:36,011:INFO:Importing untrained model
2025-07-12 12:05:36,023:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-12 12:05:36,037:INFO:Starting cross validation
2025-07-12 12:05:36,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:36,421:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,461:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,479:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,481:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,947:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,965:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:36,997:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:37,007:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:37,340:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:37,388:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:05:37,495:INFO:Calculating mean and std
2025-07-12 12:05:37,497:INFO:Creating metrics dataframe
2025-07-12 12:05:37,501:INFO:Uploading results into container
2025-07-12 12:05:37,502:INFO:Uploading model into container now
2025-07-12 12:05:37,503:INFO:_master_model_container: 8
2025-07-12 12:05:37,503:INFO:_display_container: 2
2025-07-12 12:05:37,503:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-12 12:05:37,503:INFO:create_model() successfully completed......................................
2025-07-12 12:05:37,752:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:37,752:INFO:Creating metrics dataframe
2025-07-12 12:05:37,772:INFO:Initializing Ada Boost Classifier
2025-07-12 12:05:37,772:INFO:Total runtime is 0.7509016235669455 minutes
2025-07-12 12:05:37,780:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:37,781:INFO:Initializing create_model()
2025-07-12 12:05:37,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:37,781:INFO:Checking exceptions
2025-07-12 12:05:37,781:INFO:Importing libraries
2025-07-12 12:05:37,781:INFO:Copying training dataset
2025-07-12 12:05:37,793:INFO:Defining folds
2025-07-12 12:05:37,793:INFO:Declaring metric variables
2025-07-12 12:05:37,802:INFO:Importing untrained model
2025-07-12 12:05:37,812:INFO:Ada Boost Classifier Imported successfully
2025-07-12 12:05:37,827:INFO:Starting cross validation
2025-07-12 12:05:37,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:38,219:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:38,219:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:38,227:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:38,257:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:39,085:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:39,426:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:39,438:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:39,498:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:39,508:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:40,525:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:40,557:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:05:41,159:INFO:Calculating mean and std
2025-07-12 12:05:41,161:INFO:Creating metrics dataframe
2025-07-12 12:05:41,161:INFO:Uploading results into container
2025-07-12 12:05:41,161:INFO:Uploading model into container now
2025-07-12 12:05:41,161:INFO:_master_model_container: 9
2025-07-12 12:05:41,161:INFO:_display_container: 2
2025-07-12 12:05:41,161:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-12 12:05:41,161:INFO:create_model() successfully completed......................................
2025-07-12 12:05:41,413:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:41,413:INFO:Creating metrics dataframe
2025-07-12 12:05:41,431:INFO:Initializing Gradient Boosting Classifier
2025-07-12 12:05:41,431:INFO:Total runtime is 0.8118852217992147 minutes
2025-07-12 12:05:41,442:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:41,442:INFO:Initializing create_model()
2025-07-12 12:05:41,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:41,442:INFO:Checking exceptions
2025-07-12 12:05:41,442:INFO:Importing libraries
2025-07-12 12:05:41,442:INFO:Copying training dataset
2025-07-12 12:05:41,461:INFO:Defining folds
2025-07-12 12:05:41,461:INFO:Declaring metric variables
2025-07-12 12:05:41,468:INFO:Importing untrained model
2025-07-12 12:05:41,479:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:05:41,492:INFO:Starting cross validation
2025-07-12 12:05:41,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:48,682:INFO:Calculating mean and std
2025-07-12 12:05:48,687:INFO:Creating metrics dataframe
2025-07-12 12:05:48,687:INFO:Uploading results into container
2025-07-12 12:05:48,687:INFO:Uploading model into container now
2025-07-12 12:05:48,687:INFO:_master_model_container: 10
2025-07-12 12:05:48,687:INFO:_display_container: 2
2025-07-12 12:05:48,687:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:05:48,687:INFO:create_model() successfully completed......................................
2025-07-12 12:05:48,960:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:48,960:INFO:Creating metrics dataframe
2025-07-12 12:05:48,980:INFO:Initializing Linear Discriminant Analysis
2025-07-12 12:05:48,980:INFO:Total runtime is 0.9376911163330078 minutes
2025-07-12 12:05:48,988:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:48,989:INFO:Initializing create_model()
2025-07-12 12:05:48,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:48,989:INFO:Checking exceptions
2025-07-12 12:05:48,990:INFO:Importing libraries
2025-07-12 12:05:48,990:INFO:Copying training dataset
2025-07-12 12:05:49,008:INFO:Defining folds
2025-07-12 12:05:49,008:INFO:Declaring metric variables
2025-07-12 12:05:49,018:INFO:Importing untrained model
2025-07-12 12:05:49,028:INFO:Linear Discriminant Analysis Imported successfully
2025-07-12 12:05:49,039:INFO:Starting cross validation
2025-07-12 12:05:49,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:49,645:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:50,117:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:50,190:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:50,258:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:50,540:INFO:Calculating mean and std
2025-07-12 12:05:50,542:INFO:Creating metrics dataframe
2025-07-12 12:05:50,542:INFO:Uploading results into container
2025-07-12 12:05:50,542:INFO:Uploading model into container now
2025-07-12 12:05:50,542:INFO:_master_model_container: 11
2025-07-12 12:05:50,542:INFO:_display_container: 2
2025-07-12 12:05:50,548:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-12 12:05:50,549:INFO:create_model() successfully completed......................................
2025-07-12 12:05:50,813:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:50,813:INFO:Creating metrics dataframe
2025-07-12 12:05:50,829:INFO:Initializing Extra Trees Classifier
2025-07-12 12:05:50,829:INFO:Total runtime is 0.9685117363929748 minutes
2025-07-12 12:05:50,843:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:50,843:INFO:Initializing create_model()
2025-07-12 12:05:50,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:50,844:INFO:Checking exceptions
2025-07-12 12:05:50,844:INFO:Importing libraries
2025-07-12 12:05:50,844:INFO:Copying training dataset
2025-07-12 12:05:50,855:INFO:Defining folds
2025-07-12 12:05:50,855:INFO:Declaring metric variables
2025-07-12 12:05:50,862:INFO:Importing untrained model
2025-07-12 12:05:50,873:INFO:Extra Trees Classifier Imported successfully
2025-07-12 12:05:50,879:INFO:Starting cross validation
2025-07-12 12:05:50,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:55,389:INFO:Calculating mean and std
2025-07-12 12:05:55,389:INFO:Creating metrics dataframe
2025-07-12 12:05:55,395:INFO:Uploading results into container
2025-07-12 12:05:55,395:INFO:Uploading model into container now
2025-07-12 12:05:55,395:INFO:_master_model_container: 12
2025-07-12 12:05:55,398:INFO:_display_container: 2
2025-07-12 12:05:55,399:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-12 12:05:55,399:INFO:create_model() successfully completed......................................
2025-07-12 12:05:55,642:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:55,642:INFO:Creating metrics dataframe
2025-07-12 12:05:55,642:INFO:Initializing Light Gradient Boosting Machine
2025-07-12 12:05:55,642:INFO:Total runtime is 1.048735499382019 minutes
2025-07-12 12:05:55,663:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:55,663:INFO:Initializing create_model()
2025-07-12 12:05:55,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:55,664:INFO:Checking exceptions
2025-07-12 12:05:55,664:INFO:Importing libraries
2025-07-12 12:05:55,664:INFO:Copying training dataset
2025-07-12 12:05:55,677:INFO:Defining folds
2025-07-12 12:05:55,678:INFO:Declaring metric variables
2025-07-12 12:05:55,684:INFO:Importing untrained model
2025-07-12 12:05:55,696:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 12:05:55,711:INFO:Starting cross validation
2025-07-12 12:05:55,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:58,224:INFO:Calculating mean and std
2025-07-12 12:05:58,226:INFO:Creating metrics dataframe
2025-07-12 12:05:58,233:INFO:Uploading results into container
2025-07-12 12:05:58,235:INFO:Uploading model into container now
2025-07-12 12:05:58,236:INFO:_master_model_container: 13
2025-07-12 12:05:58,236:INFO:_display_container: 2
2025-07-12 12:05:58,239:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-12 12:05:58,239:INFO:create_model() successfully completed......................................
2025-07-12 12:05:58,506:INFO:SubProcess create_model() end ==================================
2025-07-12 12:05:58,506:INFO:Creating metrics dataframe
2025-07-12 12:05:58,537:INFO:Initializing Dummy Classifier
2025-07-12 12:05:58,537:INFO:Total runtime is 1.0969828963279724 minutes
2025-07-12 12:05:58,546:INFO:SubProcess create_model() called ==================================
2025-07-12 12:05:58,546:INFO:Initializing create_model()
2025-07-12 12:05:58,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1857858D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:05:58,547:INFO:Checking exceptions
2025-07-12 12:05:58,547:INFO:Importing libraries
2025-07-12 12:05:58,547:INFO:Copying training dataset
2025-07-12 12:05:58,565:INFO:Defining folds
2025-07-12 12:05:58,565:INFO:Declaring metric variables
2025-07-12 12:05:58,570:INFO:Importing untrained model
2025-07-12 12:05:58,583:INFO:Dummy Classifier Imported successfully
2025-07-12 12:05:58,602:INFO:Starting cross validation
2025-07-12 12:05:58,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:05:59,081:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,093:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,093:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,123:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,524:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,524:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,557:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,557:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,889:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,919:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:05:59,939:INFO:Calculating mean and std
2025-07-12 12:05:59,939:INFO:Creating metrics dataframe
2025-07-12 12:05:59,948:INFO:Uploading results into container
2025-07-12 12:05:59,949:INFO:Uploading model into container now
2025-07-12 12:05:59,950:INFO:_master_model_container: 14
2025-07-12 12:05:59,950:INFO:_display_container: 2
2025-07-12 12:05:59,950:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-12 12:05:59,951:INFO:create_model() successfully completed......................................
2025-07-12 12:06:00,233:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:00,233:INFO:Creating metrics dataframe
2025-07-12 12:06:00,253:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-07-12 12:06:00,282:INFO:Initializing create_model()
2025-07-12 12:06:00,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:00,282:INFO:Checking exceptions
2025-07-12 12:06:00,286:INFO:Importing libraries
2025-07-12 12:06:00,287:INFO:Copying training dataset
2025-07-12 12:06:00,300:INFO:Defining folds
2025-07-12 12:06:00,300:INFO:Declaring metric variables
2025-07-12 12:06:00,300:INFO:Importing untrained model
2025-07-12 12:06:00,300:INFO:Declaring custom model
2025-07-12 12:06:00,302:INFO:Logistic Regression Imported successfully
2025-07-12 12:06:00,307:INFO:Cross validation set to False
2025-07-12 12:06:00,307:INFO:Fitting Model
2025-07-12 12:06:01,757:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression


2025-07-12 12:06:01,757:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-12 12:06:01,757:INFO:create_model() successfully completed......................................
2025-07-12 12:06:02,064:INFO:_master_model_container: 14
2025-07-12 12:06:02,065:INFO:_display_container: 2
2025-07-12 12:06:02,066:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-12 12:06:02,067:INFO:compare_models() successfully completed......................................
2025-07-12 12:06:15,076:INFO:Initializing compare_models()
2025-07-12 12:06:15,077:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-12 12:06:15,077:INFO:Checking exceptions
2025-07-12 12:06:15,084:INFO:Preparing display monitor
2025-07-12 12:06:15,147:INFO:Initializing Logistic Regression
2025-07-12 12:06:15,147:INFO:Total runtime is 0.0 minutes
2025-07-12 12:06:15,160:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:15,162:INFO:Initializing create_model()
2025-07-12 12:06:15,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:15,163:INFO:Checking exceptions
2025-07-12 12:06:15,163:INFO:Importing libraries
2025-07-12 12:06:15,163:INFO:Copying training dataset
2025-07-12 12:06:15,184:INFO:Defining folds
2025-07-12 12:06:15,184:INFO:Declaring metric variables
2025-07-12 12:06:15,191:INFO:Importing untrained model
2025-07-12 12:06:15,200:INFO:Logistic Regression Imported successfully
2025-07-12 12:06:15,208:INFO:Starting cross validation
2025-07-12 12:06:15,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:18,062:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:18,125:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:18,125:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:18,238:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:18,269:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:18,282:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:18,344:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:18,390:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:21,224:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:21,301:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:21,357:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:21,398:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:21,411:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:21,441:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:21,478:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:21,523:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:22,749:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:22,817:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-12 12:06:22,834:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:22,881:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:22,897:INFO:Calculating mean and std
2025-07-12 12:06:22,897:INFO:Creating metrics dataframe
2025-07-12 12:06:22,897:INFO:Uploading results into container
2025-07-12 12:06:22,897:INFO:Uploading model into container now
2025-07-12 12:06:22,897:INFO:_master_model_container: 15
2025-07-12 12:06:22,897:INFO:_display_container: 3
2025-07-12 12:06:22,897:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-12 12:06:22,897:INFO:create_model() successfully completed......................................
2025-07-12 12:06:23,152:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:23,152:INFO:Creating metrics dataframe
2025-07-12 12:06:23,152:INFO:Initializing K Neighbors Classifier
2025-07-12 12:06:23,152:INFO:Total runtime is 0.13341500361760458 minutes
2025-07-12 12:06:23,169:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:23,169:INFO:Initializing create_model()
2025-07-12 12:06:23,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:23,169:INFO:Checking exceptions
2025-07-12 12:06:23,169:INFO:Importing libraries
2025-07-12 12:06:23,169:INFO:Copying training dataset
2025-07-12 12:06:23,190:INFO:Defining folds
2025-07-12 12:06:23,190:INFO:Declaring metric variables
2025-07-12 12:06:23,190:INFO:Importing untrained model
2025-07-12 12:06:23,205:INFO:K Neighbors Classifier Imported successfully
2025-07-12 12:06:23,220:INFO:Starting cross validation
2025-07-12 12:06:23,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:25,059:INFO:Calculating mean and std
2025-07-12 12:06:25,061:INFO:Creating metrics dataframe
2025-07-12 12:06:25,061:INFO:Uploading results into container
2025-07-12 12:06:25,061:INFO:Uploading model into container now
2025-07-12 12:06:25,061:INFO:_master_model_container: 16
2025-07-12 12:06:25,061:INFO:_display_container: 3
2025-07-12 12:06:25,061:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-12 12:06:25,061:INFO:create_model() successfully completed......................................
2025-07-12 12:06:25,312:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:25,312:INFO:Creating metrics dataframe
2025-07-12 12:06:25,322:INFO:Initializing Naive Bayes
2025-07-12 12:06:25,323:INFO:Total runtime is 0.1696027954419454 minutes
2025-07-12 12:06:25,330:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:25,331:INFO:Initializing create_model()
2025-07-12 12:06:25,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:25,332:INFO:Checking exceptions
2025-07-12 12:06:25,332:INFO:Importing libraries
2025-07-12 12:06:25,332:INFO:Copying training dataset
2025-07-12 12:06:25,344:INFO:Defining folds
2025-07-12 12:06:25,344:INFO:Declaring metric variables
2025-07-12 12:06:25,351:INFO:Importing untrained model
2025-07-12 12:06:25,353:INFO:Naive Bayes Imported successfully
2025-07-12 12:06:25,368:INFO:Starting cross validation
2025-07-12 12:06:25,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:25,867:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:25,895:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:25,916:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,371:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,385:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,385:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,686:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,691:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:26,703:INFO:Calculating mean and std
2025-07-12 12:06:26,703:INFO:Creating metrics dataframe
2025-07-12 12:06:26,703:INFO:Uploading results into container
2025-07-12 12:06:26,703:INFO:Uploading model into container now
2025-07-12 12:06:26,703:INFO:_master_model_container: 17
2025-07-12 12:06:26,703:INFO:_display_container: 3
2025-07-12 12:06:26,703:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-12 12:06:26,713:INFO:create_model() successfully completed......................................
2025-07-12 12:06:26,980:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:26,980:INFO:Creating metrics dataframe
2025-07-12 12:06:26,987:INFO:Initializing Decision Tree Classifier
2025-07-12 12:06:26,987:INFO:Total runtime is 0.19733702341715495 minutes
2025-07-12 12:06:26,987:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:26,997:INFO:Initializing create_model()
2025-07-12 12:06:26,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:26,997:INFO:Checking exceptions
2025-07-12 12:06:26,998:INFO:Importing libraries
2025-07-12 12:06:26,998:INFO:Copying training dataset
2025-07-12 12:06:27,004:INFO:Defining folds
2025-07-12 12:06:27,004:INFO:Declaring metric variables
2025-07-12 12:06:27,017:INFO:Importing untrained model
2025-07-12 12:06:27,021:INFO:Decision Tree Classifier Imported successfully
2025-07-12 12:06:27,035:INFO:Starting cross validation
2025-07-12 12:06:27,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:28,428:INFO:Calculating mean and std
2025-07-12 12:06:28,438:INFO:Creating metrics dataframe
2025-07-12 12:06:28,438:INFO:Uploading results into container
2025-07-12 12:06:28,438:INFO:Uploading model into container now
2025-07-12 12:06:28,438:INFO:_master_model_container: 18
2025-07-12 12:06:28,438:INFO:_display_container: 3
2025-07-12 12:06:28,438:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-12 12:06:28,438:INFO:create_model() successfully completed......................................
2025-07-12 12:06:28,670:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:28,670:INFO:Creating metrics dataframe
2025-07-12 12:06:28,685:INFO:Initializing SVM - Linear Kernel
2025-07-12 12:06:28,685:INFO:Total runtime is 0.2256370464960734 minutes
2025-07-12 12:06:28,685:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:28,685:INFO:Initializing create_model()
2025-07-12 12:06:28,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:28,685:INFO:Checking exceptions
2025-07-12 12:06:28,685:INFO:Importing libraries
2025-07-12 12:06:28,685:INFO:Copying training dataset
2025-07-12 12:06:28,701:INFO:Defining folds
2025-07-12 12:06:28,701:INFO:Declaring metric variables
2025-07-12 12:06:28,717:INFO:Importing untrained model
2025-07-12 12:06:28,717:INFO:SVM - Linear Kernel Imported successfully
2025-07-12 12:06:28,732:INFO:Starting cross validation
2025-07-12 12:06:28,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:29,397:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:29,925:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:29,927:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:30,009:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:30,441:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:30,461:INFO:Calculating mean and std
2025-07-12 12:06:30,471:INFO:Creating metrics dataframe
2025-07-12 12:06:30,471:INFO:Uploading results into container
2025-07-12 12:06:30,471:INFO:Uploading model into container now
2025-07-12 12:06:30,479:INFO:_master_model_container: 19
2025-07-12 12:06:30,479:INFO:_display_container: 3
2025-07-12 12:06:30,479:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-12 12:06:30,479:INFO:create_model() successfully completed......................................
2025-07-12 12:06:30,752:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:30,752:INFO:Creating metrics dataframe
2025-07-12 12:06:30,768:INFO:Initializing Ridge Classifier
2025-07-12 12:06:30,768:INFO:Total runtime is 0.26034255027770997 minutes
2025-07-12 12:06:30,768:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:30,768:INFO:Initializing create_model()
2025-07-12 12:06:30,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:30,768:INFO:Checking exceptions
2025-07-12 12:06:30,768:INFO:Importing libraries
2025-07-12 12:06:30,768:INFO:Copying training dataset
2025-07-12 12:06:30,790:INFO:Defining folds
2025-07-12 12:06:30,790:INFO:Declaring metric variables
2025-07-12 12:06:30,790:INFO:Importing untrained model
2025-07-12 12:06:30,806:INFO:Ridge Classifier Imported successfully
2025-07-12 12:06:30,848:INFO:Starting cross validation
2025-07-12 12:06:30,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:31,367:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:31,377:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:31,427:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:31,953:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:31,955:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:31,975:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:32,346:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:32,368:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:32,376:INFO:Calculating mean and std
2025-07-12 12:06:32,384:INFO:Creating metrics dataframe
2025-07-12 12:06:32,387:INFO:Uploading results into container
2025-07-12 12:06:32,388:INFO:Uploading model into container now
2025-07-12 12:06:32,389:INFO:_master_model_container: 20
2025-07-12 12:06:32,389:INFO:_display_container: 3
2025-07-12 12:06:32,391:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-12 12:06:32,391:INFO:create_model() successfully completed......................................
2025-07-12 12:06:32,707:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:32,707:INFO:Creating metrics dataframe
2025-07-12 12:06:32,724:INFO:Initializing Random Forest Classifier
2025-07-12 12:06:32,724:INFO:Total runtime is 0.2929496725400289 minutes
2025-07-12 12:06:32,740:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:32,740:INFO:Initializing create_model()
2025-07-12 12:06:32,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:32,740:INFO:Checking exceptions
2025-07-12 12:06:32,741:INFO:Importing libraries
2025-07-12 12:06:32,741:INFO:Copying training dataset
2025-07-12 12:06:32,757:INFO:Defining folds
2025-07-12 12:06:32,758:INFO:Declaring metric variables
2025-07-12 12:06:32,773:INFO:Importing untrained model
2025-07-12 12:06:32,784:INFO:Random Forest Classifier Imported successfully
2025-07-12 12:06:32,804:INFO:Starting cross validation
2025-07-12 12:06:32,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:38,186:INFO:Calculating mean and std
2025-07-12 12:06:38,186:INFO:Creating metrics dataframe
2025-07-12 12:06:38,186:INFO:Uploading results into container
2025-07-12 12:06:38,186:INFO:Uploading model into container now
2025-07-12 12:06:38,186:INFO:_master_model_container: 21
2025-07-12 12:06:38,186:INFO:_display_container: 3
2025-07-12 12:06:38,202:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-12 12:06:38,202:INFO:create_model() successfully completed......................................
2025-07-12 12:06:38,456:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:38,456:INFO:Creating metrics dataframe
2025-07-12 12:06:38,472:INFO:Initializing Quadratic Discriminant Analysis
2025-07-12 12:06:38,472:INFO:Total runtime is 0.38875001271565757 minutes
2025-07-12 12:06:38,472:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:38,472:INFO:Initializing create_model()
2025-07-12 12:06:38,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:38,472:INFO:Checking exceptions
2025-07-12 12:06:38,487:INFO:Importing libraries
2025-07-12 12:06:38,487:INFO:Copying training dataset
2025-07-12 12:06:38,503:INFO:Defining folds
2025-07-12 12:06:38,504:INFO:Declaring metric variables
2025-07-12 12:06:38,510:INFO:Importing untrained model
2025-07-12 12:06:38,516:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-12 12:06:38,528:INFO:Starting cross validation
2025-07-12 12:06:38,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:38,881:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:38,881:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:38,907:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:38,925:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,341:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,360:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,387:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,387:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,766:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,777:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-12 12:06:39,866:INFO:Calculating mean and std
2025-07-12 12:06:39,866:INFO:Creating metrics dataframe
2025-07-12 12:06:39,866:INFO:Uploading results into container
2025-07-12 12:06:39,876:INFO:Uploading model into container now
2025-07-12 12:06:39,877:INFO:_master_model_container: 22
2025-07-12 12:06:39,878:INFO:_display_container: 3
2025-07-12 12:06:39,878:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-12 12:06:39,879:INFO:create_model() successfully completed......................................
2025-07-12 12:06:40,108:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:40,108:INFO:Creating metrics dataframe
2025-07-12 12:06:40,124:INFO:Initializing Ada Boost Classifier
2025-07-12 12:06:40,124:INFO:Total runtime is 0.4162783145904541 minutes
2025-07-12 12:06:40,140:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:40,140:INFO:Initializing create_model()
2025-07-12 12:06:40,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:40,140:INFO:Checking exceptions
2025-07-12 12:06:40,140:INFO:Importing libraries
2025-07-12 12:06:40,140:INFO:Copying training dataset
2025-07-12 12:06:40,155:INFO:Defining folds
2025-07-12 12:06:40,155:INFO:Declaring metric variables
2025-07-12 12:06:40,164:INFO:Importing untrained model
2025-07-12 12:06:40,169:INFO:Ada Boost Classifier Imported successfully
2025-07-12 12:06:40,173:INFO:Starting cross validation
2025-07-12 12:06:40,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:40,482:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:40,502:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:40,512:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:40,542:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:41,299:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:41,559:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:41,582:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:41,610:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:41,615:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:42,653:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:42,657:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-12 12:06:43,254:INFO:Calculating mean and std
2025-07-12 12:06:43,256:INFO:Creating metrics dataframe
2025-07-12 12:06:43,256:INFO:Uploading results into container
2025-07-12 12:06:43,256:INFO:Uploading model into container now
2025-07-12 12:06:43,256:INFO:_master_model_container: 23
2025-07-12 12:06:43,256:INFO:_display_container: 3
2025-07-12 12:06:43,256:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-12 12:06:43,256:INFO:create_model() successfully completed......................................
2025-07-12 12:06:43,498:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:43,498:INFO:Creating metrics dataframe
2025-07-12 12:06:43,514:INFO:Initializing Gradient Boosting Classifier
2025-07-12 12:06:43,514:INFO:Total runtime is 0.47278032700220746 minutes
2025-07-12 12:06:43,514:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:43,514:INFO:Initializing create_model()
2025-07-12 12:06:43,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:43,530:INFO:Checking exceptions
2025-07-12 12:06:43,530:INFO:Importing libraries
2025-07-12 12:06:43,530:INFO:Copying training dataset
2025-07-12 12:06:43,530:INFO:Defining folds
2025-07-12 12:06:43,530:INFO:Declaring metric variables
2025-07-12 12:06:43,545:INFO:Importing untrained model
2025-07-12 12:06:43,545:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:06:43,561:INFO:Starting cross validation
2025-07-12 12:06:43,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:50,265:INFO:Calculating mean and std
2025-07-12 12:06:50,265:INFO:Creating metrics dataframe
2025-07-12 12:06:50,265:INFO:Uploading results into container
2025-07-12 12:06:50,265:INFO:Uploading model into container now
2025-07-12 12:06:50,265:INFO:_master_model_container: 24
2025-07-12 12:06:50,265:INFO:_display_container: 3
2025-07-12 12:06:50,280:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:06:50,280:INFO:create_model() successfully completed......................................
2025-07-12 12:06:50,547:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:50,547:INFO:Creating metrics dataframe
2025-07-12 12:06:50,563:INFO:Initializing Linear Discriminant Analysis
2025-07-12 12:06:50,563:INFO:Total runtime is 0.5902569055557251 minutes
2025-07-12 12:06:50,563:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:50,563:INFO:Initializing create_model()
2025-07-12 12:06:50,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:50,578:INFO:Checking exceptions
2025-07-12 12:06:50,578:INFO:Importing libraries
2025-07-12 12:06:50,578:INFO:Copying training dataset
2025-07-12 12:06:50,596:INFO:Defining folds
2025-07-12 12:06:50,596:INFO:Declaring metric variables
2025-07-12 12:06:50,607:INFO:Importing untrained model
2025-07-12 12:06:50,621:INFO:Linear Discriminant Analysis Imported successfully
2025-07-12 12:06:50,635:INFO:Starting cross validation
2025-07-12 12:06:50,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:51,244:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:51,697:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:51,728:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:51,738:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:06:52,040:INFO:Calculating mean and std
2025-07-12 12:06:52,048:INFO:Creating metrics dataframe
2025-07-12 12:06:52,053:INFO:Uploading results into container
2025-07-12 12:06:52,054:INFO:Uploading model into container now
2025-07-12 12:06:52,055:INFO:_master_model_container: 25
2025-07-12 12:06:52,055:INFO:_display_container: 3
2025-07-12 12:06:52,056:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-12 12:06:52,056:INFO:create_model() successfully completed......................................
2025-07-12 12:06:52,286:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:52,286:INFO:Creating metrics dataframe
2025-07-12 12:06:52,305:INFO:Initializing Extra Trees Classifier
2025-07-12 12:06:52,305:INFO:Total runtime is 0.6192967375119527 minutes
2025-07-12 12:06:52,305:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:52,320:INFO:Initializing create_model()
2025-07-12 12:06:52,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:52,320:INFO:Checking exceptions
2025-07-12 12:06:52,320:INFO:Importing libraries
2025-07-12 12:06:52,321:INFO:Copying training dataset
2025-07-12 12:06:52,331:INFO:Defining folds
2025-07-12 12:06:52,331:INFO:Declaring metric variables
2025-07-12 12:06:52,338:INFO:Importing untrained model
2025-07-12 12:06:52,344:INFO:Extra Trees Classifier Imported successfully
2025-07-12 12:06:52,359:INFO:Starting cross validation
2025-07-12 12:06:52,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:57,204:INFO:Calculating mean and std
2025-07-12 12:06:57,204:INFO:Creating metrics dataframe
2025-07-12 12:06:57,212:INFO:Uploading results into container
2025-07-12 12:06:57,214:INFO:Uploading model into container now
2025-07-12 12:06:57,214:INFO:_master_model_container: 26
2025-07-12 12:06:57,214:INFO:_display_container: 3
2025-07-12 12:06:57,214:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-12 12:06:57,214:INFO:create_model() successfully completed......................................
2025-07-12 12:06:57,470:INFO:SubProcess create_model() end ==================================
2025-07-12 12:06:57,470:INFO:Creating metrics dataframe
2025-07-12 12:06:57,485:INFO:Initializing Light Gradient Boosting Machine
2025-07-12 12:06:57,485:INFO:Total runtime is 0.7056329687436421 minutes
2025-07-12 12:06:57,485:INFO:SubProcess create_model() called ==================================
2025-07-12 12:06:57,485:INFO:Initializing create_model()
2025-07-12 12:06:57,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:06:57,485:INFO:Checking exceptions
2025-07-12 12:06:57,485:INFO:Importing libraries
2025-07-12 12:06:57,485:INFO:Copying training dataset
2025-07-12 12:06:57,504:INFO:Defining folds
2025-07-12 12:06:57,505:INFO:Declaring metric variables
2025-07-12 12:06:57,512:INFO:Importing untrained model
2025-07-12 12:06:57,524:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 12:06:57,537:INFO:Starting cross validation
2025-07-12 12:06:57,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:06:59,881:INFO:Calculating mean and std
2025-07-12 12:06:59,881:INFO:Creating metrics dataframe
2025-07-12 12:06:59,891:INFO:Uploading results into container
2025-07-12 12:06:59,891:INFO:Uploading model into container now
2025-07-12 12:06:59,891:INFO:_master_model_container: 27
2025-07-12 12:06:59,891:INFO:_display_container: 3
2025-07-12 12:06:59,891:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-12 12:06:59,896:INFO:create_model() successfully completed......................................
2025-07-12 12:07:00,148:INFO:SubProcess create_model() end ==================================
2025-07-12 12:07:00,148:INFO:Creating metrics dataframe
2025-07-12 12:07:00,164:INFO:Initializing Dummy Classifier
2025-07-12 12:07:00,164:INFO:Total runtime is 0.7502813736597697 minutes
2025-07-12 12:07:00,180:INFO:SubProcess create_model() called ==================================
2025-07-12 12:07:00,180:INFO:Initializing create_model()
2025-07-12 12:07:00,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F8177D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:07:00,180:INFO:Checking exceptions
2025-07-12 12:07:00,180:INFO:Importing libraries
2025-07-12 12:07:00,180:INFO:Copying training dataset
2025-07-12 12:07:00,180:INFO:Defining folds
2025-07-12 12:07:00,180:INFO:Declaring metric variables
2025-07-12 12:07:00,200:INFO:Importing untrained model
2025-07-12 12:07:00,205:INFO:Dummy Classifier Imported successfully
2025-07-12 12:07:00,216:INFO:Starting cross validation
2025-07-12 12:07:00,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:07:00,645:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:00,645:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:00,655:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:00,665:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,039:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,049:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,057:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,069:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,331:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,341:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-12 12:07:01,351:INFO:Calculating mean and std
2025-07-12 12:07:01,351:INFO:Creating metrics dataframe
2025-07-12 12:07:01,360:INFO:Uploading results into container
2025-07-12 12:07:01,360:INFO:Uploading model into container now
2025-07-12 12:07:01,360:INFO:_master_model_container: 28
2025-07-12 12:07:01,360:INFO:_display_container: 3
2025-07-12 12:07:01,360:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-12 12:07:01,360:INFO:create_model() successfully completed......................................
2025-07-12 12:07:01,586:INFO:SubProcess create_model() end ==================================
2025-07-12 12:07:01,586:INFO:Creating metrics dataframe
2025-07-12 12:07:01,619:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2025-07-12 12:07:01,636:INFO:Initializing create_model()
2025-07-12 12:07:01,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:07:01,636:INFO:Checking exceptions
2025-07-12 12:07:01,639:INFO:Importing libraries
2025-07-12 12:07:01,640:INFO:Copying training dataset
2025-07-12 12:07:01,654:INFO:Defining folds
2025-07-12 12:07:01,654:INFO:Declaring metric variables
2025-07-12 12:07:01,654:INFO:Importing untrained model
2025-07-12 12:07:01,654:INFO:Declaring custom model
2025-07-12 12:07:01,655:INFO:SVM - Linear Kernel Imported successfully
2025-07-12 12:07:01,658:INFO:Cross validation set to False
2025-07-12 12:07:01,658:INFO:Fitting Model
2025-07-12 12:07:01,926:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-12 12:07:01,926:INFO:create_model() successfully completed......................................
2025-07-12 12:07:02,325:INFO:_master_model_container: 28
2025-07-12 12:07:02,327:INFO:_display_container: 3
2025-07-12 12:07:02,328:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-12 12:07:02,328:INFO:compare_models() successfully completed......................................
2025-07-12 12:09:49,377:INFO:gpu_param set to False
2025-07-12 12:09:49,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:09:49,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:09:49,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:09:49,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-12 12:20:16,131:INFO:Initializing create_model()
2025-07-12 12:20:16,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:20:16,133:INFO:Checking exceptions
2025-07-12 12:20:16,168:INFO:Importing libraries
2025-07-12 12:20:16,168:INFO:Copying training dataset
2025-07-12 12:20:16,191:INFO:Defining folds
2025-07-12 12:20:16,191:INFO:Declaring metric variables
2025-07-12 12:20:16,197:INFO:Importing untrained model
2025-07-12 12:20:16,201:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:20:16,224:INFO:Starting cross validation
2025-07-12 12:20:16,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:20:38,857:INFO:Calculating mean and std
2025-07-12 12:20:38,857:INFO:Creating metrics dataframe
2025-07-12 12:20:38,865:INFO:Finalizing model
2025-07-12 12:20:40,904:INFO:Uploading results into container
2025-07-12 12:20:40,906:INFO:Uploading model into container now
2025-07-12 12:20:40,930:INFO:_master_model_container: 29
2025-07-12 12:20:40,930:INFO:_display_container: 4
2025-07-12 12:20:40,933:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:20:40,933:INFO:create_model() successfully completed......................................
2025-07-12 12:21:20,884:INFO:Initializing tune_model()
2025-07-12 12:21:20,885:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-12 12:21:20,886:INFO:Checking exceptions
2025-07-12 12:21:20,931:INFO:Copying training dataset
2025-07-12 12:21:20,939:INFO:Checking base model
2025-07-12 12:21:20,939:INFO:Base model : Gradient Boosting Classifier
2025-07-12 12:21:20,946:INFO:Declaring metric variables
2025-07-12 12:21:20,952:INFO:Defining Hyperparameters
2025-07-12 12:21:21,240:INFO:Tuning with n_jobs=-1
2025-07-12 12:21:21,240:INFO:Initializing RandomizedSearchCV
2025-07-12 12:22:48,528:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.4}
2025-07-12 12:22:48,528:INFO:Hyperparameter search completed
2025-07-12 12:22:48,528:INFO:SubProcess create_model() called ==================================
2025-07-12 12:22:48,536:INFO:Initializing create_model()
2025-07-12 12:22:48,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1F80CAA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'n_estimators': 30, 'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 8, 'learning_rate': 0.4})
2025-07-12 12:22:48,536:INFO:Checking exceptions
2025-07-12 12:22:48,536:INFO:Importing libraries
2025-07-12 12:22:48,536:INFO:Copying training dataset
2025-07-12 12:22:48,554:INFO:Defining folds
2025-07-12 12:22:48,554:INFO:Declaring metric variables
2025-07-12 12:22:48,558:INFO:Importing untrained model
2025-07-12 12:22:48,558:INFO:Declaring custom model
2025-07-12 12:22:48,575:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:22:48,592:INFO:Starting cross validation
2025-07-12 12:22:48,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:22:51,044:INFO:Calculating mean and std
2025-07-12 12:22:51,046:INFO:Creating metrics dataframe
2025-07-12 12:22:51,058:INFO:Finalizing model
2025-07-12 12:22:51,573:INFO:Uploading results into container
2025-07-12 12:22:51,573:INFO:Uploading model into container now
2025-07-12 12:22:51,573:INFO:_master_model_container: 30
2025-07-12 12:22:51,573:INFO:_display_container: 5
2025-07-12 12:22:51,588:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:22:51,588:INFO:create_model() successfully completed......................................
2025-07-12 12:22:51,873:INFO:SubProcess create_model() end ==================================
2025-07-12 12:22:51,873:INFO:choose_better activated
2025-07-12 12:22:51,889:INFO:SubProcess create_model() called ==================================
2025-07-12 12:22:51,889:INFO:Initializing create_model()
2025-07-12 12:22:51,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:22:51,889:INFO:Checking exceptions
2025-07-12 12:22:51,894:INFO:Importing libraries
2025-07-12 12:22:51,895:INFO:Copying training dataset
2025-07-12 12:22:51,904:INFO:Defining folds
2025-07-12 12:22:51,905:INFO:Declaring metric variables
2025-07-12 12:22:51,905:INFO:Importing untrained model
2025-07-12 12:22:51,905:INFO:Declaring custom model
2025-07-12 12:22:51,906:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:22:51,906:INFO:Starting cross validation
2025-07-12 12:22:51,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 12:22:57,793:INFO:Calculating mean and std
2025-07-12 12:22:57,795:INFO:Creating metrics dataframe
2025-07-12 12:22:57,795:INFO:Finalizing model
2025-07-12 12:22:59,047:INFO:Uploading results into container
2025-07-12 12:22:59,047:INFO:Uploading model into container now
2025-07-12 12:22:59,047:INFO:_master_model_container: 31
2025-07-12 12:22:59,047:INFO:_display_container: 6
2025-07-12 12:22:59,047:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:22:59,047:INFO:create_model() successfully completed......................................
2025-07-12 12:22:59,291:INFO:SubProcess create_model() end ==================================
2025-07-12 12:22:59,291:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.0705
2025-07-12 12:22:59,291:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.1563
2025-07-12 12:22:59,291:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-07-12 12:22:59,291:INFO:choose_better completed
2025-07-12 12:22:59,309:INFO:_master_model_container: 31
2025-07-12 12:22:59,309:INFO:_display_container: 5
2025-07-12 12:22:59,309:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:22:59,309:INFO:tune_model() successfully completed......................................
2025-07-12 12:23:42,859:INFO:Initializing plot_model()
2025-07-12 12:23:42,860:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 12:23:42,861:INFO:Checking exceptions
2025-07-12 12:23:42,876:INFO:Preloading libraries
2025-07-12 12:23:42,887:INFO:Copying training dataset
2025-07-12 12:23:42,888:INFO:Plot type: auc
2025-07-12 12:23:43,051:INFO:Fitting Model
2025-07-12 12:23:43,051:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names


2025-07-12 12:23:43,051:INFO:Scoring test/hold-out set
2025-07-12 12:23:43,445:INFO:Visual Rendered Successfully
2025-07-12 12:23:43,717:INFO:plot_model() successfully completed......................................
2025-07-12 12:23:56,185:INFO:Initializing plot_model()
2025-07-12 12:23:56,187:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 12:23:56,188:INFO:Checking exceptions
2025-07-12 12:23:56,200:INFO:Preloading libraries
2025-07-12 12:23:56,208:INFO:Copying training dataset
2025-07-12 12:23:56,208:INFO:Plot type: pr
2025-07-12 12:23:56,375:INFO:Fitting Model
2025-07-12 12:23:56,375:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names


2025-07-12 12:23:56,375:INFO:Scoring test/hold-out set
2025-07-12 12:23:56,660:INFO:Visual Rendered Successfully
2025-07-12 12:23:56,908:INFO:plot_model() successfully completed......................................
2025-07-12 12:23:59,608:INFO:Initializing plot_model()
2025-07-12 12:23:59,609:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 12:23:59,609:INFO:Checking exceptions
2025-07-12 12:23:59,621:INFO:Preloading libraries
2025-07-12 12:23:59,629:INFO:Copying training dataset
2025-07-12 12:23:59,629:INFO:Plot type: feature
2025-07-12 12:23:59,629:WARNING:No coef_ found. Trying feature_importances_
2025-07-12 12:23:59,915:INFO:Visual Rendered Successfully
2025-07-12 12:24:00,175:INFO:plot_model() successfully completed......................................
2025-07-12 12:24:07,147:INFO:Initializing plot_model()
2025-07-12 12:24:07,148:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 12:24:07,148:INFO:Checking exceptions
2025-07-12 12:24:07,160:INFO:Preloading libraries
2025-07-12 12:24:07,170:INFO:Copying training dataset
2025-07-12 12:24:07,170:INFO:Plot type: confusion_matrix
2025-07-12 12:24:07,386:INFO:Fitting Model
2025-07-12 12:24:07,386:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names


2025-07-12 12:24:07,386:INFO:Scoring test/hold-out set
2025-07-12 12:24:07,677:INFO:Visual Rendered Successfully
2025-07-12 12:24:08,015:INFO:plot_model() successfully completed......................................
2025-07-12 12:24:36,454:INFO:Initializing predict_model()
2025-07-12 12:24:36,455:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1FC384A40>)
2025-07-12 12:24:36,455:INFO:Checking exceptions
2025-07-12 12:24:36,455:INFO:Preloading libraries
2025-07-12 12:25:56,850:INFO:Initializing finalize_model()
2025-07-12 12:25:56,851:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-12 12:25:56,853:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-12 12:25:56,863:INFO:Initializing create_model()
2025-07-12 12:25:56,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=30, n_iter_no_change=None,
                           random_state=123, subsample=0.2, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 12:25:56,864:INFO:Checking exceptions
2025-07-12 12:25:56,866:INFO:Importing libraries
2025-07-12 12:25:56,867:INFO:Copying training dataset
2025-07-12 12:25:56,867:INFO:Defining folds
2025-07-12 12:25:56,868:INFO:Declaring metric variables
2025-07-12 12:25:56,868:INFO:Importing untrained model
2025-07-12 12:25:56,868:INFO:Declaring custom model
2025-07-12 12:25:56,870:INFO:Gradient Boosting Classifier Imported successfully
2025-07-12 12:25:56,872:INFO:Cross validation set to False
2025-07-12 12:25:56,872:INFO:Fitting Model
2025-07-12 12:25:57,351:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-12 12:25:57,351:INFO:create_model() successfully completed......................................
2025-07-12 12:25:57,626:INFO:_master_model_container: 31
2025-07-12 12:25:57,626:INFO:_display_container: 6
2025-07-12 12:25:57,660:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-12 12:25:57,660:INFO:finalize_model() successfully completed......................................
2025-07-12 12:26:19,706:INFO:Initializing predict_model()
2025-07-12 12:26:19,706:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D18537F740>)
2025-07-12 12:26:19,706:INFO:Checking exceptions
2025-07-12 12:26:19,706:INFO:Preloading libraries
2025-07-12 13:12:42,741:INFO:Initializing predict_model()
2025-07-12 13:12:42,741:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1FA33B240>)
2025-07-12 13:12:42,742:INFO:Checking exceptions
2025-07-12 13:12:42,742:INFO:Preloading libraries
2025-07-12 13:12:42,745:INFO:Set up data.
2025-07-12 13:12:42,756:INFO:Set up index.
2025-07-12 13:23:01,904:INFO:Initializing save_model()
2025-07-12 13:23:01,904:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), model_name=Final GBC Model 02Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-12 13:23:01,904:INFO:Adding model into prep_pipe
2025-07-12 13:23:01,905:WARNING:Only Model saved as it was a pipeline.
2025-07-12 13:23:01,970:INFO:Final GBC Model 02Jun2022.pkl saved in current working directory
2025-07-12 13:23:02,097:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-07-12 13:23:02,097:INFO:save_model() successfully completed......................................
2025-07-12 13:23:58,916:INFO:Initializing load_model()
2025-07-12 13:23:58,917:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-12 13:24:25,360:INFO:Initializing predict_model()
2025-07-12 13:24:25,360:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.4, loss='log_loss',
                                            max_depth=8, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.05,
                                            min_samples_leaf=2,
                                            min_samples_split=9,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=30,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=0.2,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D18537F6A0>)
2025-07-12 13:24:25,360:INFO:Checking exceptions
2025-07-12 13:24:25,360:INFO:Preloading libraries
2025-07-12 13:24:25,365:INFO:Set up data.
2025-07-12 13:24:25,380:INFO:Set up index.
2025-07-12 13:32:51,850:INFO:Initializing create_model()
2025-07-12 13:32:51,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lightgbn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 13:32:51,851:INFO:Checking exceptions
2025-07-12 13:33:13,960:INFO:Initializing create_model()
2025-07-12 13:33:13,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 13:33:13,961:INFO:Checking exceptions
2025-07-12 13:33:13,999:INFO:Importing libraries
2025-07-12 13:33:14,000:INFO:Copying training dataset
2025-07-12 13:33:14,021:INFO:Defining folds
2025-07-12 13:33:14,021:INFO:Declaring metric variables
2025-07-12 13:33:14,039:INFO:Importing untrained model
2025-07-12 13:33:14,052:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 13:33:14,068:INFO:Starting cross validation
2025-07-12 13:33:14,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 13:33:33,567:INFO:Calculating mean and std
2025-07-12 13:33:33,574:INFO:Creating metrics dataframe
2025-07-12 13:33:33,586:INFO:Finalizing model
2025-07-12 13:33:33,809:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-12 13:33:33,809:INFO:[LightGBM] [Info] Number of positive: 505, number of negative: 6145
2025-07-12 13:33:33,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.
2025-07-12 13:33:33,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-12 13:33:33,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-12 13:33:33,819:INFO:[LightGBM] [Info] Total Bins 616
2025-07-12 13:33:33,819:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-12 13:33:33,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075940 -> initscore=-2.498836
2025-07-12 13:33:33,819:INFO:[LightGBM] [Info] Start training from score -2.498836
2025-07-12 13:33:33,971:INFO:Uploading results into container
2025-07-12 13:33:33,971:INFO:Uploading model into container now
2025-07-12 13:33:34,002:INFO:_master_model_container: 32
2025-07-12 13:33:34,002:INFO:_display_container: 10
2025-07-12 13:33:34,003:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:33:34,003:INFO:create_model() successfully completed......................................
2025-07-12 13:34:11,044:INFO:Initializing create_model()
2025-07-12 13:34:11,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 13:34:11,045:INFO:Checking exceptions
2025-07-12 13:34:11,077:INFO:Importing libraries
2025-07-12 13:34:11,077:INFO:Copying training dataset
2025-07-12 13:34:11,097:INFO:Defining folds
2025-07-12 13:34:11,097:INFO:Declaring metric variables
2025-07-12 13:34:11,102:INFO:Importing untrained model
2025-07-12 13:34:11,111:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 13:34:11,126:INFO:Starting cross validation
2025-07-12 13:34:11,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 13:34:13,602:INFO:Calculating mean and std
2025-07-12 13:34:13,610:INFO:Creating metrics dataframe
2025-07-12 13:34:13,623:INFO:Finalizing model
2025-07-12 13:34:13,811:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] Number of positive: 505, number of negative: 6145
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.
2025-07-12 13:34:13,813:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-12 13:34:13,813:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] Total Bins 616
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075940 -> initscore=-2.498836
2025-07-12 13:34:13,813:INFO:[LightGBM] [Info] Start training from score -2.498836
2025-07-12 13:34:13,931:INFO:Uploading results into container
2025-07-12 13:34:13,932:INFO:Uploading model into container now
2025-07-12 13:34:13,959:INFO:_master_model_container: 33
2025-07-12 13:34:13,959:INFO:_display_container: 11
2025-07-12 13:34:13,959:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:34:13,962:INFO:create_model() successfully completed......................................
2025-07-12 13:35:23,799:INFO:Initializing tune_model()
2025-07-12 13:35:23,799:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-12 13:35:23,800:INFO:Checking exceptions
2025-07-12 13:35:23,838:INFO:Copying training dataset
2025-07-12 13:35:23,851:INFO:Checking base model
2025-07-12 13:35:23,851:INFO:Base model : Light Gradient Boosting Machine
2025-07-12 13:35:23,856:INFO:Declaring metric variables
2025-07-12 13:35:23,868:INFO:Defining Hyperparameters
2025-07-12 13:35:24,181:INFO:Tuning with n_jobs=-1
2025-07-12 13:35:24,181:INFO:Initializing RandomizedSearchCV
2025-07-12 13:35:45,593:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-07-12 13:35:45,593:INFO:Hyperparameter search completed
2025-07-12 13:35:45,593:INFO:SubProcess create_model() called ==================================
2025-07-12 13:35:45,593:INFO:Initializing create_model()
2025-07-12 13:35:45,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1852F6A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-07-12 13:35:45,593:INFO:Checking exceptions
2025-07-12 13:35:45,593:INFO:Importing libraries
2025-07-12 13:35:45,593:INFO:Copying training dataset
2025-07-12 13:35:45,614:INFO:Defining folds
2025-07-12 13:35:45,614:INFO:Declaring metric variables
2025-07-12 13:35:45,623:INFO:Importing untrained model
2025-07-12 13:35:45,623:INFO:Declaring custom model
2025-07-12 13:35:45,635:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 13:35:45,650:INFO:Starting cross validation
2025-07-12 13:35:45,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 13:35:47,510:INFO:Calculating mean and std
2025-07-12 13:35:47,518:INFO:Creating metrics dataframe
2025-07-12 13:35:47,530:INFO:Finalizing model
2025-07-12 13:35:47,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:35:47,712:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:35:47,712:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:35:47,720:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-12 13:35:47,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:35:47,722:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:35:47,722:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:35:47,722:INFO:[LightGBM] [Info] Number of positive: 505, number of negative: 6145
2025-07-12 13:35:47,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.
2025-07-12 13:35:47,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-12 13:35:47,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-12 13:35:47,724:INFO:[LightGBM] [Info] Total Bins 616
2025-07-12 13:35:47,725:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-12 13:35:47,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075940 -> initscore=-2.498836
2025-07-12 13:35:47,726:INFO:[LightGBM] [Info] Start training from score -2.498836
2025-07-12 13:35:47,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:35:47,802:INFO:Uploading results into container
2025-07-12 13:35:47,802:INFO:Uploading model into container now
2025-07-12 13:35:47,802:INFO:_master_model_container: 34
2025-07-12 13:35:47,802:INFO:_display_container: 12
2025-07-12 13:35:47,802:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:35:47,802:INFO:create_model() successfully completed......................................
2025-07-12 13:35:48,111:INFO:SubProcess create_model() end ==================================
2025-07-12 13:35:48,111:INFO:choose_better activated
2025-07-12 13:35:48,111:INFO:SubProcess create_model() called ==================================
2025-07-12 13:35:48,111:INFO:Initializing create_model()
2025-07-12 13:35:48,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 13:35:48,111:INFO:Checking exceptions
2025-07-12 13:35:48,111:INFO:Importing libraries
2025-07-12 13:35:48,111:INFO:Copying training dataset
2025-07-12 13:35:48,137:INFO:Defining folds
2025-07-12 13:35:48,137:INFO:Declaring metric variables
2025-07-12 13:35:48,137:INFO:Importing untrained model
2025-07-12 13:35:48,138:INFO:Declaring custom model
2025-07-12 13:35:48,141:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 13:35:48,141:INFO:Starting cross validation
2025-07-12 13:35:48,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-12 13:35:50,443:INFO:Calculating mean and std
2025-07-12 13:35:50,451:INFO:Creating metrics dataframe
2025-07-12 13:35:50,453:INFO:Finalizing model
2025-07-12 13:35:50,640:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] Number of positive: 505, number of negative: 6145
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2025-07-12 13:35:50,640:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-12 13:35:50,640:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] Total Bins 616
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.075940 -> initscore=-2.498836
2025-07-12 13:35:50,640:INFO:[LightGBM] [Info] Start training from score -2.498836
2025-07-12 13:35:50,755:INFO:Uploading results into container
2025-07-12 13:35:50,763:INFO:Uploading model into container now
2025-07-12 13:35:50,763:INFO:_master_model_container: 35
2025-07-12 13:35:50,763:INFO:_display_container: 13
2025-07-12 13:35:50,765:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:35:50,765:INFO:create_model() successfully completed......................................
2025-07-12 13:35:51,076:INFO:SubProcess create_model() end ==================================
2025-07-12 13:35:51,076:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1045
2025-07-12 13:35:51,076:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1066
2025-07-12 13:35:51,076:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-07-12 13:35:51,076:INFO:choose_better completed
2025-07-12 13:35:51,095:INFO:_master_model_container: 35
2025-07-12 13:35:51,095:INFO:_display_container: 12
2025-07-12 13:35:51,097:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:35:51,097:INFO:tune_model() successfully completed......................................
2025-07-12 13:36:27,408:INFO:Initializing plot_model()
2025-07-12 13:36:27,408:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 13:36:27,409:INFO:Checking exceptions
2025-07-12 13:36:27,423:INFO:Preloading libraries
2025-07-12 13:36:27,432:INFO:Copying training dataset
2025-07-12 13:36:27,433:INFO:Plot type: pr
2025-07-12 13:36:27,681:INFO:Fitting Model
2025-07-12 13:36:27,682:INFO:Scoring test/hold-out set
2025-07-12 13:36:27,684:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:36:27,684:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:36:27,684:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:36:27,694:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:36:27,694:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:36:27,694:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:36:28,035:INFO:Visual Rendered Successfully
2025-07-12 13:36:28,324:INFO:plot_model() successfully completed......................................
2025-07-12 13:36:36,447:INFO:Initializing plot_model()
2025-07-12 13:36:36,447:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 13:36:36,448:INFO:Checking exceptions
2025-07-12 13:36:36,458:INFO:Preloading libraries
2025-07-12 13:36:36,470:INFO:Copying training dataset
2025-07-12 13:36:36,470:INFO:Plot type: feature
2025-07-12 13:36:36,471:WARNING:No coef_ found. Trying feature_importances_
2025-07-12 13:36:36,831:INFO:Visual Rendered Successfully
2025-07-12 13:36:37,122:INFO:plot_model() successfully completed......................................
2025-07-12 13:36:49,824:INFO:Initializing plot_model()
2025-07-12 13:36:49,825:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-12 13:36:49,825:INFO:Checking exceptions
2025-07-12 13:36:49,835:INFO:Preloading libraries
2025-07-12 13:36:49,845:INFO:Copying training dataset
2025-07-12 13:36:49,845:INFO:Plot type: confusion_matrix
2025-07-12 13:36:50,043:INFO:Fitting Model
2025-07-12 13:36:50,043:INFO:Scoring test/hold-out set
2025-07-12 13:36:50,043:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:36:50,043:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:36:50,043:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:36:50,058:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:36:50,058:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:36:50,058:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:36:50,274:INFO:Visual Rendered Successfully
2025-07-12 13:36:50,582:INFO:plot_model() successfully completed......................................
2025-07-12 13:36:58,874:INFO:Initializing predict_model()
2025-07-12 13:36:58,874:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D18549EC00>)
2025-07-12 13:36:58,875:INFO:Checking exceptions
2025-07-12 13:36:58,875:INFO:Preloading libraries
2025-07-12 13:37:08,697:INFO:Initializing finalize_model()
2025-07-12 13:37:08,698:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-12 13:37:08,701:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-12 13:37:08,717:INFO:Initializing create_model()
2025-07-12 13:37:08,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-12 13:37:08,718:INFO:Checking exceptions
2025-07-12 13:37:08,720:INFO:Importing libraries
2025-07-12 13:37:08,720:INFO:Copying training dataset
2025-07-12 13:37:08,721:INFO:Defining folds
2025-07-12 13:37:08,721:INFO:Declaring metric variables
2025-07-12 13:37:08,721:INFO:Importing untrained model
2025-07-12 13:37:08,721:INFO:Declaring custom model
2025-07-12 13:37:08,723:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-12 13:37:08,726:INFO:Cross validation set to False
2025-07-12 13:37:08,727:INFO:Fitting Model
2025-07-12 13:37:08,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:37:08,927:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:37:08,927:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:37:08,943:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-12 13:37:08,943:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-12 13:37:08,943:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-12 13:37:08,943:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-12 13:37:08,943:INFO:[LightGBM] [Info] Number of positive: 722, number of negative: 8778
2025-07-12 13:37:08,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002409 seconds.
2025-07-12 13:37:08,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-07-12 13:37:08,949:INFO:[LightGBM] [Info] Total Bins 618
2025-07-12 13:37:08,949:INFO:[LightGBM] [Info] Number of data points in the train set: 9500, number of used features: 28
2025-07-12 13:37:08,949:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.076000 -> initscore=-2.497979
2025-07-12 13:37:08,949:INFO:[LightGBM] [Info] Start training from score -2.497979
2025-07-12 13:37:08,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:08,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:08,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:09,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:09,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:09,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-12 13:37:09,122:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-12 13:37:09,122:INFO:create_model() successfully completed......................................
2025-07-12 13:37:09,418:INFO:_master_model_container: 35
2025-07-12 13:37:09,418:INFO:_display_container: 13
2025-07-12 13:37:09,473:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-12 13:37:09,473:INFO:finalize_model() successfully completed......................................
2025-07-12 13:37:15,710:INFO:Initializing predict_model()
2025-07-12 13:37:15,711:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1FA34DB20>)
2025-07-12 13:37:15,711:INFO:Checking exceptions
2025-07-12 13:37:15,711:INFO:Preloading libraries
2025-07-12 13:37:28,732:INFO:Initializing predict_model()
2025-07-12 13:37:28,733:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1E19F4AE0>)
2025-07-12 13:37:28,733:INFO:Checking exceptions
2025-07-12 13:37:28,733:INFO:Preloading libraries
2025-07-12 13:37:28,737:INFO:Set up data.
2025-07-12 13:37:28,754:INFO:Set up index.
2025-07-12 13:38:37,343:INFO:Initializing save_model()
2025-07-12 13:38:37,344:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=Final GBC Model 02Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-12 13:38:37,344:INFO:Adding model into prep_pipe
2025-07-12 13:38:37,344:WARNING:Only Model saved as it was a pipeline.
2025-07-12 13:38:37,371:INFO:Final GBC Model 02Jun2022.pkl saved in current working directory
2025-07-12 13:38:37,451:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-12 13:38:37,451:INFO:save_model() successfully completed......................................
2025-07-12 13:38:46,459:INFO:Initializing load_model()
2025-07-12 13:38:46,459:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-12 13:38:48,798:INFO:Initializing predict_model()
2025-07-12 13:38:48,799:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D1854A4F10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D1FA34DB20>)
2025-07-12 13:38:48,799:INFO:Checking exceptions
2025-07-12 13:38:48,799:INFO:Preloading libraries
2025-07-12 13:38:48,829:INFO:Set up data.
2025-07-12 13:38:48,839:INFO:Set up index.
2025-07-13 11:44:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 11:44:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 11:44:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 11:44:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 11:44:13,724:INFO:PyCaret ClassificationExperiment
2025-07-13 11:44:13,725:INFO:Logging name: clf-default-name
2025-07-13 11:44:13,725:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 11:44:13,725:INFO:version 3.3.2
2025-07-13 11:44:13,725:INFO:Initializing setup()
2025-07-13 11:44:13,725:INFO:self.USI: 9d8a
2025-07-13 11:44:13,725:INFO:self._variable_keys: {'X_train', 'seed', 'pipeline', 'logging_param', 'gpu_n_jobs_param', 'exp_name_log', 'X_test', 'fold_generator', '_available_plots', 'n_jobs_param', 'memory', 'is_multiclass', 'X', 'html_param', '_ml_usecase', 'fold_groups_param', 'fix_imbalance', 'idx', 'y_train', 'USI', 'log_plots_param', 'exp_id', 'gpu_param', 'y', 'target_param', 'y_test', 'fold_shuffle_param', 'data'}
2025-07-13 11:44:13,725:INFO:Checking environment
2025-07-13 11:44:13,725:INFO:python_version: 3.11.7
2025-07-13 11:44:13,725:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-13 11:44:13,726:INFO:machine: AMD64
2025-07-13 11:44:13,726:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 11:44:13,726:INFO:Memory: svmem(total=12698038272, available=6040125440, percent=52.4, used=6657912832, free=6040125440)
2025-07-13 11:44:13,726:INFO:Physical Core: 2
2025-07-13 11:44:13,726:INFO:Logical Core: 4
2025-07-13 11:44:13,726:INFO:Checking libraries
2025-07-13 11:44:13,726:INFO:System:
2025-07-13 11:44:13,726:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-13 11:44:13,727:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-13 11:44:13,727:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 11:44:13,727:INFO:PyCaret required dependencies:
2025-07-13 11:44:15,724:INFO:                 pip: 23.3.1
2025-07-13 11:44:15,724:INFO:          setuptools: 68.2.2
2025-07-13 11:44:15,725:INFO:             pycaret: 3.3.2
2025-07-13 11:44:15,725:INFO:             IPython: 8.20.0
2025-07-13 11:44:15,725:INFO:          ipywidgets: 7.7.2
2025-07-13 11:44:15,725:INFO:                tqdm: 4.65.0
2025-07-13 11:44:15,725:INFO:               numpy: 1.26.4
2025-07-13 11:44:15,725:INFO:              pandas: 2.1.4
2025-07-13 11:44:15,725:INFO:              jinja2: 3.1.3
2025-07-13 11:44:15,725:INFO:               scipy: 1.11.4
2025-07-13 11:44:15,725:INFO:              joblib: 1.2.0
2025-07-13 11:44:15,725:INFO:             sklearn: 1.4.2
2025-07-13 11:44:15,725:INFO:                pyod: 2.0.5
2025-07-13 11:44:15,725:INFO:            imblearn: 0.13.0
2025-07-13 11:44:15,726:INFO:   category_encoders: 2.7.0
2025-07-13 11:44:15,726:INFO:            lightgbm: 4.6.0
2025-07-13 11:44:15,726:INFO:               numba: 0.59.0
2025-07-13 11:44:15,726:INFO:            requests: 2.31.0
2025-07-13 11:44:15,726:INFO:          matplotlib: 3.7.5
2025-07-13 11:44:15,726:INFO:          scikitplot: 0.3.7
2025-07-13 11:44:15,726:INFO:         yellowbrick: 1.5
2025-07-13 11:44:15,726:INFO:              plotly: 5.24.1
2025-07-13 11:44:15,726:INFO:    plotly-resampler: Not installed
2025-07-13 11:44:15,726:INFO:             kaleido: 1.0.0
2025-07-13 11:44:15,726:INFO:           schemdraw: 0.15
2025-07-13 11:44:15,726:INFO:         statsmodels: 0.14.0
2025-07-13 11:44:15,726:INFO:              sktime: 0.26.0
2025-07-13 11:44:15,726:INFO:               tbats: 1.1.3
2025-07-13 11:44:15,726:INFO:            pmdarima: 2.0.4
2025-07-13 11:44:15,726:INFO:              psutil: 5.9.0
2025-07-13 11:44:15,726:INFO:          markupsafe: 2.1.3
2025-07-13 11:44:15,726:INFO:             pickle5: Not installed
2025-07-13 11:44:15,726:INFO:         cloudpickle: 2.2.1
2025-07-13 11:44:15,726:INFO:         deprecation: 2.1.0
2025-07-13 11:44:15,726:INFO:              xxhash: 3.5.0
2025-07-13 11:44:15,727:INFO:           wurlitzer: Not installed
2025-07-13 11:44:15,727:INFO:PyCaret optional dependencies:
2025-07-13 11:44:15,750:INFO:                shap: Not installed
2025-07-13 11:44:15,750:INFO:           interpret: Not installed
2025-07-13 11:44:15,750:INFO:                umap: Not installed
2025-07-13 11:44:15,750:INFO:     ydata_profiling: 4.7.0
2025-07-13 11:44:15,750:INFO:  explainerdashboard: Not installed
2025-07-13 11:44:15,750:INFO:             autoviz: Not installed
2025-07-13 11:44:15,750:INFO:           fairlearn: Not installed
2025-07-13 11:44:15,750:INFO:          deepchecks: Not installed
2025-07-13 11:44:15,750:INFO:             xgboost: Not installed
2025-07-13 11:44:15,750:INFO:            catboost: Not installed
2025-07-13 11:44:15,750:INFO:              kmodes: Not installed
2025-07-13 11:44:15,750:INFO:             mlxtend: Not installed
2025-07-13 11:44:15,751:INFO:       statsforecast: Not installed
2025-07-13 11:44:15,751:INFO:        tune_sklearn: Not installed
2025-07-13 11:44:15,751:INFO:                 ray: Not installed
2025-07-13 11:44:15,751:INFO:            hyperopt: Not installed
2025-07-13 11:44:15,751:INFO:              optuna: Not installed
2025-07-13 11:44:15,751:INFO:               skopt: Not installed
2025-07-13 11:44:15,751:INFO:              mlflow: Not installed
2025-07-13 11:44:15,751:INFO:              gradio: Not installed
2025-07-13 11:44:15,751:INFO:             fastapi: Not installed
2025-07-13 11:44:15,751:INFO:             uvicorn: Not installed
2025-07-13 11:44:15,751:INFO:              m2cgen: Not installed
2025-07-13 11:44:15,751:INFO:           evidently: Not installed
2025-07-13 11:44:15,751:INFO:               fugue: Not installed
2025-07-13 11:44:15,752:INFO:           streamlit: 1.46.1
2025-07-13 11:44:15,752:INFO:             prophet: Not installed
2025-07-13 11:44:15,752:INFO:None
2025-07-13 11:44:15,752:INFO:Set up data.
2025-07-13 11:44:15,771:INFO:Set up folding strategy.
2025-07-13 11:44:15,771:INFO:Set up train/test split.
2025-07-13 11:44:15,793:INFO:Set up index.
2025-07-13 11:44:15,795:INFO:Assigning column types.
2025-07-13 11:44:15,798:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 11:44:15,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 11:44:15,918:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:44:16,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 11:44:16,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:44:16,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,175:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 11:44:16,291:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:44:16,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,460:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:44:16,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,538:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 11:44:16,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:16,911:INFO:Preparing preprocessing pipeline...
2025-07-13 11:44:16,913:INFO:Set up simple imputation.
2025-07-13 11:44:16,922:INFO:Set up encoding of ordinal features.
2025-07-13 11:44:16,929:INFO:Set up encoding of categorical features.
2025-07-13 11:44:17,171:INFO:Finished creating preprocessing pipeline.
2025-07-13 11:44:17,237:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 11:44:17,237:INFO:Creating final display dataframe.
2025-07-13 11:44:17,934:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9d8a
2025-07-13 11:44:18,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:18,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:18,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:18,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:44:18,319:INFO:setup() successfully completed in 4.64s...............
2025-07-13 11:45:11,116:INFO:PyCaret ClassificationExperiment
2025-07-13 11:45:11,116:INFO:Logging name: clf-default-name
2025-07-13 11:45:11,116:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 11:45:11,116:INFO:version 3.3.2
2025-07-13 11:45:11,116:INFO:Initializing setup()
2025-07-13 11:45:11,116:INFO:self.USI: 9167
2025-07-13 11:45:11,116:INFO:self._variable_keys: {'X_train', 'seed', 'pipeline', 'logging_param', 'gpu_n_jobs_param', 'exp_name_log', 'X_test', 'fold_generator', '_available_plots', 'n_jobs_param', 'memory', 'is_multiclass', 'X', 'html_param', '_ml_usecase', 'fold_groups_param', 'fix_imbalance', 'idx', 'y_train', 'USI', 'log_plots_param', 'exp_id', 'gpu_param', 'y', 'target_param', 'y_test', 'fold_shuffle_param', 'data'}
2025-07-13 11:45:11,116:INFO:Checking environment
2025-07-13 11:45:11,117:INFO:python_version: 3.11.7
2025-07-13 11:45:11,117:INFO:python_build: ('main', 'Dec 15 2023 18:05:47')
2025-07-13 11:45:11,117:INFO:machine: AMD64
2025-07-13 11:45:11,117:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 11:45:11,117:INFO:Memory: svmem(total=12698038272, available=6004285440, percent=52.7, used=6693752832, free=6004285440)
2025-07-13 11:45:11,117:INFO:Physical Core: 2
2025-07-13 11:45:11,117:INFO:Logical Core: 4
2025-07-13 11:45:11,117:INFO:Checking libraries
2025-07-13 11:45:11,117:INFO:System:
2025-07-13 11:45:11,117:INFO:    python: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]
2025-07-13 11:45:11,118:INFO:executable: C:\Users\Cristina\anaconda3\python.exe
2025-07-13 11:45:11,118:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 11:45:11,118:INFO:PyCaret required dependencies:
2025-07-13 11:45:11,118:INFO:                 pip: 23.3.1
2025-07-13 11:45:11,118:INFO:          setuptools: 68.2.2
2025-07-13 11:45:11,119:INFO:             pycaret: 3.3.2
2025-07-13 11:45:11,119:INFO:             IPython: 8.20.0
2025-07-13 11:45:11,119:INFO:          ipywidgets: 7.7.2
2025-07-13 11:45:11,119:INFO:                tqdm: 4.65.0
2025-07-13 11:45:11,119:INFO:               numpy: 1.26.4
2025-07-13 11:45:11,119:INFO:              pandas: 2.1.4
2025-07-13 11:45:11,119:INFO:              jinja2: 3.1.3
2025-07-13 11:45:11,119:INFO:               scipy: 1.11.4
2025-07-13 11:45:11,119:INFO:              joblib: 1.2.0
2025-07-13 11:45:11,119:INFO:             sklearn: 1.4.2
2025-07-13 11:45:11,119:INFO:                pyod: 2.0.5
2025-07-13 11:45:11,119:INFO:            imblearn: 0.13.0
2025-07-13 11:45:11,120:INFO:   category_encoders: 2.7.0
2025-07-13 11:45:11,120:INFO:            lightgbm: 4.6.0
2025-07-13 11:45:11,120:INFO:               numba: 0.59.0
2025-07-13 11:45:11,120:INFO:            requests: 2.31.0
2025-07-13 11:45:11,120:INFO:          matplotlib: 3.7.5
2025-07-13 11:45:11,120:INFO:          scikitplot: 0.3.7
2025-07-13 11:45:11,120:INFO:         yellowbrick: 1.5
2025-07-13 11:45:11,120:INFO:              plotly: 5.24.1
2025-07-13 11:45:11,120:INFO:    plotly-resampler: Not installed
2025-07-13 11:45:11,120:INFO:             kaleido: 1.0.0
2025-07-13 11:45:11,120:INFO:           schemdraw: 0.15
2025-07-13 11:45:11,120:INFO:         statsmodels: 0.14.0
2025-07-13 11:45:11,120:INFO:              sktime: 0.26.0
2025-07-13 11:45:11,121:INFO:               tbats: 1.1.3
2025-07-13 11:45:11,121:INFO:            pmdarima: 2.0.4
2025-07-13 11:45:11,121:INFO:              psutil: 5.9.0
2025-07-13 11:45:11,121:INFO:          markupsafe: 2.1.3
2025-07-13 11:45:11,121:INFO:             pickle5: Not installed
2025-07-13 11:45:11,121:INFO:         cloudpickle: 2.2.1
2025-07-13 11:45:11,121:INFO:         deprecation: 2.1.0
2025-07-13 11:45:11,121:INFO:              xxhash: 3.5.0
2025-07-13 11:45:11,121:INFO:           wurlitzer: Not installed
2025-07-13 11:45:11,121:INFO:PyCaret optional dependencies:
2025-07-13 11:45:11,121:INFO:                shap: Not installed
2025-07-13 11:45:11,121:INFO:           interpret: Not installed
2025-07-13 11:45:11,121:INFO:                umap: Not installed
2025-07-13 11:45:11,121:INFO:     ydata_profiling: 4.7.0
2025-07-13 11:45:11,121:INFO:  explainerdashboard: Not installed
2025-07-13 11:45:11,121:INFO:             autoviz: Not installed
2025-07-13 11:45:11,121:INFO:           fairlearn: Not installed
2025-07-13 11:45:11,121:INFO:          deepchecks: Not installed
2025-07-13 11:45:11,121:INFO:             xgboost: Not installed
2025-07-13 11:45:11,121:INFO:            catboost: Not installed
2025-07-13 11:45:11,121:INFO:              kmodes: Not installed
2025-07-13 11:45:11,124:INFO:             mlxtend: Not installed
2025-07-13 11:45:11,124:INFO:       statsforecast: Not installed
2025-07-13 11:45:11,124:INFO:        tune_sklearn: Not installed
2025-07-13 11:45:11,124:INFO:                 ray: Not installed
2025-07-13 11:45:11,125:INFO:            hyperopt: Not installed
2025-07-13 11:45:11,125:INFO:              optuna: Not installed
2025-07-13 11:45:11,125:INFO:               skopt: Not installed
2025-07-13 11:45:11,125:INFO:              mlflow: Not installed
2025-07-13 11:45:11,125:INFO:              gradio: Not installed
2025-07-13 11:45:11,125:INFO:             fastapi: Not installed
2025-07-13 11:45:11,125:INFO:             uvicorn: Not installed
2025-07-13 11:45:11,125:INFO:              m2cgen: Not installed
2025-07-13 11:45:11,125:INFO:           evidently: Not installed
2025-07-13 11:45:11,125:INFO:               fugue: Not installed
2025-07-13 11:45:11,126:INFO:           streamlit: 1.46.1
2025-07-13 11:45:11,126:INFO:             prophet: Not installed
2025-07-13 11:45:11,126:INFO:None
2025-07-13 11:45:11,126:INFO:Set up data.
2025-07-13 11:45:11,146:INFO:Set up folding strategy.
2025-07-13 11:45:11,146:INFO:Set up train/test split.
2025-07-13 11:45:11,158:INFO:Set up index.
2025-07-13 11:45:11,159:INFO:Assigning column types.
2025-07-13 11:45:11,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 11:45:11,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,285:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,552:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 11:45:11,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 11:45:11,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:11,940:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 11:45:12,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:12,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:12,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:12,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:12,322:INFO:Preparing preprocessing pipeline...
2025-07-13 11:45:12,324:INFO:Set up simple imputation.
2025-07-13 11:45:12,331:INFO:Set up encoding of ordinal features.
2025-07-13 11:45:12,338:INFO:Set up encoding of categorical features.
2025-07-13 11:45:12,545:INFO:Finished creating preprocessing pipeline.
2025-07-13 11:45:12,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 11:45:12,592:INFO:Creating final display dataframe.
2025-07-13 11:45:13,296:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             16.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              9167
2025-07-13 11:45:13,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:13,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:13,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:13,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 11:45:13,697:INFO:setup() successfully completed in 2.61s...............
2025-07-13 11:45:31,431:INFO:Initializing compare_models()
2025-07-13 11:45:31,431:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-13 11:45:31,431:INFO:Checking exceptions
2025-07-13 11:45:31,443:INFO:Preparing display monitor
2025-07-13 11:45:31,511:INFO:Initializing Logistic Regression
2025-07-13 11:45:31,513:INFO:Total runtime is 3.3346811930338543e-05 minutes
2025-07-13 11:45:31,554:INFO:SubProcess create_model() called ==================================
2025-07-13 11:45:31,555:INFO:Initializing create_model()
2025-07-13 11:45:31,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:45:31,556:INFO:Checking exceptions
2025-07-13 11:45:31,556:INFO:Importing libraries
2025-07-13 11:45:31,556:INFO:Copying training dataset
2025-07-13 11:45:31,606:INFO:Defining folds
2025-07-13 11:45:31,606:INFO:Declaring metric variables
2025-07-13 11:45:31,615:INFO:Importing untrained model
2025-07-13 11:45:31,625:INFO:Logistic Regression Imported successfully
2025-07-13 11:45:31,662:INFO:Starting cross validation
2025-07-13 11:45:31,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:45:49,555:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:49,574:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:49,721:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:49,741:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:50,114:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:50,235:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:51,505:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:51,734:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:52,500:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:52,503:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:52,694:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:52,699:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:53,062:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:53,227:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:54,387:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:54,548:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:54,852:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:54,900:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:45:54,972:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:55,002:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:55,023:INFO:Calculating mean and std
2025-07-13 11:45:55,031:INFO:Creating metrics dataframe
2025-07-13 11:45:55,034:INFO:Uploading results into container
2025-07-13 11:45:55,034:INFO:Uploading model into container now
2025-07-13 11:45:55,034:INFO:_master_model_container: 1
2025-07-13 11:45:55,034:INFO:_display_container: 2
2025-07-13 11:45:55,034:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 11:45:55,034:INFO:create_model() successfully completed......................................
2025-07-13 11:45:55,345:INFO:SubProcess create_model() end ==================================
2025-07-13 11:45:55,345:INFO:Creating metrics dataframe
2025-07-13 11:45:55,357:INFO:Initializing K Neighbors Classifier
2025-07-13 11:45:55,357:INFO:Total runtime is 0.3974222977956136 minutes
2025-07-13 11:45:55,368:INFO:SubProcess create_model() called ==================================
2025-07-13 11:45:55,368:INFO:Initializing create_model()
2025-07-13 11:45:55,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:45:55,368:INFO:Checking exceptions
2025-07-13 11:45:55,368:INFO:Importing libraries
2025-07-13 11:45:55,368:INFO:Copying training dataset
2025-07-13 11:45:55,390:INFO:Defining folds
2025-07-13 11:45:55,390:INFO:Declaring metric variables
2025-07-13 11:45:55,399:INFO:Importing untrained model
2025-07-13 11:45:55,413:INFO:K Neighbors Classifier Imported successfully
2025-07-13 11:45:55,431:INFO:Starting cross validation
2025-07-13 11:45:55,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:45:57,714:INFO:Calculating mean and std
2025-07-13 11:45:57,716:INFO:Creating metrics dataframe
2025-07-13 11:45:57,716:INFO:Uploading results into container
2025-07-13 11:45:57,724:INFO:Uploading model into container now
2025-07-13 11:45:57,724:INFO:_master_model_container: 2
2025-07-13 11:45:57,726:INFO:_display_container: 2
2025-07-13 11:45:57,726:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-13 11:45:57,726:INFO:create_model() successfully completed......................................
2025-07-13 11:45:58,011:INFO:SubProcess create_model() end ==================================
2025-07-13 11:45:58,011:INFO:Creating metrics dataframe
2025-07-13 11:45:58,032:INFO:Initializing Naive Bayes
2025-07-13 11:45:58,032:INFO:Total runtime is 0.44200636943181354 minutes
2025-07-13 11:45:58,042:INFO:SubProcess create_model() called ==================================
2025-07-13 11:45:58,042:INFO:Initializing create_model()
2025-07-13 11:45:58,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:45:58,042:INFO:Checking exceptions
2025-07-13 11:45:58,042:INFO:Importing libraries
2025-07-13 11:45:58,042:INFO:Copying training dataset
2025-07-13 11:45:58,062:INFO:Defining folds
2025-07-13 11:45:58,062:INFO:Declaring metric variables
2025-07-13 11:45:58,077:INFO:Importing untrained model
2025-07-13 11:45:58,081:INFO:Naive Bayes Imported successfully
2025-07-13 11:45:58,107:INFO:Starting cross validation
2025-07-13 11:45:58,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:45:59,783:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:45:59,800:INFO:Calculating mean and std
2025-07-13 11:45:59,802:INFO:Creating metrics dataframe
2025-07-13 11:45:59,802:INFO:Uploading results into container
2025-07-13 11:45:59,810:INFO:Uploading model into container now
2025-07-13 11:45:59,810:INFO:_master_model_container: 3
2025-07-13 11:45:59,812:INFO:_display_container: 2
2025-07-13 11:45:59,812:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-13 11:45:59,812:INFO:create_model() successfully completed......................................
2025-07-13 11:46:00,063:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:00,063:INFO:Creating metrics dataframe
2025-07-13 11:46:00,083:INFO:Initializing Decision Tree Classifier
2025-07-13 11:46:00,083:INFO:Total runtime is 0.47619307835896807 minutes
2025-07-13 11:46:00,083:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:00,083:INFO:Initializing create_model()
2025-07-13 11:46:00,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:00,083:INFO:Checking exceptions
2025-07-13 11:46:00,083:INFO:Importing libraries
2025-07-13 11:46:00,083:INFO:Copying training dataset
2025-07-13 11:46:00,093:INFO:Defining folds
2025-07-13 11:46:00,093:INFO:Declaring metric variables
2025-07-13 11:46:00,109:INFO:Importing untrained model
2025-07-13 11:46:00,109:INFO:Decision Tree Classifier Imported successfully
2025-07-13 11:46:00,124:INFO:Starting cross validation
2025-07-13 11:46:00,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:01,865:INFO:Calculating mean and std
2025-07-13 11:46:01,865:INFO:Creating metrics dataframe
2025-07-13 11:46:01,865:INFO:Uploading results into container
2025-07-13 11:46:01,865:INFO:Uploading model into container now
2025-07-13 11:46:01,873:INFO:_master_model_container: 4
2025-07-13 11:46:01,873:INFO:_display_container: 2
2025-07-13 11:46:01,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-13 11:46:01,873:INFO:create_model() successfully completed......................................
2025-07-13 11:46:02,096:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:02,097:INFO:Creating metrics dataframe
2025-07-13 11:46:02,120:INFO:Initializing SVM - Linear Kernel
2025-07-13 11:46:02,120:INFO:Total runtime is 0.5101396282513936 minutes
2025-07-13 11:46:02,122:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:02,122:INFO:Initializing create_model()
2025-07-13 11:46:02,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:02,122:INFO:Checking exceptions
2025-07-13 11:46:02,122:INFO:Importing libraries
2025-07-13 11:46:02,122:INFO:Copying training dataset
2025-07-13 11:46:02,141:INFO:Defining folds
2025-07-13 11:46:02,141:INFO:Declaring metric variables
2025-07-13 11:46:02,156:INFO:Importing untrained model
2025-07-13 11:46:02,156:INFO:SVM - Linear Kernel Imported successfully
2025-07-13 11:46:02,177:INFO:Starting cross validation
2025-07-13 11:46:02,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:02,925:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:03,649:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:03,655:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:03,676:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:04,095:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:04,136:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:04,148:INFO:Calculating mean and std
2025-07-13 11:46:04,156:INFO:Creating metrics dataframe
2025-07-13 11:46:04,158:INFO:Uploading results into container
2025-07-13 11:46:04,158:INFO:Uploading model into container now
2025-07-13 11:46:04,158:INFO:_master_model_container: 5
2025-07-13 11:46:04,158:INFO:_display_container: 2
2025-07-13 11:46:04,158:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-13 11:46:04,158:INFO:create_model() successfully completed......................................
2025-07-13 11:46:04,398:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:04,408:INFO:Creating metrics dataframe
2025-07-13 11:46:04,420:INFO:Initializing Ridge Classifier
2025-07-13 11:46:04,420:INFO:Total runtime is 0.5484713673591614 minutes
2025-07-13 11:46:04,435:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:04,436:INFO:Initializing create_model()
2025-07-13 11:46:04,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:04,437:INFO:Checking exceptions
2025-07-13 11:46:04,437:INFO:Importing libraries
2025-07-13 11:46:04,437:INFO:Copying training dataset
2025-07-13 11:46:04,455:INFO:Defining folds
2025-07-13 11:46:04,457:INFO:Declaring metric variables
2025-07-13 11:46:04,472:INFO:Importing untrained model
2025-07-13 11:46:04,483:INFO:Ridge Classifier Imported successfully
2025-07-13 11:46:04,501:INFO:Starting cross validation
2025-07-13 11:46:04,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:05,058:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,069:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,130:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,139:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,823:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,846:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,864:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:05,886:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:06,304:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:06,321:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:06,352:INFO:Calculating mean and std
2025-07-13 11:46:06,360:INFO:Creating metrics dataframe
2025-07-13 11:46:06,362:INFO:Uploading results into container
2025-07-13 11:46:06,362:INFO:Uploading model into container now
2025-07-13 11:46:06,362:INFO:_master_model_container: 6
2025-07-13 11:46:06,362:INFO:_display_container: 2
2025-07-13 11:46:06,362:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-13 11:46:06,370:INFO:create_model() successfully completed......................................
2025-07-13 11:46:06,657:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:06,658:INFO:Creating metrics dataframe
2025-07-13 11:46:06,680:INFO:Initializing Random Forest Classifier
2025-07-13 11:46:06,680:INFO:Total runtime is 0.5861491123835245 minutes
2025-07-13 11:46:06,686:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:06,686:INFO:Initializing create_model()
2025-07-13 11:46:06,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:06,686:INFO:Checking exceptions
2025-07-13 11:46:06,686:INFO:Importing libraries
2025-07-13 11:46:06,686:INFO:Copying training dataset
2025-07-13 11:46:06,727:INFO:Defining folds
2025-07-13 11:46:06,727:INFO:Declaring metric variables
2025-07-13 11:46:06,744:INFO:Importing untrained model
2025-07-13 11:46:06,756:INFO:Random Forest Classifier Imported successfully
2025-07-13 11:46:06,800:INFO:Starting cross validation
2025-07-13 11:46:06,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:13,565:INFO:Calculating mean and std
2025-07-13 11:46:13,565:INFO:Creating metrics dataframe
2025-07-13 11:46:13,571:INFO:Uploading results into container
2025-07-13 11:46:13,573:INFO:Uploading model into container now
2025-07-13 11:46:13,573:INFO:_master_model_container: 7
2025-07-13 11:46:13,573:INFO:_display_container: 2
2025-07-13 11:46:13,573:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-13 11:46:13,573:INFO:create_model() successfully completed......................................
2025-07-13 11:46:13,807:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:13,808:INFO:Creating metrics dataframe
2025-07-13 11:46:13,821:INFO:Initializing Quadratic Discriminant Analysis
2025-07-13 11:46:13,821:INFO:Total runtime is 0.7051574826240539 minutes
2025-07-13 11:46:13,825:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:13,826:INFO:Initializing create_model()
2025-07-13 11:46:13,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:13,826:INFO:Checking exceptions
2025-07-13 11:46:13,827:INFO:Importing libraries
2025-07-13 11:46:13,827:INFO:Copying training dataset
2025-07-13 11:46:13,839:INFO:Defining folds
2025-07-13 11:46:13,840:INFO:Declaring metric variables
2025-07-13 11:46:13,848:INFO:Importing untrained model
2025-07-13 11:46:13,852:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-13 11:46:13,870:INFO:Starting cross validation
2025-07-13 11:46:13,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:14,221:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,229:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,246:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,650:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,650:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,670:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:14,680:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:15,015:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:15,019:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 11:46:15,099:INFO:Calculating mean and std
2025-07-13 11:46:15,099:INFO:Creating metrics dataframe
2025-07-13 11:46:15,099:INFO:Uploading results into container
2025-07-13 11:46:15,099:INFO:Uploading model into container now
2025-07-13 11:46:15,099:INFO:_master_model_container: 8
2025-07-13 11:46:15,099:INFO:_display_container: 2
2025-07-13 11:46:15,099:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-13 11:46:15,099:INFO:create_model() successfully completed......................................
2025-07-13 11:46:15,296:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:15,297:INFO:Creating metrics dataframe
2025-07-13 11:46:15,299:INFO:Initializing Ada Boost Classifier
2025-07-13 11:46:15,299:INFO:Total runtime is 0.7297946254412332 minutes
2025-07-13 11:46:15,318:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:15,318:INFO:Initializing create_model()
2025-07-13 11:46:15,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:15,319:INFO:Checking exceptions
2025-07-13 11:46:15,319:INFO:Importing libraries
2025-07-13 11:46:15,320:INFO:Copying training dataset
2025-07-13 11:46:15,331:INFO:Defining folds
2025-07-13 11:46:15,331:INFO:Declaring metric variables
2025-07-13 11:46:15,331:INFO:Importing untrained model
2025-07-13 11:46:15,352:INFO:Ada Boost Classifier Imported successfully
2025-07-13 11:46:15,364:INFO:Starting cross validation
2025-07-13 11:46:15,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:15,726:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:15,736:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:15,766:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:15,814:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:17,087:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:17,147:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:17,157:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:17,218:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:18,691:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:18,778:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 11:46:19,774:INFO:Calculating mean and std
2025-07-13 11:46:19,774:INFO:Creating metrics dataframe
2025-07-13 11:46:19,787:INFO:Uploading results into container
2025-07-13 11:46:19,788:INFO:Uploading model into container now
2025-07-13 11:46:19,790:INFO:_master_model_container: 9
2025-07-13 11:46:19,790:INFO:_display_container: 2
2025-07-13 11:46:19,791:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-13 11:46:19,791:INFO:create_model() successfully completed......................................
2025-07-13 11:46:20,108:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:20,108:INFO:Creating metrics dataframe
2025-07-13 11:46:20,126:INFO:Initializing Gradient Boosting Classifier
2025-07-13 11:46:20,126:INFO:Total runtime is 0.8102444847424823 minutes
2025-07-13 11:46:20,136:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:20,136:INFO:Initializing create_model()
2025-07-13 11:46:20,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:20,136:INFO:Checking exceptions
2025-07-13 11:46:20,136:INFO:Importing libraries
2025-07-13 11:46:20,136:INFO:Copying training dataset
2025-07-13 11:46:20,152:INFO:Defining folds
2025-07-13 11:46:20,152:INFO:Declaring metric variables
2025-07-13 11:46:20,152:INFO:Importing untrained model
2025-07-13 11:46:20,176:INFO:Gradient Boosting Classifier Imported successfully
2025-07-13 11:46:20,194:INFO:Starting cross validation
2025-07-13 11:46:20,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:27,972:INFO:Calculating mean and std
2025-07-13 11:46:27,972:INFO:Creating metrics dataframe
2025-07-13 11:46:27,972:INFO:Uploading results into container
2025-07-13 11:46:27,972:INFO:Uploading model into container now
2025-07-13 11:46:27,972:INFO:_master_model_container: 10
2025-07-13 11:46:27,980:INFO:_display_container: 2
2025-07-13 11:46:27,980:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-13 11:46:27,980:INFO:create_model() successfully completed......................................
2025-07-13 11:46:28,200:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:28,201:INFO:Creating metrics dataframe
2025-07-13 11:46:28,215:INFO:Initializing Linear Discriminant Analysis
2025-07-13 11:46:28,215:INFO:Total runtime is 0.9450651526451109 minutes
2025-07-13 11:46:28,229:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:28,229:INFO:Initializing create_model()
2025-07-13 11:46:28,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:28,230:INFO:Checking exceptions
2025-07-13 11:46:28,230:INFO:Importing libraries
2025-07-13 11:46:28,231:INFO:Copying training dataset
2025-07-13 11:46:28,248:INFO:Defining folds
2025-07-13 11:46:28,248:INFO:Declaring metric variables
2025-07-13 11:46:28,255:INFO:Importing untrained model
2025-07-13 11:46:28,266:INFO:Linear Discriminant Analysis Imported successfully
2025-07-13 11:46:28,282:INFO:Starting cross validation
2025-07-13 11:46:28,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:28,858:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:28,877:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:28,909:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:28,929:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,454:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,487:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,526:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,546:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,951:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,951:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:29,969:INFO:Calculating mean and std
2025-07-13 11:46:29,972:INFO:Creating metrics dataframe
2025-07-13 11:46:29,977:INFO:Uploading results into container
2025-07-13 11:46:29,978:INFO:Uploading model into container now
2025-07-13 11:46:29,978:INFO:_master_model_container: 11
2025-07-13 11:46:29,978:INFO:_display_container: 2
2025-07-13 11:46:29,979:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-13 11:46:29,979:INFO:create_model() successfully completed......................................
2025-07-13 11:46:30,202:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:30,202:INFO:Creating metrics dataframe
2025-07-13 11:46:30,239:INFO:Initializing Extra Trees Classifier
2025-07-13 11:46:30,239:INFO:Total runtime is 0.9787919362386066 minutes
2025-07-13 11:46:30,239:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:30,239:INFO:Initializing create_model()
2025-07-13 11:46:30,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:30,239:INFO:Checking exceptions
2025-07-13 11:46:30,239:INFO:Importing libraries
2025-07-13 11:46:30,239:INFO:Copying training dataset
2025-07-13 11:46:30,263:INFO:Defining folds
2025-07-13 11:46:30,263:INFO:Declaring metric variables
2025-07-13 11:46:30,274:INFO:Importing untrained model
2025-07-13 11:46:30,286:INFO:Extra Trees Classifier Imported successfully
2025-07-13 11:46:30,305:INFO:Starting cross validation
2025-07-13 11:46:30,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:36,789:INFO:Calculating mean and std
2025-07-13 11:46:36,789:INFO:Creating metrics dataframe
2025-07-13 11:46:36,797:INFO:Uploading results into container
2025-07-13 11:46:36,797:INFO:Uploading model into container now
2025-07-13 11:46:36,799:INFO:_master_model_container: 12
2025-07-13 11:46:36,799:INFO:_display_container: 2
2025-07-13 11:46:36,799:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-13 11:46:36,799:INFO:create_model() successfully completed......................................
2025-07-13 11:46:37,079:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:37,079:INFO:Creating metrics dataframe
2025-07-13 11:46:37,101:INFO:Initializing Light Gradient Boosting Machine
2025-07-13 11:46:37,101:INFO:Total runtime is 1.0931593378384907 minutes
2025-07-13 11:46:37,110:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:37,110:INFO:Initializing create_model()
2025-07-13 11:46:37,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:37,110:INFO:Checking exceptions
2025-07-13 11:46:37,110:INFO:Importing libraries
2025-07-13 11:46:37,110:INFO:Copying training dataset
2025-07-13 11:46:37,131:INFO:Defining folds
2025-07-13 11:46:37,131:INFO:Declaring metric variables
2025-07-13 11:46:37,142:INFO:Importing untrained model
2025-07-13 11:46:37,151:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 11:46:37,162:INFO:Starting cross validation
2025-07-13 11:46:37,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:42,018:INFO:Calculating mean and std
2025-07-13 11:46:42,027:INFO:Creating metrics dataframe
2025-07-13 11:46:42,028:INFO:Uploading results into container
2025-07-13 11:46:42,028:INFO:Uploading model into container now
2025-07-13 11:46:42,028:INFO:_master_model_container: 13
2025-07-13 11:46:42,028:INFO:_display_container: 2
2025-07-13 11:46:42,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:46:42,028:INFO:create_model() successfully completed......................................
2025-07-13 11:46:42,258:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:42,258:INFO:Creating metrics dataframe
2025-07-13 11:46:42,308:INFO:Initializing Dummy Classifier
2025-07-13 11:46:42,311:INFO:Total runtime is 1.1799857099850972 minutes
2025-07-13 11:46:42,317:INFO:SubProcess create_model() called ==================================
2025-07-13 11:46:42,318:INFO:Initializing create_model()
2025-07-13 11:46:42,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D7EB89810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:42,319:INFO:Checking exceptions
2025-07-13 11:46:42,320:INFO:Importing libraries
2025-07-13 11:46:42,320:INFO:Copying training dataset
2025-07-13 11:46:42,331:INFO:Defining folds
2025-07-13 11:46:42,331:INFO:Declaring metric variables
2025-07-13 11:46:42,341:INFO:Importing untrained model
2025-07-13 11:46:42,351:INFO:Dummy Classifier Imported successfully
2025-07-13 11:46:42,359:INFO:Starting cross validation
2025-07-13 11:46:42,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:46:42,915:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:42,929:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:42,935:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,000:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,466:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,496:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,496:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,567:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,758:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,768:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 11:46:43,778:INFO:Calculating mean and std
2025-07-13 11:46:43,778:INFO:Creating metrics dataframe
2025-07-13 11:46:43,786:INFO:Uploading results into container
2025-07-13 11:46:43,786:INFO:Uploading model into container now
2025-07-13 11:46:43,786:INFO:_master_model_container: 14
2025-07-13 11:46:43,786:INFO:_display_container: 2
2025-07-13 11:46:43,786:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-13 11:46:43,786:INFO:create_model() successfully completed......................................
2025-07-13 11:46:43,975:INFO:SubProcess create_model() end ==================================
2025-07-13 11:46:43,975:INFO:Creating metrics dataframe
2025-07-13 11:46:43,997:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-13 11:46:44,000:INFO:Initializing create_model()
2025-07-13 11:46:44,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:46:44,000:INFO:Checking exceptions
2025-07-13 11:46:44,015:INFO:Importing libraries
2025-07-13 11:46:44,015:INFO:Copying training dataset
2025-07-13 11:46:44,015:INFO:Defining folds
2025-07-13 11:46:44,015:INFO:Declaring metric variables
2025-07-13 11:46:44,015:INFO:Importing untrained model
2025-07-13 11:46:44,015:INFO:Declaring custom model
2025-07-13 11:46:44,015:INFO:Logistic Regression Imported successfully
2025-07-13 11:46:44,015:INFO:Cross validation set to False
2025-07-13 11:46:44,015:INFO:Fitting Model
2025-07-13 11:46:45,176:WARNING:C:\Users\Cristina\anaconda3\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 11:46:45,178:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 11:46:45,178:INFO:create_model() successfully completed......................................
2025-07-13 11:46:45,429:INFO:_master_model_container: 14
2025-07-13 11:46:45,429:INFO:_display_container: 2
2025-07-13 11:46:45,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 11:46:45,429:INFO:compare_models() successfully completed......................................
2025-07-13 11:48:20,886:INFO:Initializing create_model()
2025-07-13 11:48:20,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:48:20,887:INFO:Checking exceptions
2025-07-13 11:48:20,930:INFO:Importing libraries
2025-07-13 11:48:20,930:INFO:Copying training dataset
2025-07-13 11:48:20,944:INFO:Defining folds
2025-07-13 11:48:20,944:INFO:Declaring metric variables
2025-07-13 11:48:20,962:INFO:Importing untrained model
2025-07-13 11:48:20,972:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 11:48:20,990:INFO:Starting cross validation
2025-07-13 11:48:20,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:48:23,569:INFO:Calculating mean and std
2025-07-13 11:48:23,569:INFO:Creating metrics dataframe
2025-07-13 11:48:23,588:INFO:Finalizing model
2025-07-13 11:48:23,783:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 11:48:23,784:INFO:[LightGBM] [Info] Number of positive: 484, number of negative: 6166
2025-07-13 11:48:23,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.
2025-07-13 11:48:23,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 11:48:23,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 11:48:23,786:INFO:[LightGBM] [Info] Total Bins 614
2025-07-13 11:48:23,786:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 11:48:23,786:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.072782 -> initscore=-2.544721
2025-07-13 11:48:23,786:INFO:[LightGBM] [Info] Start training from score -2.544721
2025-07-13 11:48:23,925:INFO:Uploading results into container
2025-07-13 11:48:23,925:INFO:Uploading model into container now
2025-07-13 11:48:23,956:INFO:_master_model_container: 15
2025-07-13 11:48:23,956:INFO:_display_container: 3
2025-07-13 11:48:23,956:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:48:23,956:INFO:create_model() successfully completed......................................
2025-07-13 11:49:03,775:INFO:Initializing tune_model()
2025-07-13 11:49:03,775:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-13 11:49:03,776:INFO:Checking exceptions
2025-07-13 11:49:03,823:INFO:Copying training dataset
2025-07-13 11:49:03,835:INFO:Checking base model
2025-07-13 11:49:03,836:INFO:Base model : Light Gradient Boosting Machine
2025-07-13 11:49:03,848:INFO:Declaring metric variables
2025-07-13 11:49:03,856:INFO:Defining Hyperparameters
2025-07-13 11:49:04,055:INFO:Tuning with n_jobs=-1
2025-07-13 11:49:04,055:INFO:Initializing RandomizedSearchCV
2025-07-13 11:49:26,736:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-07-13 11:49:26,744:INFO:Hyperparameter search completed
2025-07-13 11:49:26,744:INFO:SubProcess create_model() called ==================================
2025-07-13 11:49:26,746:INFO:Initializing create_model()
2025-07-13 11:49:26,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021D65A8CD50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-07-13 11:49:26,746:INFO:Checking exceptions
2025-07-13 11:49:26,746:INFO:Importing libraries
2025-07-13 11:49:26,746:INFO:Copying training dataset
2025-07-13 11:49:26,767:INFO:Defining folds
2025-07-13 11:49:26,767:INFO:Declaring metric variables
2025-07-13 11:49:26,775:INFO:Importing untrained model
2025-07-13 11:49:26,775:INFO:Declaring custom model
2025-07-13 11:49:26,787:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 11:49:26,797:INFO:Starting cross validation
2025-07-13 11:49:26,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:49:28,838:INFO:Calculating mean and std
2025-07-13 11:49:28,840:INFO:Creating metrics dataframe
2025-07-13 11:49:28,850:INFO:Finalizing model
2025-07-13 11:49:29,072:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:49:29,073:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:49:29,073:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:49:29,084:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 11:49:29,084:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:49:29,084:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:49:29,084:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] Number of positive: 484, number of negative: 6166
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000822 seconds.
2025-07-13 11:49:29,084:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 11:49:29,084:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] Total Bins 616
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 28
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.072782 -> initscore=-2.544721
2025-07-13 11:49:29,084:INFO:[LightGBM] [Info] Start training from score -2.544721
2025-07-13 11:49:29,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:49:29,179:INFO:Uploading results into container
2025-07-13 11:49:29,179:INFO:Uploading model into container now
2025-07-13 11:49:29,179:INFO:_master_model_container: 16
2025-07-13 11:49:29,179:INFO:_display_container: 4
2025-07-13 11:49:29,179:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:49:29,179:INFO:create_model() successfully completed......................................
2025-07-13 11:49:29,414:INFO:SubProcess create_model() end ==================================
2025-07-13 11:49:29,414:INFO:choose_better activated
2025-07-13 11:49:29,418:INFO:SubProcess create_model() called ==================================
2025-07-13 11:49:29,420:INFO:Initializing create_model()
2025-07-13 11:49:29,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:49:29,420:INFO:Checking exceptions
2025-07-13 11:49:29,423:INFO:Importing libraries
2025-07-13 11:49:29,423:INFO:Copying training dataset
2025-07-13 11:49:29,436:INFO:Defining folds
2025-07-13 11:49:29,437:INFO:Declaring metric variables
2025-07-13 11:49:29,437:INFO:Importing untrained model
2025-07-13 11:49:29,437:INFO:Declaring custom model
2025-07-13 11:49:29,439:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 11:49:29,439:INFO:Starting cross validation
2025-07-13 11:49:29,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 11:49:32,549:INFO:Calculating mean and std
2025-07-13 11:49:32,549:INFO:Creating metrics dataframe
2025-07-13 11:49:32,549:INFO:Finalizing model
2025-07-13 11:49:32,772:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 11:49:32,772:INFO:[LightGBM] [Info] Number of positive: 484, number of negative: 6166
2025-07-13 11:49:32,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.
2025-07-13 11:49:32,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 11:49:32,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 11:49:32,788:INFO:[LightGBM] [Info] Total Bins 614
2025-07-13 11:49:32,788:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 11:49:32,788:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.072782 -> initscore=-2.544721
2025-07-13 11:49:32,788:INFO:[LightGBM] [Info] Start training from score -2.544721
2025-07-13 11:49:32,960:INFO:Uploading results into container
2025-07-13 11:49:32,960:INFO:Uploading model into container now
2025-07-13 11:49:32,960:INFO:_master_model_container: 17
2025-07-13 11:49:32,960:INFO:_display_container: 5
2025-07-13 11:49:32,960:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:49:32,960:INFO:create_model() successfully completed......................................
2025-07-13 11:49:33,209:INFO:SubProcess create_model() end ==================================
2025-07-13 11:49:33,210:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1073
2025-07-13 11:49:33,210:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1369
2025-07-13 11:49:33,210:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-07-13 11:49:33,210:INFO:choose_better completed
2025-07-13 11:49:33,227:INFO:_master_model_container: 17
2025-07-13 11:49:33,227:INFO:_display_container: 4
2025-07-13 11:49:33,227:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:49:33,227:INFO:tune_model() successfully completed......................................
2025-07-13 11:50:45,893:INFO:Initializing plot_model()
2025-07-13 11:50:45,894:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 11:50:45,895:INFO:Checking exceptions
2025-07-13 11:50:45,906:INFO:Preloading libraries
2025-07-13 11:50:45,919:INFO:Copying training dataset
2025-07-13 11:50:45,919:INFO:Plot type: auc
2025-07-13 11:50:46,137:INFO:Fitting Model
2025-07-13 11:50:46,137:INFO:Scoring test/hold-out set
2025-07-13 11:50:46,137:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:50:46,137:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:50:46,137:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:50:46,152:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:50:46,152:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:50:46,152:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:50:46,600:INFO:Visual Rendered Successfully
2025-07-13 11:50:46,785:INFO:plot_model() successfully completed......................................
2025-07-13 11:50:48,173:INFO:Initializing plot_model()
2025-07-13 11:50:48,173:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 11:50:48,173:INFO:Checking exceptions
2025-07-13 11:50:48,185:INFO:Preloading libraries
2025-07-13 11:50:48,195:INFO:Copying training dataset
2025-07-13 11:50:48,195:INFO:Plot type: auc
2025-07-13 11:50:48,400:INFO:Fitting Model
2025-07-13 11:50:48,400:INFO:Scoring test/hold-out set
2025-07-13 11:50:48,400:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:50:48,400:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:50:48,400:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:50:48,410:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:50:48,410:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:50:48,410:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:50:48,781:INFO:Visual Rendered Successfully
2025-07-13 11:50:48,968:INFO:plot_model() successfully completed......................................
2025-07-13 11:50:49,997:INFO:Initializing plot_model()
2025-07-13 11:50:49,997:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 11:50:49,998:INFO:Checking exceptions
2025-07-13 11:50:50,013:INFO:Preloading libraries
2025-07-13 11:50:50,022:INFO:Copying training dataset
2025-07-13 11:50:50,022:INFO:Plot type: feature
2025-07-13 11:50:50,023:WARNING:No coef_ found. Trying feature_importances_
2025-07-13 11:50:50,461:INFO:Visual Rendered Successfully
2025-07-13 11:50:50,700:INFO:plot_model() successfully completed......................................
2025-07-13 11:51:00,289:INFO:Initializing plot_model()
2025-07-13 11:51:00,289:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 11:51:00,290:INFO:Checking exceptions
2025-07-13 11:51:00,303:INFO:Preloading libraries
2025-07-13 11:51:00,312:INFO:Copying training dataset
2025-07-13 11:51:00,312:INFO:Plot type: confusion_matrix
2025-07-13 11:51:00,515:INFO:Fitting Model
2025-07-13 11:51:00,515:INFO:Scoring test/hold-out set
2025-07-13 11:51:00,515:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:51:00,515:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:51:00,515:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:51:00,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:51:00,525:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:51:00,525:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:51:00,758:INFO:Visual Rendered Successfully
2025-07-13 11:51:00,948:INFO:plot_model() successfully completed......................................
2025-07-13 11:51:04,882:INFO:Initializing predict_model()
2025-07-13 11:51:04,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D5F4FD440>)
2025-07-13 11:51:04,883:INFO:Checking exceptions
2025-07-13 11:51:04,884:INFO:Preloading libraries
2025-07-13 11:51:07,931:INFO:Initializing predict_model()
2025-07-13 11:51:07,931:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D65A6BCE0>)
2025-07-13 11:51:07,932:INFO:Checking exceptions
2025-07-13 11:51:07,932:INFO:Preloading libraries
2025-07-13 11:51:10,097:INFO:Initializing predict_model()
2025-07-13 11:51:10,097:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D65A6BCE0>)
2025-07-13 11:51:10,097:INFO:Checking exceptions
2025-07-13 11:51:10,098:INFO:Preloading libraries
2025-07-13 11:53:02,216:INFO:Initializing finalize_model()
2025-07-13 11:53:02,218:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-13 11:53:02,221:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 11:53:02,236:INFO:Initializing create_model()
2025-07-13 11:53:02,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 11:53:02,236:INFO:Checking exceptions
2025-07-13 11:53:02,239:INFO:Importing libraries
2025-07-13 11:53:02,239:INFO:Copying training dataset
2025-07-13 11:53:02,240:INFO:Defining folds
2025-07-13 11:53:02,240:INFO:Declaring metric variables
2025-07-13 11:53:02,240:INFO:Importing untrained model
2025-07-13 11:53:02,240:INFO:Declaring custom model
2025-07-13 11:53:02,243:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 11:53:02,247:INFO:Cross validation set to False
2025-07-13 11:53:02,247:INFO:Fitting Model
2025-07-13 11:53:02,447:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:53:02,447:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:53:02,447:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:53:02,457:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 11:53:02,457:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 11:53:02,457:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 11:53:02,457:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 11:53:02,457:INFO:[LightGBM] [Info] Number of positive: 692, number of negative: 8808
2025-07-13 11:53:02,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.
2025-07-13 11:53:02,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 11:53:02,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 11:53:02,465:INFO:[LightGBM] [Info] Total Bins 616
2025-07-13 11:53:02,467:INFO:[LightGBM] [Info] Number of data points in the train set: 9500, number of used features: 28
2025-07-13 11:53:02,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.072842 -> initscore=-2.543830
2025-07-13 11:53:02,467:INFO:[LightGBM] [Info] Start training from score -2.543830
2025-07-13 11:53:02,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 11:53:02,636:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 11:53:02,636:INFO:create_model() successfully completed......................................
2025-07-13 11:53:02,839:INFO:_master_model_container: 17
2025-07-13 11:53:02,839:INFO:_display_container: 7
2025-07-13 11:53:02,900:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 11:53:02,900:INFO:finalize_model() successfully completed......................................
2025-07-13 11:53:04,888:INFO:Initializing load_model()
2025-07-13 11:53:04,889:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-13 11:53:05,775:INFO:Initializing load_model()
2025-07-13 11:53:05,776:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-13 11:55:49,525:INFO:Initializing predict_model()
2025-07-13 11:55:49,525:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D7EB63F60>)
2025-07-13 11:55:49,526:INFO:Checking exceptions
2025-07-13 11:55:49,526:INFO:Preloading libraries
2025-07-13 11:56:23,112:INFO:Initializing predict_model()
2025-07-13 11:56:23,112:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D7EB63BA0>)
2025-07-13 11:56:23,113:INFO:Checking exceptions
2025-07-13 11:56:23,113:INFO:Preloading libraries
2025-07-13 11:56:23,117:INFO:Set up data.
2025-07-13 11:56:23,134:INFO:Set up index.
2025-07-13 11:57:49,010:INFO:Initializing save_model()
2025-07-13 11:57:49,010:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=Final GBC Model 02Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-13 11:57:49,010:INFO:Adding model into prep_pipe
2025-07-13 11:57:49,010:WARNING:Only Model saved as it was a pipeline.
2025-07-13 11:57:49,026:INFO:Final GBC Model 02Jun2022.pkl saved in current working directory
2025-07-13 11:57:49,125:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 11:57:49,125:INFO:save_model() successfully completed......................................
2025-07-13 11:58:03,968:INFO:Initializing load_model()
2025-07-13 11:58:03,969:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-13 11:58:19,475:INFO:Initializing predict_model()
2025-07-13 11:58:19,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021D7DCF9C90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021D60174220>)
2025-07-13 11:58:19,476:INFO:Checking exceptions
2025-07-13 11:58:19,476:INFO:Preloading libraries
2025-07-13 11:58:19,481:INFO:Set up data.
2025-07-13 11:58:19,505:INFO:Set up index.
2025-07-13 13:41:31,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 13:41:31,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 13:41:31,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 13:41:31,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 13:42:01,567:INFO:Initializing load_model()
2025-07-13 13:42:01,567:INFO:load_model(model_name=LR Model Aula 5 062022, platform=None, authentication=None, verbose=True)
2025-07-13 13:42:03,011:INFO:Initializing predict_model()
2025-07-13 13:42:03,011:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024D7E59B7D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sexo', 'posse_de_veiculo',
                                             'posse_de_imovel', 'tipo_renda',
                                             'educacao', 'estado_civil',
                                             'tipo_residencia'],
                                    tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('transformation',
                 TransformerWrapper(transformer=QuantileTransformer(output_distribution='normal',
                                                                    random_state=6840))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 GradientBoostingClassifier(random_state=6840))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024D7E9AB4C0>)
2025-07-13 13:42:03,011:INFO:Checking exceptions
2025-07-13 13:42:03,011:INFO:Preloading libraries
2025-07-13 13:42:03,011:INFO:Set up data.
2025-07-13 13:42:03,064:INFO:Set up index.
2025-07-13 14:12:03,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:12:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:12:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:12:03,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:19:44,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:19:44,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:19:44,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:19:44,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:27:17,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:27:17,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:27:17,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:27:17,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:57:22,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:57:22,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:57:22,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:57:22,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 14:57:23,231:INFO:PyCaret ClassificationExperiment
2025-07-13 14:57:23,231:INFO:Logging name: clf-default-name
2025-07-13 14:57:23,232:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 14:57:23,232:INFO:version 3.3.2
2025-07-13 14:57:23,232:INFO:Initializing setup()
2025-07-13 14:57:23,232:INFO:self.USI: ab33
2025-07-13 14:57:23,232:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'seed', 'y_test', 'html_param', 'X_train', 'fold_shuffle_param', 'memory', 'exp_name_log', 'exp_id', 'is_multiclass', 'USI', 'gpu_param', 'fold_generator', 'y_train', 'data', 'X', 'fix_imbalance', 'target_param', 'logging_param', 'idx', 'pipeline', '_ml_usecase', 'log_plots_param', '_available_plots', 'X_test', 'n_jobs_param', 'y'}
2025-07-13 14:57:23,233:INFO:Checking environment
2025-07-13 14:57:23,233:INFO:python_version: 3.11.0
2025-07-13 14:57:23,233:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-07-13 14:57:23,233:INFO:machine: AMD64
2025-07-13 14:57:23,251:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 14:57:23,256:INFO:Memory: svmem(total=12698038272, available=3046879232, percent=76.0, used=9651159040, free=3046879232)
2025-07-13 14:57:23,256:INFO:Physical Core: 2
2025-07-13 14:57:23,256:INFO:Logical Core: 4
2025-07-13 14:57:23,256:INFO:Checking libraries
2025-07-13 14:57:23,256:INFO:System:
2025-07-13 14:57:23,257:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-07-13 14:57:23,257:INFO:executable: C:\Users\Cristina\AppData\Local\Programs\Python\Python311\python.exe
2025-07-13 14:57:23,257:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 14:57:23,257:INFO:PyCaret required dependencies:
2025-07-13 14:57:23,343:INFO:                 pip: 25.1.1
2025-07-13 14:57:23,343:INFO:          setuptools: 65.5.0
2025-07-13 14:57:23,343:INFO:             pycaret: 3.3.2
2025-07-13 14:57:23,343:INFO:             IPython: 9.4.0
2025-07-13 14:57:23,343:INFO:          ipywidgets: 8.1.7
2025-07-13 14:57:23,343:INFO:                tqdm: 4.67.1
2025-07-13 14:57:23,343:INFO:               numpy: 1.26.4
2025-07-13 14:57:23,343:INFO:              pandas: 2.1.4
2025-07-13 14:57:23,343:INFO:              jinja2: 3.1.6
2025-07-13 14:57:23,343:INFO:               scipy: 1.11.4
2025-07-13 14:57:23,343:INFO:              joblib: 1.3.2
2025-07-13 14:57:23,343:INFO:             sklearn: 1.4.2
2025-07-13 14:57:23,343:INFO:                pyod: 2.0.5
2025-07-13 14:57:23,343:INFO:            imblearn: 0.13.0
2025-07-13 14:57:23,343:INFO:   category_encoders: 2.7.0
2025-07-13 14:57:23,343:INFO:            lightgbm: 4.6.0
2025-07-13 14:57:23,343:INFO:               numba: 0.61.2
2025-07-13 14:57:23,343:INFO:            requests: 2.32.3
2025-07-13 14:57:23,343:INFO:          matplotlib: 3.7.5
2025-07-13 14:57:23,343:INFO:          scikitplot: 0.3.7
2025-07-13 14:57:23,343:INFO:         yellowbrick: 1.5
2025-07-13 14:57:23,343:INFO:              plotly: 5.24.1
2025-07-13 14:57:23,343:INFO:    plotly-resampler: Not installed
2025-07-13 14:57:23,343:INFO:             kaleido: 1.0.0
2025-07-13 14:57:23,343:INFO:           schemdraw: 0.15
2025-07-13 14:57:23,343:INFO:         statsmodels: 0.14.4
2025-07-13 14:57:23,343:INFO:              sktime: 0.26.0
2025-07-13 14:57:23,343:INFO:               tbats: 1.1.3
2025-07-13 14:57:23,343:INFO:            pmdarima: 2.0.4
2025-07-13 14:57:23,343:INFO:              psutil: 7.0.0
2025-07-13 14:57:23,343:INFO:          markupsafe: 3.0.2
2025-07-13 14:57:23,343:INFO:             pickle5: Not installed
2025-07-13 14:57:23,343:INFO:         cloudpickle: 3.1.1
2025-07-13 14:57:23,343:INFO:         deprecation: 2.1.0
2025-07-13 14:57:23,343:INFO:              xxhash: 3.5.0
2025-07-13 14:57:23,343:INFO:           wurlitzer: Not installed
2025-07-13 14:57:23,343:INFO:PyCaret optional dependencies:
2025-07-13 14:57:23,358:INFO:                shap: Not installed
2025-07-13 14:57:23,358:INFO:           interpret: Not installed
2025-07-13 14:57:23,358:INFO:                umap: Not installed
2025-07-13 14:57:23,358:INFO:     ydata_profiling: Not installed
2025-07-13 14:57:23,358:INFO:  explainerdashboard: Not installed
2025-07-13 14:57:23,358:INFO:             autoviz: Not installed
2025-07-13 14:57:23,358:INFO:           fairlearn: Not installed
2025-07-13 14:57:23,358:INFO:          deepchecks: Not installed
2025-07-13 14:57:23,358:INFO:             xgboost: Not installed
2025-07-13 14:57:23,358:INFO:            catboost: Not installed
2025-07-13 14:57:23,358:INFO:              kmodes: Not installed
2025-07-13 14:57:23,358:INFO:             mlxtend: Not installed
2025-07-13 14:57:23,358:INFO:       statsforecast: Not installed
2025-07-13 14:57:23,358:INFO:        tune_sklearn: Not installed
2025-07-13 14:57:23,358:INFO:                 ray: Not installed
2025-07-13 14:57:23,358:INFO:            hyperopt: Not installed
2025-07-13 14:57:23,358:INFO:              optuna: Not installed
2025-07-13 14:57:23,358:INFO:               skopt: Not installed
2025-07-13 14:57:23,358:INFO:              mlflow: Not installed
2025-07-13 14:57:23,358:INFO:              gradio: Not installed
2025-07-13 14:57:23,358:INFO:             fastapi: Not installed
2025-07-13 14:57:23,358:INFO:             uvicorn: Not installed
2025-07-13 14:57:23,358:INFO:              m2cgen: Not installed
2025-07-13 14:57:23,358:INFO:           evidently: Not installed
2025-07-13 14:57:23,358:INFO:               fugue: Not installed
2025-07-13 14:57:23,358:INFO:           streamlit: 1.44.1
2025-07-13 14:57:23,358:INFO:             prophet: Not installed
2025-07-13 14:57:23,358:INFO:None
2025-07-13 14:57:23,358:INFO:Set up data.
2025-07-13 14:57:23,389:INFO:Set up folding strategy.
2025-07-13 14:57:23,389:INFO:Set up train/test split.
2025-07-13 14:57:23,437:INFO:Set up index.
2025-07-13 14:57:23,438:INFO:Assigning column types.
2025-07-13 14:57:23,445:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 14:57:23,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 14:57:23,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:23,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:23,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:23,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 14:57:23,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:23,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:23,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:23,790:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 14:57:23,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:23,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:23,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:24,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,127:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 14:57:24,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:24,486:INFO:Preparing preprocessing pipeline...
2025-07-13 14:57:24,486:INFO:Set up simple imputation.
2025-07-13 14:57:24,486:INFO:Set up encoding of ordinal features.
2025-07-13 14:57:24,501:INFO:Set up encoding of categorical features.
2025-07-13 14:57:24,702:INFO:Finished creating preprocessing pipeline.
2025-07-13 14:57:24,759:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 14:57:24,759:INFO:Creating final display dataframe.
2025-07-13 14:57:25,360:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              ab33
2025-07-13 14:57:25,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:25,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:25,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:25,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:25,704:INFO:setup() successfully completed in 2.51s...............
2025-07-13 14:57:25,793:INFO:PyCaret ClassificationExperiment
2025-07-13 14:57:25,793:INFO:Logging name: clf-default-name
2025-07-13 14:57:25,793:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 14:57:25,793:INFO:version 3.3.2
2025-07-13 14:57:25,793:INFO:Initializing setup()
2025-07-13 14:57:25,793:INFO:self.USI: a00b
2025-07-13 14:57:25,793:INFO:self._variable_keys: {'fold_groups_param', 'gpu_n_jobs_param', 'seed', 'y_test', 'html_param', 'X_train', 'fold_shuffle_param', 'memory', 'exp_name_log', 'exp_id', 'is_multiclass', 'USI', 'gpu_param', 'fold_generator', 'y_train', 'data', 'X', 'fix_imbalance', 'target_param', 'logging_param', 'idx', 'pipeline', '_ml_usecase', 'log_plots_param', '_available_plots', 'X_test', 'n_jobs_param', 'y'}
2025-07-13 14:57:25,793:INFO:Checking environment
2025-07-13 14:57:25,793:INFO:python_version: 3.11.0
2025-07-13 14:57:25,793:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-07-13 14:57:25,793:INFO:machine: AMD64
2025-07-13 14:57:25,793:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 14:57:25,809:INFO:Memory: svmem(total=12698038272, available=3012538368, percent=76.3, used=9685499904, free=3012538368)
2025-07-13 14:57:25,809:INFO:Physical Core: 2
2025-07-13 14:57:25,809:INFO:Logical Core: 4
2025-07-13 14:57:25,809:INFO:Checking libraries
2025-07-13 14:57:25,809:INFO:System:
2025-07-13 14:57:25,809:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-07-13 14:57:25,809:INFO:executable: C:\Users\Cristina\AppData\Local\Programs\Python\Python311\python.exe
2025-07-13 14:57:25,809:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 14:57:25,809:INFO:PyCaret required dependencies:
2025-07-13 14:57:25,809:INFO:                 pip: 25.1.1
2025-07-13 14:57:25,809:INFO:          setuptools: 65.5.0
2025-07-13 14:57:25,809:INFO:             pycaret: 3.3.2
2025-07-13 14:57:25,809:INFO:             IPython: 9.4.0
2025-07-13 14:57:25,809:INFO:          ipywidgets: 8.1.7
2025-07-13 14:57:25,809:INFO:                tqdm: 4.67.1
2025-07-13 14:57:25,809:INFO:               numpy: 1.26.4
2025-07-13 14:57:25,809:INFO:              pandas: 2.1.4
2025-07-13 14:57:25,809:INFO:              jinja2: 3.1.6
2025-07-13 14:57:25,809:INFO:               scipy: 1.11.4
2025-07-13 14:57:25,809:INFO:              joblib: 1.3.2
2025-07-13 14:57:25,809:INFO:             sklearn: 1.4.2
2025-07-13 14:57:25,809:INFO:                pyod: 2.0.5
2025-07-13 14:57:25,809:INFO:            imblearn: 0.13.0
2025-07-13 14:57:25,809:INFO:   category_encoders: 2.7.0
2025-07-13 14:57:25,809:INFO:            lightgbm: 4.6.0
2025-07-13 14:57:25,809:INFO:               numba: 0.61.2
2025-07-13 14:57:25,809:INFO:            requests: 2.32.3
2025-07-13 14:57:25,809:INFO:          matplotlib: 3.7.5
2025-07-13 14:57:25,809:INFO:          scikitplot: 0.3.7
2025-07-13 14:57:25,809:INFO:         yellowbrick: 1.5
2025-07-13 14:57:25,809:INFO:              plotly: 5.24.1
2025-07-13 14:57:25,809:INFO:    plotly-resampler: Not installed
2025-07-13 14:57:25,809:INFO:             kaleido: 1.0.0
2025-07-13 14:57:25,809:INFO:           schemdraw: 0.15
2025-07-13 14:57:25,809:INFO:         statsmodels: 0.14.4
2025-07-13 14:57:25,809:INFO:              sktime: 0.26.0
2025-07-13 14:57:25,809:INFO:               tbats: 1.1.3
2025-07-13 14:57:25,809:INFO:            pmdarima: 2.0.4
2025-07-13 14:57:25,809:INFO:              psutil: 7.0.0
2025-07-13 14:57:25,809:INFO:          markupsafe: 3.0.2
2025-07-13 14:57:25,809:INFO:             pickle5: Not installed
2025-07-13 14:57:25,809:INFO:         cloudpickle: 3.1.1
2025-07-13 14:57:25,809:INFO:         deprecation: 2.1.0
2025-07-13 14:57:25,809:INFO:              xxhash: 3.5.0
2025-07-13 14:57:25,809:INFO:           wurlitzer: Not installed
2025-07-13 14:57:25,809:INFO:PyCaret optional dependencies:
2025-07-13 14:57:25,809:INFO:                shap: Not installed
2025-07-13 14:57:25,809:INFO:           interpret: Not installed
2025-07-13 14:57:25,809:INFO:                umap: Not installed
2025-07-13 14:57:25,809:INFO:     ydata_profiling: Not installed
2025-07-13 14:57:25,809:INFO:  explainerdashboard: Not installed
2025-07-13 14:57:25,809:INFO:             autoviz: Not installed
2025-07-13 14:57:25,809:INFO:           fairlearn: Not installed
2025-07-13 14:57:25,809:INFO:          deepchecks: Not installed
2025-07-13 14:57:25,809:INFO:             xgboost: Not installed
2025-07-13 14:57:25,809:INFO:            catboost: Not installed
2025-07-13 14:57:25,809:INFO:              kmodes: Not installed
2025-07-13 14:57:25,809:INFO:             mlxtend: Not installed
2025-07-13 14:57:25,809:INFO:       statsforecast: Not installed
2025-07-13 14:57:25,809:INFO:        tune_sklearn: Not installed
2025-07-13 14:57:25,809:INFO:                 ray: Not installed
2025-07-13 14:57:25,809:INFO:            hyperopt: Not installed
2025-07-13 14:57:25,809:INFO:              optuna: Not installed
2025-07-13 14:57:25,809:INFO:               skopt: Not installed
2025-07-13 14:57:25,809:INFO:              mlflow: Not installed
2025-07-13 14:57:25,809:INFO:              gradio: Not installed
2025-07-13 14:57:25,809:INFO:             fastapi: Not installed
2025-07-13 14:57:25,809:INFO:             uvicorn: Not installed
2025-07-13 14:57:25,809:INFO:              m2cgen: Not installed
2025-07-13 14:57:25,809:INFO:           evidently: Not installed
2025-07-13 14:57:25,809:INFO:               fugue: Not installed
2025-07-13 14:57:25,809:INFO:           streamlit: 1.44.1
2025-07-13 14:57:25,809:INFO:             prophet: Not installed
2025-07-13 14:57:25,809:INFO:None
2025-07-13 14:57:25,809:INFO:Set up data.
2025-07-13 14:57:25,829:INFO:Set up folding strategy.
2025-07-13 14:57:25,829:INFO:Set up train/test split.
2025-07-13 14:57:25,842:INFO:Set up index.
2025-07-13 14:57:25,842:INFO:Assigning column types.
2025-07-13 14:57:25,859:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 14:57:25,975:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 14:57:25,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:26,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 14:57:26,160:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:26,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,243:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 14:57:26,360:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:26,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 14:57:26,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,611:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 14:57:26,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:26,996:INFO:Preparing preprocessing pipeline...
2025-07-13 14:57:27,011:INFO:Set up simple imputation.
2025-07-13 14:57:27,012:INFO:Set up encoding of ordinal features.
2025-07-13 14:57:27,012:INFO:Set up encoding of categorical features.
2025-07-13 14:57:27,280:INFO:Finished creating preprocessing pipeline.
2025-07-13 14:57:27,347:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 14:57:27,347:INFO:Creating final display dataframe.
2025-07-13 14:57:28,067:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.1%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              a00b
2025-07-13 14:57:28,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:28,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:28,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:28,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 14:57:28,475:INFO:setup() successfully completed in 2.71s...............
2025-07-13 14:57:28,499:INFO:Initializing compare_models()
2025-07-13 14:57:28,500:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-13 14:57:28,500:INFO:Checking exceptions
2025-07-13 14:57:28,508:INFO:Preparing display monitor
2025-07-13 14:57:28,512:INFO:Initializing Logistic Regression
2025-07-13 14:57:28,513:INFO:Total runtime is 1.6669432322184246e-05 minutes
2025-07-13 14:57:28,513:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:28,513:INFO:Initializing create_model()
2025-07-13 14:57:28,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:28,514:INFO:Checking exceptions
2025-07-13 14:57:28,514:INFO:Importing libraries
2025-07-13 14:57:28,514:INFO:Copying training dataset
2025-07-13 14:57:28,526:INFO:Defining folds
2025-07-13 14:57:28,526:INFO:Declaring metric variables
2025-07-13 14:57:28,526:INFO:Importing untrained model
2025-07-13 14:57:28,527:INFO:Logistic Regression Imported successfully
2025-07-13 14:57:28,527:INFO:Starting cross validation
2025-07-13 14:57:28,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:39,275:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:39,464:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:39,482:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:39,633:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:40,071:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:40,254:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:40,385:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:40,576:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:41,832:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:41,932:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:42,067:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:42,106:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:42,827:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:43,062:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:43,411:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:43,574:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:44,531:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:44,605:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:57:44,650:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:44,702:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:44,722:INFO:Calculating mean and std
2025-07-13 14:57:44,724:INFO:Creating metrics dataframe
2025-07-13 14:57:44,727:INFO:Uploading results into container
2025-07-13 14:57:44,728:INFO:Uploading model into container now
2025-07-13 14:57:44,728:INFO:_master_model_container: 1
2025-07-13 14:57:44,728:INFO:_display_container: 2
2025-07-13 14:57:44,729:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 14:57:44,729:INFO:create_model() successfully completed......................................
2025-07-13 14:57:44,842:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:44,842:INFO:Creating metrics dataframe
2025-07-13 14:57:44,842:INFO:Initializing K Neighbors Classifier
2025-07-13 14:57:44,842:INFO:Total runtime is 0.27216939926147465 minutes
2025-07-13 14:57:44,842:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:44,842:INFO:Initializing create_model()
2025-07-13 14:57:44,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:44,842:INFO:Checking exceptions
2025-07-13 14:57:44,842:INFO:Importing libraries
2025-07-13 14:57:44,842:INFO:Copying training dataset
2025-07-13 14:57:44,858:INFO:Defining folds
2025-07-13 14:57:44,858:INFO:Declaring metric variables
2025-07-13 14:57:44,858:INFO:Importing untrained model
2025-07-13 14:57:44,858:INFO:K Neighbors Classifier Imported successfully
2025-07-13 14:57:44,858:INFO:Starting cross validation
2025-07-13 14:57:44,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:47,159:INFO:Calculating mean and std
2025-07-13 14:57:47,159:INFO:Creating metrics dataframe
2025-07-13 14:57:47,159:INFO:Uploading results into container
2025-07-13 14:57:47,159:INFO:Uploading model into container now
2025-07-13 14:57:47,159:INFO:_master_model_container: 2
2025-07-13 14:57:47,159:INFO:_display_container: 2
2025-07-13 14:57:47,159:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-13 14:57:47,159:INFO:create_model() successfully completed......................................
2025-07-13 14:57:47,269:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:47,269:INFO:Creating metrics dataframe
2025-07-13 14:57:47,269:INFO:Initializing Naive Bayes
2025-07-13 14:57:47,269:INFO:Total runtime is 0.31262214978535974 minutes
2025-07-13 14:57:47,269:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:47,269:INFO:Initializing create_model()
2025-07-13 14:57:47,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:47,269:INFO:Checking exceptions
2025-07-13 14:57:47,269:INFO:Importing libraries
2025-07-13 14:57:47,269:INFO:Copying training dataset
2025-07-13 14:57:47,280:INFO:Defining folds
2025-07-13 14:57:47,280:INFO:Declaring metric variables
2025-07-13 14:57:47,280:INFO:Importing untrained model
2025-07-13 14:57:47,280:INFO:Naive Bayes Imported successfully
2025-07-13 14:57:47,280:INFO:Starting cross validation
2025-07-13 14:57:47,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:48,504:INFO:Calculating mean and std
2025-07-13 14:57:48,504:INFO:Creating metrics dataframe
2025-07-13 14:57:48,504:INFO:Uploading results into container
2025-07-13 14:57:48,504:INFO:Uploading model into container now
2025-07-13 14:57:48,504:INFO:_master_model_container: 3
2025-07-13 14:57:48,504:INFO:_display_container: 2
2025-07-13 14:57:48,504:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-13 14:57:48,504:INFO:create_model() successfully completed......................................
2025-07-13 14:57:48,607:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:48,608:INFO:Creating metrics dataframe
2025-07-13 14:57:48,611:INFO:Initializing Decision Tree Classifier
2025-07-13 14:57:48,611:INFO:Total runtime is 0.3349781115849813 minutes
2025-07-13 14:57:48,611:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:48,611:INFO:Initializing create_model()
2025-07-13 14:57:48,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:48,612:INFO:Checking exceptions
2025-07-13 14:57:48,612:INFO:Importing libraries
2025-07-13 14:57:48,612:INFO:Copying training dataset
2025-07-13 14:57:48,620:INFO:Defining folds
2025-07-13 14:57:48,620:INFO:Declaring metric variables
2025-07-13 14:57:48,620:INFO:Importing untrained model
2025-07-13 14:57:48,622:INFO:Decision Tree Classifier Imported successfully
2025-07-13 14:57:48,622:INFO:Starting cross validation
2025-07-13 14:57:48,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:50,309:INFO:Calculating mean and std
2025-07-13 14:57:50,309:INFO:Creating metrics dataframe
2025-07-13 14:57:50,309:INFO:Uploading results into container
2025-07-13 14:57:50,309:INFO:Uploading model into container now
2025-07-13 14:57:50,317:INFO:_master_model_container: 4
2025-07-13 14:57:50,317:INFO:_display_container: 2
2025-07-13 14:57:50,317:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-13 14:57:50,317:INFO:create_model() successfully completed......................................
2025-07-13 14:57:50,473:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:50,473:INFO:Creating metrics dataframe
2025-07-13 14:57:50,480:INFO:Initializing SVM - Linear Kernel
2025-07-13 14:57:50,480:INFO:Total runtime is 0.3661325494448344 minutes
2025-07-13 14:57:50,480:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:50,482:INFO:Initializing create_model()
2025-07-13 14:57:50,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:50,482:INFO:Checking exceptions
2025-07-13 14:57:50,482:INFO:Importing libraries
2025-07-13 14:57:50,482:INFO:Copying training dataset
2025-07-13 14:57:50,501:INFO:Defining folds
2025-07-13 14:57:50,501:INFO:Declaring metric variables
2025-07-13 14:57:50,502:INFO:Importing untrained model
2025-07-13 14:57:50,503:INFO:SVM - Linear Kernel Imported successfully
2025-07-13 14:57:50,503:INFO:Starting cross validation
2025-07-13 14:57:50,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:51,071:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:51,088:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:51,580:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:51,590:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:51,681:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,039:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,039:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,066:INFO:Calculating mean and std
2025-07-13 14:57:52,068:INFO:Creating metrics dataframe
2025-07-13 14:57:52,068:INFO:Uploading results into container
2025-07-13 14:57:52,068:INFO:Uploading model into container now
2025-07-13 14:57:52,068:INFO:_master_model_container: 5
2025-07-13 14:57:52,068:INFO:_display_container: 2
2025-07-13 14:57:52,068:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-13 14:57:52,068:INFO:create_model() successfully completed......................................
2025-07-13 14:57:52,220:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:52,220:INFO:Creating metrics dataframe
2025-07-13 14:57:52,220:INFO:Initializing Ridge Classifier
2025-07-13 14:57:52,220:INFO:Total runtime is 0.39513166745503747 minutes
2025-07-13 14:57:52,220:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:52,220:INFO:Initializing create_model()
2025-07-13 14:57:52,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:52,220:INFO:Checking exceptions
2025-07-13 14:57:52,220:INFO:Importing libraries
2025-07-13 14:57:52,220:INFO:Copying training dataset
2025-07-13 14:57:52,240:INFO:Defining folds
2025-07-13 14:57:52,240:INFO:Declaring metric variables
2025-07-13 14:57:52,240:INFO:Importing untrained model
2025-07-13 14:57:52,240:INFO:Ridge Classifier Imported successfully
2025-07-13 14:57:52,240:INFO:Starting cross validation
2025-07-13 14:57:52,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:52,783:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,783:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,791:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:52,861:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,336:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,371:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,381:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,421:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,756:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,765:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:57:53,785:INFO:Calculating mean and std
2025-07-13 14:57:53,785:INFO:Creating metrics dataframe
2025-07-13 14:57:53,785:INFO:Uploading results into container
2025-07-13 14:57:53,785:INFO:Uploading model into container now
2025-07-13 14:57:53,785:INFO:_master_model_container: 6
2025-07-13 14:57:53,785:INFO:_display_container: 2
2025-07-13 14:57:53,785:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-13 14:57:53,785:INFO:create_model() successfully completed......................................
2025-07-13 14:57:53,896:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:53,896:INFO:Creating metrics dataframe
2025-07-13 14:57:53,896:INFO:Initializing Random Forest Classifier
2025-07-13 14:57:53,896:INFO:Total runtime is 0.42305644750595095 minutes
2025-07-13 14:57:53,896:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:53,896:INFO:Initializing create_model()
2025-07-13 14:57:53,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:53,896:INFO:Checking exceptions
2025-07-13 14:57:53,896:INFO:Importing libraries
2025-07-13 14:57:53,896:INFO:Copying training dataset
2025-07-13 14:57:53,911:INFO:Defining folds
2025-07-13 14:57:53,911:INFO:Declaring metric variables
2025-07-13 14:57:53,911:INFO:Importing untrained model
2025-07-13 14:57:53,911:INFO:Random Forest Classifier Imported successfully
2025-07-13 14:57:53,911:INFO:Starting cross validation
2025-07-13 14:57:53,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:57:59,641:INFO:Calculating mean and std
2025-07-13 14:57:59,641:INFO:Creating metrics dataframe
2025-07-13 14:57:59,641:INFO:Uploading results into container
2025-07-13 14:57:59,641:INFO:Uploading model into container now
2025-07-13 14:57:59,641:INFO:_master_model_container: 7
2025-07-13 14:57:59,641:INFO:_display_container: 2
2025-07-13 14:57:59,641:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-13 14:57:59,641:INFO:create_model() successfully completed......................................
2025-07-13 14:57:59,757:INFO:SubProcess create_model() end ==================================
2025-07-13 14:57:59,757:INFO:Creating metrics dataframe
2025-07-13 14:57:59,757:INFO:Initializing Quadratic Discriminant Analysis
2025-07-13 14:57:59,757:INFO:Total runtime is 0.5207412203152975 minutes
2025-07-13 14:57:59,757:INFO:SubProcess create_model() called ==================================
2025-07-13 14:57:59,757:INFO:Initializing create_model()
2025-07-13 14:57:59,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:57:59,757:INFO:Checking exceptions
2025-07-13 14:57:59,757:INFO:Importing libraries
2025-07-13 14:57:59,757:INFO:Copying training dataset
2025-07-13 14:57:59,772:INFO:Defining folds
2025-07-13 14:57:59,772:INFO:Declaring metric variables
2025-07-13 14:57:59,772:INFO:Importing untrained model
2025-07-13 14:57:59,772:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-13 14:57:59,772:INFO:Starting cross validation
2025-07-13 14:57:59,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:00,095:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,127:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,137:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,169:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,572:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,590:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,613:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,622:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,964:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:00,981:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 14:58:01,098:INFO:Calculating mean and std
2025-07-13 14:58:01,100:INFO:Creating metrics dataframe
2025-07-13 14:58:01,100:INFO:Uploading results into container
2025-07-13 14:58:01,100:INFO:Uploading model into container now
2025-07-13 14:58:01,100:INFO:_master_model_container: 8
2025-07-13 14:58:01,100:INFO:_display_container: 2
2025-07-13 14:58:01,100:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-13 14:58:01,100:INFO:create_model() successfully completed......................................
2025-07-13 14:58:01,201:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:01,201:INFO:Creating metrics dataframe
2025-07-13 14:58:01,211:INFO:Initializing Ada Boost Classifier
2025-07-13 14:58:01,211:INFO:Total runtime is 0.5449788331985473 minutes
2025-07-13 14:58:01,211:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:01,211:INFO:Initializing create_model()
2025-07-13 14:58:01,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:01,211:INFO:Checking exceptions
2025-07-13 14:58:01,211:INFO:Importing libraries
2025-07-13 14:58:01,211:INFO:Copying training dataset
2025-07-13 14:58:01,211:INFO:Defining folds
2025-07-13 14:58:01,211:INFO:Declaring metric variables
2025-07-13 14:58:01,211:INFO:Importing untrained model
2025-07-13 14:58:01,211:INFO:Ada Boost Classifier Imported successfully
2025-07-13 14:58:01,211:INFO:Starting cross validation
2025-07-13 14:58:01,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:01,558:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:01,568:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:01,595:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:01,690:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:02,583:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:02,596:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:02,627:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:02,699:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:03,527:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:03,538:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 14:58:04,051:INFO:Calculating mean and std
2025-07-13 14:58:04,051:INFO:Creating metrics dataframe
2025-07-13 14:58:04,051:INFO:Uploading results into container
2025-07-13 14:58:04,051:INFO:Uploading model into container now
2025-07-13 14:58:04,051:INFO:_master_model_container: 9
2025-07-13 14:58:04,055:INFO:_display_container: 2
2025-07-13 14:58:04,055:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-13 14:58:04,055:INFO:create_model() successfully completed......................................
2025-07-13 14:58:04,148:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:04,148:INFO:Creating metrics dataframe
2025-07-13 14:58:04,148:INFO:Initializing Gradient Boosting Classifier
2025-07-13 14:58:04,148:INFO:Total runtime is 0.5939312100410461 minutes
2025-07-13 14:58:04,148:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:04,148:INFO:Initializing create_model()
2025-07-13 14:58:04,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:04,148:INFO:Checking exceptions
2025-07-13 14:58:04,148:INFO:Importing libraries
2025-07-13 14:58:04,148:INFO:Copying training dataset
2025-07-13 14:58:04,158:INFO:Defining folds
2025-07-13 14:58:04,158:INFO:Declaring metric variables
2025-07-13 14:58:04,158:INFO:Importing untrained model
2025-07-13 14:58:04,158:INFO:Gradient Boosting Classifier Imported successfully
2025-07-13 14:58:04,158:INFO:Starting cross validation
2025-07-13 14:58:04,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:10,164:INFO:Calculating mean and std
2025-07-13 14:58:10,164:INFO:Creating metrics dataframe
2025-07-13 14:58:10,166:INFO:Uploading results into container
2025-07-13 14:58:10,166:INFO:Uploading model into container now
2025-07-13 14:58:10,166:INFO:_master_model_container: 10
2025-07-13 14:58:10,166:INFO:_display_container: 2
2025-07-13 14:58:10,171:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-13 14:58:10,171:INFO:create_model() successfully completed......................................
2025-07-13 14:58:10,266:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:10,266:INFO:Creating metrics dataframe
2025-07-13 14:58:10,281:INFO:Initializing Linear Discriminant Analysis
2025-07-13 14:58:10,281:INFO:Total runtime is 0.696151332060496 minutes
2025-07-13 14:58:10,281:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:10,281:INFO:Initializing create_model()
2025-07-13 14:58:10,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:10,281:INFO:Checking exceptions
2025-07-13 14:58:10,281:INFO:Importing libraries
2025-07-13 14:58:10,281:INFO:Copying training dataset
2025-07-13 14:58:10,281:INFO:Defining folds
2025-07-13 14:58:10,281:INFO:Declaring metric variables
2025-07-13 14:58:10,297:INFO:Importing untrained model
2025-07-13 14:58:10,297:INFO:Linear Discriminant Analysis Imported successfully
2025-07-13 14:58:10,297:INFO:Starting cross validation
2025-07-13 14:58:10,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:10,773:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:10,773:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:10,783:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:10,867:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,324:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,354:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,375:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,405:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,718:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,754:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:11,771:INFO:Calculating mean and std
2025-07-13 14:58:11,772:INFO:Creating metrics dataframe
2025-07-13 14:58:11,775:INFO:Uploading results into container
2025-07-13 14:58:11,775:INFO:Uploading model into container now
2025-07-13 14:58:11,776:INFO:_master_model_container: 11
2025-07-13 14:58:11,776:INFO:_display_container: 2
2025-07-13 14:58:11,777:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-13 14:58:11,777:INFO:create_model() successfully completed......................................
2025-07-13 14:58:11,887:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:11,887:INFO:Creating metrics dataframe
2025-07-13 14:58:11,887:INFO:Initializing Extra Trees Classifier
2025-07-13 14:58:11,887:INFO:Total runtime is 0.7229151288668314 minutes
2025-07-13 14:58:11,887:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:11,887:INFO:Initializing create_model()
2025-07-13 14:58:11,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:11,887:INFO:Checking exceptions
2025-07-13 14:58:11,887:INFO:Importing libraries
2025-07-13 14:58:11,887:INFO:Copying training dataset
2025-07-13 14:58:11,903:INFO:Defining folds
2025-07-13 14:58:11,903:INFO:Declaring metric variables
2025-07-13 14:58:11,903:INFO:Importing untrained model
2025-07-13 14:58:11,903:INFO:Extra Trees Classifier Imported successfully
2025-07-13 14:58:11,903:INFO:Starting cross validation
2025-07-13 14:58:11,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:16,460:INFO:Calculating mean and std
2025-07-13 14:58:16,461:INFO:Creating metrics dataframe
2025-07-13 14:58:16,463:INFO:Uploading results into container
2025-07-13 14:58:16,464:INFO:Uploading model into container now
2025-07-13 14:58:16,464:INFO:_master_model_container: 12
2025-07-13 14:58:16,464:INFO:_display_container: 2
2025-07-13 14:58:16,465:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-13 14:58:16,465:INFO:create_model() successfully completed......................................
2025-07-13 14:58:16,563:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:16,563:INFO:Creating metrics dataframe
2025-07-13 14:58:16,570:INFO:Initializing Light Gradient Boosting Machine
2025-07-13 14:58:16,570:INFO:Total runtime is 0.8009564598401386 minutes
2025-07-13 14:58:16,570:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:16,570:INFO:Initializing create_model()
2025-07-13 14:58:16,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:16,570:INFO:Checking exceptions
2025-07-13 14:58:16,570:INFO:Importing libraries
2025-07-13 14:58:16,570:INFO:Copying training dataset
2025-07-13 14:58:16,579:INFO:Defining folds
2025-07-13 14:58:16,580:INFO:Declaring metric variables
2025-07-13 14:58:16,580:INFO:Importing untrained model
2025-07-13 14:58:16,581:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 14:58:16,581:INFO:Starting cross validation
2025-07-13 14:58:16,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:20,827:INFO:Calculating mean and std
2025-07-13 14:58:20,829:INFO:Creating metrics dataframe
2025-07-13 14:58:20,833:INFO:Uploading results into container
2025-07-13 14:58:20,834:INFO:Uploading model into container now
2025-07-13 14:58:20,835:INFO:_master_model_container: 13
2025-07-13 14:58:20,835:INFO:_display_container: 2
2025-07-13 14:58:20,837:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:58:20,837:INFO:create_model() successfully completed......................................
2025-07-13 14:58:20,968:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:20,968:INFO:Creating metrics dataframe
2025-07-13 14:58:20,978:INFO:Initializing Dummy Classifier
2025-07-13 14:58:20,978:INFO:Total runtime is 0.8744268218676248 minutes
2025-07-13 14:58:20,978:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:20,978:INFO:Initializing create_model()
2025-07-13 14:58:20,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C8468D9BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:20,978:INFO:Checking exceptions
2025-07-13 14:58:20,978:INFO:Importing libraries
2025-07-13 14:58:20,978:INFO:Copying training dataset
2025-07-13 14:58:20,988:INFO:Defining folds
2025-07-13 14:58:20,988:INFO:Declaring metric variables
2025-07-13 14:58:20,988:INFO:Importing untrained model
2025-07-13 14:58:20,996:INFO:Dummy Classifier Imported successfully
2025-07-13 14:58:20,996:INFO:Starting cross validation
2025-07-13 14:58:20,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:21,562:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:21,569:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:21,583:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:21,613:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,062:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,073:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,087:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,116:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,341:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,351:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 14:58:22,371:INFO:Calculating mean and std
2025-07-13 14:58:22,372:INFO:Creating metrics dataframe
2025-07-13 14:58:22,374:INFO:Uploading results into container
2025-07-13 14:58:22,374:INFO:Uploading model into container now
2025-07-13 14:58:22,375:INFO:_master_model_container: 14
2025-07-13 14:58:22,375:INFO:_display_container: 2
2025-07-13 14:58:22,375:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-13 14:58:22,375:INFO:create_model() successfully completed......................................
2025-07-13 14:58:22,460:INFO:SubProcess create_model() end ==================================
2025-07-13 14:58:22,460:INFO:Creating metrics dataframe
2025-07-13 14:58:22,476:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-13 14:58:22,476:INFO:Initializing create_model()
2025-07-13 14:58:22,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:22,476:INFO:Checking exceptions
2025-07-13 14:58:22,476:INFO:Importing libraries
2025-07-13 14:58:22,476:INFO:Copying training dataset
2025-07-13 14:58:22,476:INFO:Defining folds
2025-07-13 14:58:22,476:INFO:Declaring metric variables
2025-07-13 14:58:22,476:INFO:Importing untrained model
2025-07-13 14:58:22,476:INFO:Declaring custom model
2025-07-13 14:58:22,476:INFO:Logistic Regression Imported successfully
2025-07-13 14:58:22,476:INFO:Cross validation set to False
2025-07-13 14:58:22,476:INFO:Fitting Model
2025-07-13 14:58:23,838:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 14:58:23,839:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 14:58:23,839:INFO:create_model() successfully completed......................................
2025-07-13 14:58:24,135:INFO:_master_model_container: 14
2025-07-13 14:58:24,137:INFO:_display_container: 2
2025-07-13 14:58:24,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 14:58:24,138:INFO:compare_models() successfully completed......................................
2025-07-13 14:58:24,146:INFO:Initializing create_model()
2025-07-13 14:58:24,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:58:24,146:INFO:Checking exceptions
2025-07-13 14:58:24,166:INFO:Importing libraries
2025-07-13 14:58:24,166:INFO:Copying training dataset
2025-07-13 14:58:24,202:INFO:Defining folds
2025-07-13 14:58:24,202:INFO:Declaring metric variables
2025-07-13 14:58:24,203:INFO:Importing untrained model
2025-07-13 14:58:24,205:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 14:58:24,206:INFO:Starting cross validation
2025-07-13 14:58:24,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:58:28,156:INFO:Calculating mean and std
2025-07-13 14:58:28,158:INFO:Creating metrics dataframe
2025-07-13 14:58:28,163:INFO:Finalizing model
2025-07-13 14:58:28,455:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 14:58:28,460:INFO:[LightGBM] [Info] Number of positive: 540, number of negative: 6110
2025-07-13 14:58:28,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001918 seconds.
2025-07-13 14:58:28,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 14:58:28,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 14:58:28,465:INFO:[LightGBM] [Info] Total Bins 615
2025-07-13 14:58:28,465:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 14:58:28,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081203 -> initscore=-2.426113
2025-07-13 14:58:28,465:INFO:[LightGBM] [Info] Start training from score -2.426113
2025-07-13 14:58:28,649:INFO:Uploading results into container
2025-07-13 14:58:28,650:INFO:Uploading model into container now
2025-07-13 14:58:28,677:INFO:_master_model_container: 15
2025-07-13 14:58:28,677:INFO:_display_container: 3
2025-07-13 14:58:28,678:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:58:28,678:INFO:create_model() successfully completed......................................
2025-07-13 14:58:28,798:INFO:Initializing tune_model()
2025-07-13 14:58:28,798:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-13 14:58:28,798:INFO:Checking exceptions
2025-07-13 14:58:28,806:INFO:Copying training dataset
2025-07-13 14:58:28,806:INFO:Checking base model
2025-07-13 14:58:28,816:INFO:Base model : Light Gradient Boosting Machine
2025-07-13 14:58:28,816:INFO:Declaring metric variables
2025-07-13 14:58:28,816:INFO:Defining Hyperparameters
2025-07-13 14:58:28,917:INFO:Tuning with n_jobs=-1
2025-07-13 14:58:28,917:INFO:Initializing RandomizedSearchCV
2025-07-13 14:58:57,971:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-07-13 14:58:57,971:INFO:Hyperparameter search completed
2025-07-13 14:58:57,971:INFO:SubProcess create_model() called ==================================
2025-07-13 14:58:57,977:INFO:Initializing create_model()
2025-07-13 14:58:57,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C844F61790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-07-13 14:58:57,977:INFO:Checking exceptions
2025-07-13 14:58:57,977:INFO:Importing libraries
2025-07-13 14:58:57,977:INFO:Copying training dataset
2025-07-13 14:58:57,989:INFO:Defining folds
2025-07-13 14:58:57,989:INFO:Declaring metric variables
2025-07-13 14:58:57,989:INFO:Importing untrained model
2025-07-13 14:58:57,989:INFO:Declaring custom model
2025-07-13 14:58:57,999:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 14:58:57,999:INFO:Starting cross validation
2025-07-13 14:58:57,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:59:00,790:INFO:Calculating mean and std
2025-07-13 14:59:00,790:INFO:Creating metrics dataframe
2025-07-13 14:59:00,790:INFO:Finalizing model
2025-07-13 14:59:01,092:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:01,092:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:01,092:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:01,113:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 14:59:01,113:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:01,113:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:01,113:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:01,113:INFO:[LightGBM] [Info] Number of positive: 540, number of negative: 6110
2025-07-13 14:59:01,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001026 seconds.
2025-07-13 14:59:01,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 14:59:01,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 14:59:01,122:INFO:[LightGBM] [Info] Total Bins 615
2025-07-13 14:59:01,124:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 14:59:01,124:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081203 -> initscore=-2.426113
2025-07-13 14:59:01,124:INFO:[LightGBM] [Info] Start training from score -2.426113
2025-07-13 14:59:01,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:01,225:INFO:Uploading results into container
2025-07-13 14:59:01,225:INFO:Uploading model into container now
2025-07-13 14:59:01,225:INFO:_master_model_container: 16
2025-07-13 14:59:01,225:INFO:_display_container: 4
2025-07-13 14:59:01,225:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:59:01,225:INFO:create_model() successfully completed......................................
2025-07-13 14:59:01,364:INFO:SubProcess create_model() end ==================================
2025-07-13 14:59:01,364:INFO:choose_better activated
2025-07-13 14:59:01,364:INFO:SubProcess create_model() called ==================================
2025-07-13 14:59:01,374:INFO:Initializing create_model()
2025-07-13 14:59:01,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:59:01,374:INFO:Checking exceptions
2025-07-13 14:59:01,377:INFO:Importing libraries
2025-07-13 14:59:01,377:INFO:Copying training dataset
2025-07-13 14:59:01,384:INFO:Defining folds
2025-07-13 14:59:01,384:INFO:Declaring metric variables
2025-07-13 14:59:01,384:INFO:Importing untrained model
2025-07-13 14:59:01,384:INFO:Declaring custom model
2025-07-13 14:59:01,384:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 14:59:01,384:INFO:Starting cross validation
2025-07-13 14:59:01,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 14:59:04,062:INFO:Calculating mean and std
2025-07-13 14:59:04,063:INFO:Creating metrics dataframe
2025-07-13 14:59:04,066:INFO:Finalizing model
2025-07-13 14:59:04,258:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 14:59:04,259:INFO:[LightGBM] [Info] Number of positive: 540, number of negative: 6110
2025-07-13 14:59:04,261:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.
2025-07-13 14:59:04,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 14:59:04,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 14:59:04,262:INFO:[LightGBM] [Info] Total Bins 615
2025-07-13 14:59:04,262:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 14:59:04,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081203 -> initscore=-2.426113
2025-07-13 14:59:04,263:INFO:[LightGBM] [Info] Start training from score -2.426113
2025-07-13 14:59:04,387:INFO:Uploading results into container
2025-07-13 14:59:04,388:INFO:Uploading model into container now
2025-07-13 14:59:04,389:INFO:_master_model_container: 17
2025-07-13 14:59:04,389:INFO:_display_container: 5
2025-07-13 14:59:04,391:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:59:04,391:INFO:create_model() successfully completed......................................
2025-07-13 14:59:04,525:INFO:SubProcess create_model() end ==================================
2025-07-13 14:59:04,527:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.06
2025-07-13 14:59:04,529:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1282
2025-07-13 14:59:04,531:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-07-13 14:59:04,531:INFO:choose_better completed
2025-07-13 14:59:04,545:INFO:_master_model_container: 17
2025-07-13 14:59:04,545:INFO:_display_container: 4
2025-07-13 14:59:04,553:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:59:04,553:INFO:tune_model() successfully completed......................................
2025-07-13 14:59:04,674:INFO:Initializing plot_model()
2025-07-13 14:59:04,675:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 14:59:04,675:INFO:Checking exceptions
2025-07-13 14:59:04,680:INFO:Preloading libraries
2025-07-13 14:59:04,690:INFO:Copying training dataset
2025-07-13 14:59:04,690:INFO:Plot type: auc
2025-07-13 14:59:04,927:INFO:Fitting Model
2025-07-13 14:59:04,927:INFO:Scoring test/hold-out set
2025-07-13 14:59:04,927:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:04,927:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:04,927:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:04,943:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:04,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:04,944:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:05,024:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 14:59:05,064:INFO:Visual Rendered Successfully
2025-07-13 14:59:05,156:INFO:plot_model() successfully completed......................................
2025-07-13 14:59:05,156:INFO:Initializing plot_model()
2025-07-13 14:59:05,156:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 14:59:05,156:INFO:Checking exceptions
2025-07-13 14:59:05,156:INFO:Preloading libraries
2025-07-13 14:59:05,179:INFO:Copying training dataset
2025-07-13 14:59:05,179:INFO:Plot type: auc
2025-07-13 14:59:05,375:INFO:Fitting Model
2025-07-13 14:59:05,376:INFO:Scoring test/hold-out set
2025-07-13 14:59:05,378:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:05,378:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:05,378:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:05,387:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:05,387:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:05,388:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:05,440:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 14:59:05,492:INFO:Visual Rendered Successfully
2025-07-13 14:59:05,590:INFO:plot_model() successfully completed......................................
2025-07-13 14:59:05,591:INFO:Initializing plot_model()
2025-07-13 14:59:05,591:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 14:59:05,592:INFO:Checking exceptions
2025-07-13 14:59:05,595:INFO:Preloading libraries
2025-07-13 14:59:05,604:INFO:Copying training dataset
2025-07-13 14:59:05,605:INFO:Plot type: feature
2025-07-13 14:59:05,607:WARNING:No coef_ found. Trying feature_importances_
2025-07-13 14:59:05,730:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 14:59:05,730:INFO:Visual Rendered Successfully
2025-07-13 14:59:05,830:INFO:plot_model() successfully completed......................................
2025-07-13 14:59:05,830:INFO:Initializing plot_model()
2025-07-13 14:59:05,830:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 14:59:05,830:INFO:Checking exceptions
2025-07-13 14:59:05,830:INFO:Preloading libraries
2025-07-13 14:59:05,851:INFO:Copying training dataset
2025-07-13 14:59:05,851:INFO:Plot type: confusion_matrix
2025-07-13 14:59:06,050:INFO:Fitting Model
2025-07-13 14:59:06,051:INFO:Scoring test/hold-out set
2025-07-13 14:59:06,053:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:06,053:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:06,053:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:06,062:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:06,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:06,063:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:06,171:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 14:59:06,195:INFO:Visual Rendered Successfully
2025-07-13 14:59:06,294:INFO:plot_model() successfully completed......................................
2025-07-13 14:59:06,310:INFO:Initializing predict_model()
2025-07-13 14:59:06,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C825BFC9A0>)
2025-07-13 14:59:06,311:INFO:Checking exceptions
2025-07-13 14:59:06,311:INFO:Preloading libraries
2025-07-13 14:59:06,649:INFO:Initializing predict_model()
2025-07-13 14:59:06,649:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C825BFC9A0>)
2025-07-13 14:59:06,649:INFO:Checking exceptions
2025-07-13 14:59:06,649:INFO:Preloading libraries
2025-07-13 14:59:06,945:INFO:Initializing predict_model()
2025-07-13 14:59:06,945:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C825BFC9A0>)
2025-07-13 14:59:06,945:INFO:Checking exceptions
2025-07-13 14:59:06,945:INFO:Preloading libraries
2025-07-13 14:59:07,253:INFO:Initializing finalize_model()
2025-07-13 14:59:07,254:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-13 14:59:07,254:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 14:59:07,261:INFO:Initializing create_model()
2025-07-13 14:59:07,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 14:59:07,261:INFO:Checking exceptions
2025-07-13 14:59:07,263:INFO:Importing libraries
2025-07-13 14:59:07,263:INFO:Copying training dataset
2025-07-13 14:59:07,263:INFO:Defining folds
2025-07-13 14:59:07,263:INFO:Declaring metric variables
2025-07-13 14:59:07,263:INFO:Importing untrained model
2025-07-13 14:59:07,263:INFO:Declaring custom model
2025-07-13 14:59:07,263:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 14:59:07,263:INFO:Cross validation set to False
2025-07-13 14:59:07,263:INFO:Fitting Model
2025-07-13 14:59:07,453:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:07,453:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:07,453:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:07,465:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 14:59:07,467:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 14:59:07,467:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 14:59:07,467:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 14:59:07,467:INFO:[LightGBM] [Info] Number of positive: 772, number of negative: 8728
2025-07-13 14:59:07,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000811 seconds.
2025-07-13 14:59:07,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 14:59:07,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 14:59:07,471:INFO:[LightGBM] [Info] Total Bins 619
2025-07-13 14:59:07,471:INFO:[LightGBM] [Info] Number of data points in the train set: 9500, number of used features: 29
2025-07-13 14:59:07,472:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081263 -> initscore=-2.425307
2025-07-13 14:59:07,472:INFO:[LightGBM] [Info] Start training from score -2.425307
2025-07-13 14:59:07,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 14:59:07,652:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 14:59:07,653:INFO:create_model() successfully completed......................................
2025-07-13 14:59:07,749:INFO:_master_model_container: 17
2025-07-13 14:59:07,749:INFO:_display_container: 7
2025-07-13 14:59:07,798:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 14:59:07,798:INFO:finalize_model() successfully completed......................................
2025-07-13 14:59:07,952:INFO:Initializing predict_model()
2025-07-13 14:59:07,952:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C826231080>)
2025-07-13 14:59:07,952:INFO:Checking exceptions
2025-07-13 14:59:07,952:INFO:Preloading libraries
2025-07-13 14:59:08,271:INFO:Initializing predict_model()
2025-07-13 14:59:08,271:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C826231080>)
2025-07-13 14:59:08,272:INFO:Checking exceptions
2025-07-13 14:59:08,272:INFO:Preloading libraries
2025-07-13 14:59:08,272:INFO:Set up data.
2025-07-13 14:59:08,279:INFO:Set up index.
2025-07-13 14:59:08,601:INFO:Initializing save_model()
2025-07-13 14:59:08,601:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=Final GBC Model 02Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-13 14:59:08,601:INFO:Adding model into prep_pipe
2025-07-13 14:59:08,601:WARNING:Only Model saved as it was a pipeline.
2025-07-13 14:59:08,632:INFO:Final GBC Model 02Jun2022.pkl saved in current working directory
2025-07-13 14:59:08,718:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 14:59:08,718:INFO:save_model() successfully completed......................................
2025-07-13 14:59:08,818:INFO:Initializing load_model()
2025-07-13 14:59:08,818:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-13 14:59:08,932:INFO:Initializing predict_model()
2025-07-13 14:59:08,932:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C8468AFC50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C8465AE0C0>)
2025-07-13 14:59:08,932:INFO:Checking exceptions
2025-07-13 14:59:08,932:INFO:Preloading libraries
2025-07-13 14:59:08,932:INFO:Set up data.
2025-07-13 14:59:08,947:INFO:Set up index.
2025-07-13 15:15:12,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 15:15:12,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 15:15:12,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 15:15:12,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-13 15:15:13,545:INFO:PyCaret ClassificationExperiment
2025-07-13 15:15:13,545:INFO:Logging name: clf-default-name
2025-07-13 15:15:13,545:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 15:15:13,546:INFO:version 3.3.2
2025-07-13 15:15:13,546:INFO:Initializing setup()
2025-07-13 15:15:13,546:INFO:self.USI: ed9c
2025-07-13 15:15:13,546:INFO:self._variable_keys: {'is_multiclass', 'USI', 'fold_generator', 'target_param', 'data', 'gpu_param', 'pipeline', 'logging_param', 'fix_imbalance', 'X', '_ml_usecase', 'X_test', 'y_test', 'idx', '_available_plots', 'fold_groups_param', 'y', 'fold_shuffle_param', 'n_jobs_param', 'y_train', 'exp_name_log', 'memory', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', 'seed', 'X_train'}
2025-07-13 15:15:13,546:INFO:Checking environment
2025-07-13 15:15:13,546:INFO:python_version: 3.11.0
2025-07-13 15:15:13,546:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-07-13 15:15:13,546:INFO:machine: AMD64
2025-07-13 15:15:13,572:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 15:15:13,577:INFO:Memory: svmem(total=12698038272, available=2919514112, percent=77.0, used=9778524160, free=2919514112)
2025-07-13 15:15:13,577:INFO:Physical Core: 2
2025-07-13 15:15:13,577:INFO:Logical Core: 4
2025-07-13 15:15:13,578:INFO:Checking libraries
2025-07-13 15:15:13,578:INFO:System:
2025-07-13 15:15:13,578:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-07-13 15:15:13,578:INFO:executable: C:\Users\Cristina\AppData\Local\Programs\Python\Python311\python.exe
2025-07-13 15:15:13,578:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 15:15:13,578:INFO:PyCaret required dependencies:
2025-07-13 15:15:13,601:INFO:                 pip: 25.1.1
2025-07-13 15:15:13,601:INFO:          setuptools: 65.5.0
2025-07-13 15:15:13,601:INFO:             pycaret: 3.3.2
2025-07-13 15:15:13,601:INFO:             IPython: 9.4.0
2025-07-13 15:15:13,616:INFO:          ipywidgets: 8.1.7
2025-07-13 15:15:13,616:INFO:                tqdm: 4.67.1
2025-07-13 15:15:13,616:INFO:               numpy: 1.26.4
2025-07-13 15:15:13,616:INFO:              pandas: 2.1.4
2025-07-13 15:15:13,616:INFO:              jinja2: 3.1.6
2025-07-13 15:15:13,616:INFO:               scipy: 1.11.4
2025-07-13 15:15:13,616:INFO:              joblib: 1.3.2
2025-07-13 15:15:13,616:INFO:             sklearn: 1.4.2
2025-07-13 15:15:13,616:INFO:                pyod: 2.0.5
2025-07-13 15:15:13,616:INFO:            imblearn: 0.13.0
2025-07-13 15:15:13,616:INFO:   category_encoders: 2.7.0
2025-07-13 15:15:13,616:INFO:            lightgbm: 4.6.0
2025-07-13 15:15:13,616:INFO:               numba: 0.61.2
2025-07-13 15:15:13,616:INFO:            requests: 2.32.3
2025-07-13 15:15:13,616:INFO:          matplotlib: 3.7.5
2025-07-13 15:15:13,616:INFO:          scikitplot: 0.3.7
2025-07-13 15:15:13,616:INFO:         yellowbrick: 1.5
2025-07-13 15:15:13,616:INFO:              plotly: 5.24.1
2025-07-13 15:15:13,616:INFO:    plotly-resampler: Not installed
2025-07-13 15:15:13,616:INFO:             kaleido: 1.0.0
2025-07-13 15:15:13,616:INFO:           schemdraw: 0.15
2025-07-13 15:15:13,616:INFO:         statsmodels: 0.14.4
2025-07-13 15:15:13,616:INFO:              sktime: 0.26.0
2025-07-13 15:15:13,616:INFO:               tbats: 1.1.3
2025-07-13 15:15:13,616:INFO:            pmdarima: 2.0.4
2025-07-13 15:15:13,616:INFO:              psutil: 7.0.0
2025-07-13 15:15:13,616:INFO:          markupsafe: 3.0.2
2025-07-13 15:15:13,616:INFO:             pickle5: Not installed
2025-07-13 15:15:13,616:INFO:         cloudpickle: 3.1.1
2025-07-13 15:15:13,616:INFO:         deprecation: 2.1.0
2025-07-13 15:15:13,616:INFO:              xxhash: 3.5.0
2025-07-13 15:15:13,616:INFO:           wurlitzer: Not installed
2025-07-13 15:15:13,616:INFO:PyCaret optional dependencies:
2025-07-13 15:15:13,632:INFO:                shap: Not installed
2025-07-13 15:15:13,632:INFO:           interpret: Not installed
2025-07-13 15:15:13,632:INFO:                umap: Not installed
2025-07-13 15:15:13,632:INFO:     ydata_profiling: Not installed
2025-07-13 15:15:13,632:INFO:  explainerdashboard: Not installed
2025-07-13 15:15:13,632:INFO:             autoviz: Not installed
2025-07-13 15:15:13,632:INFO:           fairlearn: Not installed
2025-07-13 15:15:13,632:INFO:          deepchecks: Not installed
2025-07-13 15:15:13,632:INFO:             xgboost: Not installed
2025-07-13 15:15:13,632:INFO:            catboost: Not installed
2025-07-13 15:15:13,632:INFO:              kmodes: Not installed
2025-07-13 15:15:13,632:INFO:             mlxtend: Not installed
2025-07-13 15:15:13,632:INFO:       statsforecast: Not installed
2025-07-13 15:15:13,632:INFO:        tune_sklearn: Not installed
2025-07-13 15:15:13,632:INFO:                 ray: Not installed
2025-07-13 15:15:13,632:INFO:            hyperopt: Not installed
2025-07-13 15:15:13,632:INFO:              optuna: Not installed
2025-07-13 15:15:13,632:INFO:               skopt: Not installed
2025-07-13 15:15:13,632:INFO:              mlflow: Not installed
2025-07-13 15:15:13,632:INFO:              gradio: Not installed
2025-07-13 15:15:13,632:INFO:             fastapi: Not installed
2025-07-13 15:15:13,632:INFO:             uvicorn: Not installed
2025-07-13 15:15:13,632:INFO:              m2cgen: Not installed
2025-07-13 15:15:13,632:INFO:           evidently: Not installed
2025-07-13 15:15:13,632:INFO:               fugue: Not installed
2025-07-13 15:15:13,632:INFO:           streamlit: 1.44.1
2025-07-13 15:15:13,632:INFO:             prophet: Not installed
2025-07-13 15:15:13,632:INFO:None
2025-07-13 15:15:13,632:INFO:Set up data.
2025-07-13 15:15:13,648:INFO:Set up folding strategy.
2025-07-13 15:15:13,648:INFO:Set up train/test split.
2025-07-13 15:15:13,679:INFO:Set up index.
2025-07-13 15:15:13,679:INFO:Assigning column types.
2025-07-13 15:15:13,679:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 15:15:13,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 15:15:13,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:13,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:13,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 15:15:14,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:14,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,152:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 15:15:14,325:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:14,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:14,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,663:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 15:15:14,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:14,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:15,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:15,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:15,017:INFO:Preparing preprocessing pipeline...
2025-07-13 15:15:15,017:INFO:Set up simple imputation.
2025-07-13 15:15:15,033:INFO:Set up encoding of ordinal features.
2025-07-13 15:15:15,033:INFO:Set up encoding of categorical features.
2025-07-13 15:15:15,233:INFO:Finished creating preprocessing pipeline.
2025-07-13 15:15:15,317:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 15:15:15,318:INFO:Creating final display dataframe.
2025-07-13 15:15:16,084:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              ed9c
2025-07-13 15:15:16,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,437:INFO:setup() successfully completed in 2.92s...............
2025-07-13 15:15:16,476:INFO:PyCaret ClassificationExperiment
2025-07-13 15:15:16,476:INFO:Logging name: clf-default-name
2025-07-13 15:15:16,476:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-13 15:15:16,476:INFO:version 3.3.2
2025-07-13 15:15:16,476:INFO:Initializing setup()
2025-07-13 15:15:16,476:INFO:self.USI: c5bd
2025-07-13 15:15:16,476:INFO:self._variable_keys: {'is_multiclass', 'USI', 'fold_generator', 'target_param', 'data', 'gpu_param', 'pipeline', 'logging_param', 'fix_imbalance', 'X', '_ml_usecase', 'X_test', 'y_test', 'idx', '_available_plots', 'fold_groups_param', 'y', 'fold_shuffle_param', 'n_jobs_param', 'y_train', 'exp_name_log', 'memory', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', 'html_param', 'seed', 'X_train'}
2025-07-13 15:15:16,476:INFO:Checking environment
2025-07-13 15:15:16,476:INFO:python_version: 3.11.0
2025-07-13 15:15:16,476:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-07-13 15:15:16,476:INFO:machine: AMD64
2025-07-13 15:15:16,476:INFO:platform: Windows-10-10.0.19045-SP0
2025-07-13 15:15:16,489:INFO:Memory: svmem(total=12698038272, available=2949586944, percent=76.8, used=9748451328, free=2949586944)
2025-07-13 15:15:16,489:INFO:Physical Core: 2
2025-07-13 15:15:16,489:INFO:Logical Core: 4
2025-07-13 15:15:16,489:INFO:Checking libraries
2025-07-13 15:15:16,489:INFO:System:
2025-07-13 15:15:16,489:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-07-13 15:15:16,489:INFO:executable: C:\Users\Cristina\AppData\Local\Programs\Python\Python311\python.exe
2025-07-13 15:15:16,489:INFO:   machine: Windows-10-10.0.19045-SP0
2025-07-13 15:15:16,489:INFO:PyCaret required dependencies:
2025-07-13 15:15:16,489:INFO:                 pip: 25.1.1
2025-07-13 15:15:16,489:INFO:          setuptools: 65.5.0
2025-07-13 15:15:16,489:INFO:             pycaret: 3.3.2
2025-07-13 15:15:16,489:INFO:             IPython: 9.4.0
2025-07-13 15:15:16,489:INFO:          ipywidgets: 8.1.7
2025-07-13 15:15:16,489:INFO:                tqdm: 4.67.1
2025-07-13 15:15:16,489:INFO:               numpy: 1.26.4
2025-07-13 15:15:16,489:INFO:              pandas: 2.1.4
2025-07-13 15:15:16,489:INFO:              jinja2: 3.1.6
2025-07-13 15:15:16,489:INFO:               scipy: 1.11.4
2025-07-13 15:15:16,489:INFO:              joblib: 1.3.2
2025-07-13 15:15:16,489:INFO:             sklearn: 1.4.2
2025-07-13 15:15:16,489:INFO:                pyod: 2.0.5
2025-07-13 15:15:16,489:INFO:            imblearn: 0.13.0
2025-07-13 15:15:16,489:INFO:   category_encoders: 2.7.0
2025-07-13 15:15:16,489:INFO:            lightgbm: 4.6.0
2025-07-13 15:15:16,489:INFO:               numba: 0.61.2
2025-07-13 15:15:16,489:INFO:            requests: 2.32.3
2025-07-13 15:15:16,489:INFO:          matplotlib: 3.7.5
2025-07-13 15:15:16,489:INFO:          scikitplot: 0.3.7
2025-07-13 15:15:16,489:INFO:         yellowbrick: 1.5
2025-07-13 15:15:16,489:INFO:              plotly: 5.24.1
2025-07-13 15:15:16,489:INFO:    plotly-resampler: Not installed
2025-07-13 15:15:16,489:INFO:             kaleido: 1.0.0
2025-07-13 15:15:16,489:INFO:           schemdraw: 0.15
2025-07-13 15:15:16,489:INFO:         statsmodels: 0.14.4
2025-07-13 15:15:16,489:INFO:              sktime: 0.26.0
2025-07-13 15:15:16,489:INFO:               tbats: 1.1.3
2025-07-13 15:15:16,489:INFO:            pmdarima: 2.0.4
2025-07-13 15:15:16,489:INFO:              psutil: 7.0.0
2025-07-13 15:15:16,489:INFO:          markupsafe: 3.0.2
2025-07-13 15:15:16,489:INFO:             pickle5: Not installed
2025-07-13 15:15:16,489:INFO:         cloudpickle: 3.1.1
2025-07-13 15:15:16,489:INFO:         deprecation: 2.1.0
2025-07-13 15:15:16,489:INFO:              xxhash: 3.5.0
2025-07-13 15:15:16,489:INFO:           wurlitzer: Not installed
2025-07-13 15:15:16,489:INFO:PyCaret optional dependencies:
2025-07-13 15:15:16,489:INFO:                shap: Not installed
2025-07-13 15:15:16,489:INFO:           interpret: Not installed
2025-07-13 15:15:16,489:INFO:                umap: Not installed
2025-07-13 15:15:16,489:INFO:     ydata_profiling: Not installed
2025-07-13 15:15:16,504:INFO:  explainerdashboard: Not installed
2025-07-13 15:15:16,504:INFO:             autoviz: Not installed
2025-07-13 15:15:16,504:INFO:           fairlearn: Not installed
2025-07-13 15:15:16,504:INFO:          deepchecks: Not installed
2025-07-13 15:15:16,504:INFO:             xgboost: Not installed
2025-07-13 15:15:16,504:INFO:            catboost: Not installed
2025-07-13 15:15:16,504:INFO:              kmodes: Not installed
2025-07-13 15:15:16,504:INFO:             mlxtend: Not installed
2025-07-13 15:15:16,504:INFO:       statsforecast: Not installed
2025-07-13 15:15:16,504:INFO:        tune_sklearn: Not installed
2025-07-13 15:15:16,506:INFO:                 ray: Not installed
2025-07-13 15:15:16,506:INFO:            hyperopt: Not installed
2025-07-13 15:15:16,506:INFO:              optuna: Not installed
2025-07-13 15:15:16,506:INFO:               skopt: Not installed
2025-07-13 15:15:16,506:INFO:              mlflow: Not installed
2025-07-13 15:15:16,506:INFO:              gradio: Not installed
2025-07-13 15:15:16,506:INFO:             fastapi: Not installed
2025-07-13 15:15:16,506:INFO:             uvicorn: Not installed
2025-07-13 15:15:16,506:INFO:              m2cgen: Not installed
2025-07-13 15:15:16,506:INFO:           evidently: Not installed
2025-07-13 15:15:16,506:INFO:               fugue: Not installed
2025-07-13 15:15:16,506:INFO:           streamlit: 1.44.1
2025-07-13 15:15:16,506:INFO:             prophet: Not installed
2025-07-13 15:15:16,506:INFO:None
2025-07-13 15:15:16,506:INFO:Set up data.
2025-07-13 15:15:16,523:INFO:Set up folding strategy.
2025-07-13 15:15:16,523:INFO:Set up train/test split.
2025-07-13 15:15:16,544:INFO:Set up index.
2025-07-13 15:15:16,544:INFO:Assigning column types.
2025-07-13 15:15:16,555:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-13 15:15:16,706:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 15:15:16,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:16,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-13 15:15:16,902:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:16,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:16,970:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-13 15:15:17,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:17,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,238:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-13 15:15:17,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,297:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-13 15:15:17,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:17,867:INFO:Preparing preprocessing pipeline...
2025-07-13 15:15:17,867:INFO:Set up simple imputation.
2025-07-13 15:15:17,884:INFO:Set up encoding of ordinal features.
2025-07-13 15:15:17,893:INFO:Set up encoding of categorical features.
2025-07-13 15:15:18,096:INFO:Finished creating preprocessing pipeline.
2025-07-13 15:15:18,146:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-13 15:15:18,147:INFO:Creating final display dataframe.
2025-07-13 15:15:19,077:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape        (9500, 13)
4        Transformed data shape        (9500, 30)
5   Transformed train set shape        (6650, 30)
6    Transformed test set shape        (2850, 30)
7              Numeric features                 5
8          Categorical features                 7
9      Rows with missing values             17.0%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              c5bd
2025-07-13 15:15:19,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:19,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:19,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:19,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-13 15:15:19,438:INFO:setup() successfully completed in 3.0s...............
2025-07-13 15:15:19,457:INFO:Initializing compare_models()
2025-07-13 15:15:19,457:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, include=None, exclude=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-07-13 15:15:19,457:INFO:Checking exceptions
2025-07-13 15:15:19,463:INFO:Preparing display monitor
2025-07-13 15:15:19,467:INFO:Initializing Logistic Regression
2025-07-13 15:15:19,467:INFO:Total runtime is 0.0 minutes
2025-07-13 15:15:19,467:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:19,468:INFO:Initializing create_model()
2025-07-13 15:15:19,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:19,468:INFO:Checking exceptions
2025-07-13 15:15:19,468:INFO:Importing libraries
2025-07-13 15:15:19,468:INFO:Copying training dataset
2025-07-13 15:15:19,476:INFO:Defining folds
2025-07-13 15:15:19,477:INFO:Declaring metric variables
2025-07-13 15:15:19,477:INFO:Importing untrained model
2025-07-13 15:15:19,477:INFO:Logistic Regression Imported successfully
2025-07-13 15:15:19,477:INFO:Starting cross validation
2025-07-13 15:15:19,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:29,979:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:29,984:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:30,134:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:30,155:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:30,334:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:30,471:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:30,533:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:30,625:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:33,346:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:33,487:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:33,601:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:33,728:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:33,866:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:34,057:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:34,081:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:34,232:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:35,744:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:35,766:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:15:35,866:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:35,888:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:35,912:INFO:Calculating mean and std
2025-07-13 15:15:35,914:INFO:Creating metrics dataframe
2025-07-13 15:15:35,919:INFO:Uploading results into container
2025-07-13 15:15:35,920:INFO:Uploading model into container now
2025-07-13 15:15:35,921:INFO:_master_model_container: 1
2025-07-13 15:15:35,921:INFO:_display_container: 2
2025-07-13 15:15:35,922:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 15:15:35,922:INFO:create_model() successfully completed......................................
2025-07-13 15:15:36,083:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:36,084:INFO:Creating metrics dataframe
2025-07-13 15:15:36,092:INFO:Initializing K Neighbors Classifier
2025-07-13 15:15:36,092:INFO:Total runtime is 0.2770721952120463 minutes
2025-07-13 15:15:36,093:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:36,094:INFO:Initializing create_model()
2025-07-13 15:15:36,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:36,094:INFO:Checking exceptions
2025-07-13 15:15:36,094:INFO:Importing libraries
2025-07-13 15:15:36,095:INFO:Copying training dataset
2025-07-13 15:15:36,114:INFO:Defining folds
2025-07-13 15:15:36,114:INFO:Declaring metric variables
2025-07-13 15:15:36,115:INFO:Importing untrained model
2025-07-13 15:15:36,116:INFO:K Neighbors Classifier Imported successfully
2025-07-13 15:15:36,117:INFO:Starting cross validation
2025-07-13 15:15:36,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:38,583:INFO:Calculating mean and std
2025-07-13 15:15:38,583:INFO:Creating metrics dataframe
2025-07-13 15:15:38,583:INFO:Uploading results into container
2025-07-13 15:15:38,583:INFO:Uploading model into container now
2025-07-13 15:15:38,590:INFO:_master_model_container: 2
2025-07-13 15:15:38,590:INFO:_display_container: 2
2025-07-13 15:15:38,590:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-13 15:15:38,590:INFO:create_model() successfully completed......................................
2025-07-13 15:15:38,723:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:38,723:INFO:Creating metrics dataframe
2025-07-13 15:15:38,733:INFO:Initializing Naive Bayes
2025-07-13 15:15:38,733:INFO:Total runtime is 0.3210977872212728 minutes
2025-07-13 15:15:38,733:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:38,733:INFO:Initializing create_model()
2025-07-13 15:15:38,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:38,733:INFO:Checking exceptions
2025-07-13 15:15:38,733:INFO:Importing libraries
2025-07-13 15:15:38,733:INFO:Copying training dataset
2025-07-13 15:15:38,754:INFO:Defining folds
2025-07-13 15:15:38,754:INFO:Declaring metric variables
2025-07-13 15:15:38,754:INFO:Importing untrained model
2025-07-13 15:15:38,754:INFO:Naive Bayes Imported successfully
2025-07-13 15:15:38,754:INFO:Starting cross validation
2025-07-13 15:15:38,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:40,193:INFO:Calculating mean and std
2025-07-13 15:15:40,193:INFO:Creating metrics dataframe
2025-07-13 15:15:40,198:INFO:Uploading results into container
2025-07-13 15:15:40,198:INFO:Uploading model into container now
2025-07-13 15:15:40,200:INFO:_master_model_container: 3
2025-07-13 15:15:40,200:INFO:_display_container: 2
2025-07-13 15:15:40,200:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-13 15:15:40,200:INFO:create_model() successfully completed......................................
2025-07-13 15:15:40,344:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:40,344:INFO:Creating metrics dataframe
2025-07-13 15:15:40,352:INFO:Initializing Decision Tree Classifier
2025-07-13 15:15:40,352:INFO:Total runtime is 0.34807348648707076 minutes
2025-07-13 15:15:40,353:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:40,353:INFO:Initializing create_model()
2025-07-13 15:15:40,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:40,354:INFO:Checking exceptions
2025-07-13 15:15:40,354:INFO:Importing libraries
2025-07-13 15:15:40,354:INFO:Copying training dataset
2025-07-13 15:15:40,369:INFO:Defining folds
2025-07-13 15:15:40,369:INFO:Declaring metric variables
2025-07-13 15:15:40,369:INFO:Importing untrained model
2025-07-13 15:15:40,370:INFO:Decision Tree Classifier Imported successfully
2025-07-13 15:15:40,370:INFO:Starting cross validation
2025-07-13 15:15:40,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:42,011:INFO:Calculating mean and std
2025-07-13 15:15:42,012:INFO:Creating metrics dataframe
2025-07-13 15:15:42,012:INFO:Uploading results into container
2025-07-13 15:15:42,012:INFO:Uploading model into container now
2025-07-13 15:15:42,012:INFO:_master_model_container: 4
2025-07-13 15:15:42,012:INFO:_display_container: 2
2025-07-13 15:15:42,012:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-13 15:15:42,012:INFO:create_model() successfully completed......................................
2025-07-13 15:15:42,113:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:42,113:INFO:Creating metrics dataframe
2025-07-13 15:15:42,121:INFO:Initializing SVM - Linear Kernel
2025-07-13 15:15:42,121:INFO:Total runtime is 0.3775541504224142 minutes
2025-07-13 15:15:42,121:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:42,121:INFO:Initializing create_model()
2025-07-13 15:15:42,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:42,121:INFO:Checking exceptions
2025-07-13 15:15:42,121:INFO:Importing libraries
2025-07-13 15:15:42,121:INFO:Copying training dataset
2025-07-13 15:15:42,131:INFO:Defining folds
2025-07-13 15:15:42,131:INFO:Declaring metric variables
2025-07-13 15:15:42,131:INFO:Importing untrained model
2025-07-13 15:15:42,131:INFO:SVM - Linear Kernel Imported successfully
2025-07-13 15:15:42,131:INFO:Starting cross validation
2025-07-13 15:15:42,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:42,637:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:42,647:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:42,758:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:43,180:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:43,264:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:43,541:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:43,586:INFO:Calculating mean and std
2025-07-13 15:15:43,586:INFO:Creating metrics dataframe
2025-07-13 15:15:43,586:INFO:Uploading results into container
2025-07-13 15:15:43,586:INFO:Uploading model into container now
2025-07-13 15:15:43,586:INFO:_master_model_container: 5
2025-07-13 15:15:43,586:INFO:_display_container: 2
2025-07-13 15:15:43,586:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-13 15:15:43,586:INFO:create_model() successfully completed......................................
2025-07-13 15:15:43,697:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:43,697:INFO:Creating metrics dataframe
2025-07-13 15:15:43,697:INFO:Initializing Ridge Classifier
2025-07-13 15:15:43,697:INFO:Total runtime is 0.4038177053133647 minutes
2025-07-13 15:15:43,697:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:43,697:INFO:Initializing create_model()
2025-07-13 15:15:43,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:43,697:INFO:Checking exceptions
2025-07-13 15:15:43,697:INFO:Importing libraries
2025-07-13 15:15:43,697:INFO:Copying training dataset
2025-07-13 15:15:43,707:INFO:Defining folds
2025-07-13 15:15:43,707:INFO:Declaring metric variables
2025-07-13 15:15:43,707:INFO:Importing untrained model
2025-07-13 15:15:43,707:INFO:Ridge Classifier Imported successfully
2025-07-13 15:15:43,707:INFO:Starting cross validation
2025-07-13 15:15:43,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:44,227:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,227:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,286:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,328:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,764:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,772:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,805:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:44,835:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:45,209:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:45,221:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:15:45,241:INFO:Calculating mean and std
2025-07-13 15:15:45,241:INFO:Creating metrics dataframe
2025-07-13 15:15:45,241:INFO:Uploading results into container
2025-07-13 15:15:45,241:INFO:Uploading model into container now
2025-07-13 15:15:45,241:INFO:_master_model_container: 6
2025-07-13 15:15:45,249:INFO:_display_container: 2
2025-07-13 15:15:45,249:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-13 15:15:45,249:INFO:create_model() successfully completed......................................
2025-07-13 15:15:45,362:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:45,362:INFO:Creating metrics dataframe
2025-07-13 15:15:45,372:INFO:Initializing Random Forest Classifier
2025-07-13 15:15:45,372:INFO:Total runtime is 0.43174153168996177 minutes
2025-07-13 15:15:45,372:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:45,372:INFO:Initializing create_model()
2025-07-13 15:15:45,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:45,372:INFO:Checking exceptions
2025-07-13 15:15:45,372:INFO:Importing libraries
2025-07-13 15:15:45,372:INFO:Copying training dataset
2025-07-13 15:15:45,382:INFO:Defining folds
2025-07-13 15:15:45,382:INFO:Declaring metric variables
2025-07-13 15:15:45,390:INFO:Importing untrained model
2025-07-13 15:15:45,390:INFO:Random Forest Classifier Imported successfully
2025-07-13 15:15:45,390:INFO:Starting cross validation
2025-07-13 15:15:45,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:50,618:INFO:Calculating mean and std
2025-07-13 15:15:50,620:INFO:Creating metrics dataframe
2025-07-13 15:15:50,620:INFO:Uploading results into container
2025-07-13 15:15:50,620:INFO:Uploading model into container now
2025-07-13 15:15:50,620:INFO:_master_model_container: 7
2025-07-13 15:15:50,620:INFO:_display_container: 2
2025-07-13 15:15:50,628:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-13 15:15:50,628:INFO:create_model() successfully completed......................................
2025-07-13 15:15:50,761:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:50,761:INFO:Creating metrics dataframe
2025-07-13 15:15:50,771:INFO:Initializing Quadratic Discriminant Analysis
2025-07-13 15:15:50,771:INFO:Total runtime is 0.5217177510261536 minutes
2025-07-13 15:15:50,771:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:50,771:INFO:Initializing create_model()
2025-07-13 15:15:50,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:50,771:INFO:Checking exceptions
2025-07-13 15:15:50,771:INFO:Importing libraries
2025-07-13 15:15:50,771:INFO:Copying training dataset
2025-07-13 15:15:50,791:INFO:Defining folds
2025-07-13 15:15:50,791:INFO:Declaring metric variables
2025-07-13 15:15:50,791:INFO:Importing untrained model
2025-07-13 15:15:50,791:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-13 15:15:50,791:INFO:Starting cross validation
2025-07-13 15:15:50,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:51,198:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,219:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,230:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,240:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,771:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,792:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,792:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:51,856:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:52,261:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:52,284:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-13 15:15:52,414:INFO:Calculating mean and std
2025-07-13 15:15:52,414:INFO:Creating metrics dataframe
2025-07-13 15:15:52,414:INFO:Uploading results into container
2025-07-13 15:15:52,422:INFO:Uploading model into container now
2025-07-13 15:15:52,422:INFO:_master_model_container: 8
2025-07-13 15:15:52,422:INFO:_display_container: 2
2025-07-13 15:15:52,424:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-13 15:15:52,424:INFO:create_model() successfully completed......................................
2025-07-13 15:15:52,565:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:52,565:INFO:Creating metrics dataframe
2025-07-13 15:15:52,575:INFO:Initializing Ada Boost Classifier
2025-07-13 15:15:52,575:INFO:Total runtime is 0.551793905099233 minutes
2025-07-13 15:15:52,575:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:52,575:INFO:Initializing create_model()
2025-07-13 15:15:52,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:52,575:INFO:Checking exceptions
2025-07-13 15:15:52,575:INFO:Importing libraries
2025-07-13 15:15:52,575:INFO:Copying training dataset
2025-07-13 15:15:52,595:INFO:Defining folds
2025-07-13 15:15:52,595:INFO:Declaring metric variables
2025-07-13 15:15:52,595:INFO:Importing untrained model
2025-07-13 15:15:52,595:INFO:Ada Boost Classifier Imported successfully
2025-07-13 15:15:52,595:INFO:Starting cross validation
2025-07-13 15:15:52,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:15:52,981:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:52,989:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:53,012:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:53,044:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:54,395:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:54,408:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:54,416:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:54,492:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:55,377:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:55,438:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-13 15:15:55,954:INFO:Calculating mean and std
2025-07-13 15:15:55,954:INFO:Creating metrics dataframe
2025-07-13 15:15:55,954:INFO:Uploading results into container
2025-07-13 15:15:55,954:INFO:Uploading model into container now
2025-07-13 15:15:55,954:INFO:_master_model_container: 9
2025-07-13 15:15:55,954:INFO:_display_container: 2
2025-07-13 15:15:55,954:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-13 15:15:55,954:INFO:create_model() successfully completed......................................
2025-07-13 15:15:56,041:INFO:SubProcess create_model() end ==================================
2025-07-13 15:15:56,041:INFO:Creating metrics dataframe
2025-07-13 15:15:56,041:INFO:Initializing Gradient Boosting Classifier
2025-07-13 15:15:56,041:INFO:Total runtime is 0.6095656911532084 minutes
2025-07-13 15:15:56,041:INFO:SubProcess create_model() called ==================================
2025-07-13 15:15:56,057:INFO:Initializing create_model()
2025-07-13 15:15:56,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:15:56,057:INFO:Checking exceptions
2025-07-13 15:15:56,057:INFO:Importing libraries
2025-07-13 15:15:56,057:INFO:Copying training dataset
2025-07-13 15:15:56,057:INFO:Defining folds
2025-07-13 15:15:56,057:INFO:Declaring metric variables
2025-07-13 15:15:56,057:INFO:Importing untrained model
2025-07-13 15:15:56,057:INFO:Gradient Boosting Classifier Imported successfully
2025-07-13 15:15:56,057:INFO:Starting cross validation
2025-07-13 15:15:56,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:02,043:INFO:Calculating mean and std
2025-07-13 15:16:02,043:INFO:Creating metrics dataframe
2025-07-13 15:16:02,043:INFO:Uploading results into container
2025-07-13 15:16:02,043:INFO:Uploading model into container now
2025-07-13 15:16:02,043:INFO:_master_model_container: 10
2025-07-13 15:16:02,043:INFO:_display_container: 2
2025-07-13 15:16:02,043:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-13 15:16:02,043:INFO:create_model() successfully completed......................................
2025-07-13 15:16:02,144:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:02,144:INFO:Creating metrics dataframe
2025-07-13 15:16:02,144:INFO:Initializing Linear Discriminant Analysis
2025-07-13 15:16:02,144:INFO:Total runtime is 0.7112831791241963 minutes
2025-07-13 15:16:02,144:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:02,144:INFO:Initializing create_model()
2025-07-13 15:16:02,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:02,144:INFO:Checking exceptions
2025-07-13 15:16:02,144:INFO:Importing libraries
2025-07-13 15:16:02,144:INFO:Copying training dataset
2025-07-13 15:16:02,160:INFO:Defining folds
2025-07-13 15:16:02,160:INFO:Declaring metric variables
2025-07-13 15:16:02,160:INFO:Importing untrained model
2025-07-13 15:16:02,160:INFO:Linear Discriminant Analysis Imported successfully
2025-07-13 15:16:02,160:INFO:Starting cross validation
2025-07-13 15:16:02,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:02,861:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:02,890:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:02,919:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:02,930:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,380:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,418:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,421:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,454:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,791:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,811:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:03,831:INFO:Calculating mean and std
2025-07-13 15:16:03,831:INFO:Creating metrics dataframe
2025-07-13 15:16:03,831:INFO:Uploading results into container
2025-07-13 15:16:03,831:INFO:Uploading model into container now
2025-07-13 15:16:03,838:INFO:_master_model_container: 11
2025-07-13 15:16:03,838:INFO:_display_container: 2
2025-07-13 15:16:03,838:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-13 15:16:03,838:INFO:create_model() successfully completed......................................
2025-07-13 15:16:03,960:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:03,960:INFO:Creating metrics dataframe
2025-07-13 15:16:03,964:INFO:Initializing Extra Trees Classifier
2025-07-13 15:16:03,965:INFO:Total runtime is 0.7416324218114216 minutes
2025-07-13 15:16:03,965:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:03,965:INFO:Initializing create_model()
2025-07-13 15:16:03,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:03,965:INFO:Checking exceptions
2025-07-13 15:16:03,965:INFO:Importing libraries
2025-07-13 15:16:03,966:INFO:Copying training dataset
2025-07-13 15:16:03,979:INFO:Defining folds
2025-07-13 15:16:03,980:INFO:Declaring metric variables
2025-07-13 15:16:03,980:INFO:Importing untrained model
2025-07-13 15:16:03,980:INFO:Extra Trees Classifier Imported successfully
2025-07-13 15:16:03,981:INFO:Starting cross validation
2025-07-13 15:16:03,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:08,494:INFO:Calculating mean and std
2025-07-13 15:16:08,494:INFO:Creating metrics dataframe
2025-07-13 15:16:08,494:INFO:Uploading results into container
2025-07-13 15:16:08,494:INFO:Uploading model into container now
2025-07-13 15:16:08,494:INFO:_master_model_container: 12
2025-07-13 15:16:08,494:INFO:_display_container: 2
2025-07-13 15:16:08,494:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-13 15:16:08,494:INFO:create_model() successfully completed......................................
2025-07-13 15:16:08,589:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:08,589:INFO:Creating metrics dataframe
2025-07-13 15:16:08,589:INFO:Initializing Light Gradient Boosting Machine
2025-07-13 15:16:08,589:INFO:Total runtime is 0.8186957637468973 minutes
2025-07-13 15:16:08,589:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:08,589:INFO:Initializing create_model()
2025-07-13 15:16:08,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:08,589:INFO:Checking exceptions
2025-07-13 15:16:08,589:INFO:Importing libraries
2025-07-13 15:16:08,589:INFO:Copying training dataset
2025-07-13 15:16:08,605:INFO:Defining folds
2025-07-13 15:16:08,605:INFO:Declaring metric variables
2025-07-13 15:16:08,605:INFO:Importing untrained model
2025-07-13 15:16:08,605:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 15:16:08,605:INFO:Starting cross validation
2025-07-13 15:16:08,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:10,879:INFO:Calculating mean and std
2025-07-13 15:16:10,879:INFO:Creating metrics dataframe
2025-07-13 15:16:10,884:INFO:Uploading results into container
2025-07-13 15:16:10,884:INFO:Uploading model into container now
2025-07-13 15:16:10,884:INFO:_master_model_container: 13
2025-07-13 15:16:10,884:INFO:_display_container: 2
2025-07-13 15:16:10,886:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:10,886:INFO:create_model() successfully completed......................................
2025-07-13 15:16:11,007:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:11,007:INFO:Creating metrics dataframe
2025-07-13 15:16:11,007:INFO:Initializing Dummy Classifier
2025-07-13 15:16:11,007:INFO:Total runtime is 0.8589897354443867 minutes
2025-07-13 15:16:11,007:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:11,007:INFO:Initializing create_model()
2025-07-13 15:16:11,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED69310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:11,007:INFO:Checking exceptions
2025-07-13 15:16:11,007:INFO:Importing libraries
2025-07-13 15:16:11,007:INFO:Copying training dataset
2025-07-13 15:16:11,015:INFO:Defining folds
2025-07-13 15:16:11,015:INFO:Declaring metric variables
2025-07-13 15:16:11,015:INFO:Importing untrained model
2025-07-13 15:16:11,015:INFO:Dummy Classifier Imported successfully
2025-07-13 15:16:11,015:INFO:Starting cross validation
2025-07-13 15:16:11,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:11,404:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,407:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,409:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,428:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,773:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,787:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,797:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:11,807:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:12,035:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:12,047:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-13 15:16:12,065:INFO:Calculating mean and std
2025-07-13 15:16:12,065:INFO:Creating metrics dataframe
2025-07-13 15:16:12,067:INFO:Uploading results into container
2025-07-13 15:16:12,067:INFO:Uploading model into container now
2025-07-13 15:16:12,067:INFO:_master_model_container: 14
2025-07-13 15:16:12,067:INFO:_display_container: 2
2025-07-13 15:16:12,067:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-13 15:16:12,067:INFO:create_model() successfully completed......................................
2025-07-13 15:16:12,164:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:12,165:INFO:Creating metrics dataframe
2025-07-13 15:16:12,171:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-07-13 15:16:12,173:INFO:Initializing create_model()
2025-07-13 15:16:12,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:12,173:INFO:Checking exceptions
2025-07-13 15:16:12,174:INFO:Importing libraries
2025-07-13 15:16:12,174:INFO:Copying training dataset
2025-07-13 15:16:12,183:INFO:Defining folds
2025-07-13 15:16:12,183:INFO:Declaring metric variables
2025-07-13 15:16:12,183:INFO:Importing untrained model
2025-07-13 15:16:12,183:INFO:Declaring custom model
2025-07-13 15:16:12,184:INFO:Logistic Regression Imported successfully
2025-07-13 15:16:12,185:INFO:Cross validation set to False
2025-07-13 15:16:12,185:INFO:Fitting Model
2025-07-13 15:16:13,203:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-13 15:16:13,203:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 15:16:13,203:INFO:create_model() successfully completed......................................
2025-07-13 15:16:13,316:INFO:_master_model_container: 14
2025-07-13 15:16:13,316:INFO:_display_container: 2
2025-07-13 15:16:13,316:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-13 15:16:13,316:INFO:compare_models() successfully completed......................................
2025-07-13 15:16:13,316:INFO:Initializing create_model()
2025-07-13 15:16:13,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:13,316:INFO:Checking exceptions
2025-07-13 15:16:13,316:INFO:Importing libraries
2025-07-13 15:16:13,316:INFO:Copying training dataset
2025-07-13 15:16:13,332:INFO:Defining folds
2025-07-13 15:16:13,332:INFO:Declaring metric variables
2025-07-13 15:16:13,332:INFO:Importing untrained model
2025-07-13 15:16:13,337:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 15:16:13,338:INFO:Starting cross validation
2025-07-13 15:16:13,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:15,672:INFO:Calculating mean and std
2025-07-13 15:16:15,672:INFO:Creating metrics dataframe
2025-07-13 15:16:15,679:INFO:Finalizing model
2025-07-13 15:16:15,880:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 15:16:15,880:INFO:[LightGBM] [Info] Number of positive: 530, number of negative: 6120
2025-07-13 15:16:15,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002078 seconds.
2025-07-13 15:16:15,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 15:16:15,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 15:16:15,890:INFO:[LightGBM] [Info] Total Bins 615
2025-07-13 15:16:15,890:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 15:16:15,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079699 -> initscore=-2.446440
2025-07-13 15:16:15,890:INFO:[LightGBM] [Info] Start training from score -2.446440
2025-07-13 15:16:16,082:INFO:Uploading results into container
2025-07-13 15:16:16,082:INFO:Uploading model into container now
2025-07-13 15:16:16,102:INFO:_master_model_container: 15
2025-07-13 15:16:16,110:INFO:_display_container: 3
2025-07-13 15:16:16,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:16,110:INFO:create_model() successfully completed......................................
2025-07-13 15:16:16,221:INFO:Initializing tune_model()
2025-07-13 15:16:16,221:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-07-13 15:16:16,221:INFO:Checking exceptions
2025-07-13 15:16:16,237:INFO:Copying training dataset
2025-07-13 15:16:16,237:INFO:Checking base model
2025-07-13 15:16:16,237:INFO:Base model : Light Gradient Boosting Machine
2025-07-13 15:16:16,237:INFO:Declaring metric variables
2025-07-13 15:16:16,237:INFO:Defining Hyperparameters
2025-07-13 15:16:16,364:INFO:Tuning with n_jobs=-1
2025-07-13 15:16:16,364:INFO:Initializing RandomizedSearchCV
2025-07-13 15:16:39,987:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2025-07-13 15:16:39,987:INFO:Hyperparameter search completed
2025-07-13 15:16:39,987:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:39,987:INFO:Initializing create_model()
2025-07-13 15:16:39,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002484ED3F710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2025-07-13 15:16:39,987:INFO:Checking exceptions
2025-07-13 15:16:39,987:INFO:Importing libraries
2025-07-13 15:16:39,987:INFO:Copying training dataset
2025-07-13 15:16:40,004:INFO:Defining folds
2025-07-13 15:16:40,004:INFO:Declaring metric variables
2025-07-13 15:16:40,006:INFO:Importing untrained model
2025-07-13 15:16:40,006:INFO:Declaring custom model
2025-07-13 15:16:40,006:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 15:16:40,006:INFO:Starting cross validation
2025-07-13 15:16:40,006:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:42,039:INFO:Calculating mean and std
2025-07-13 15:16:42,039:INFO:Creating metrics dataframe
2025-07-13 15:16:42,039:INFO:Finalizing model
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:42,220:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:42,220:INFO:[LightGBM] [Info] Number of positive: 530, number of negative: 6120
2025-07-13 15:16:42,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.
2025-07-13 15:16:42,236:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 15:16:42,236:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 15:16:42,236:INFO:[LightGBM] [Info] Total Bins 617
2025-07-13 15:16:42,236:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 28
2025-07-13 15:16:42,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079699 -> initscore=-2.446440
2025-07-13 15:16:42,236:INFO:[LightGBM] [Info] Start training from score -2.446440
2025-07-13 15:16:42,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:42,293:INFO:Uploading results into container
2025-07-13 15:16:42,293:INFO:Uploading model into container now
2025-07-13 15:16:42,293:INFO:_master_model_container: 16
2025-07-13 15:16:42,293:INFO:_display_container: 4
2025-07-13 15:16:42,308:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:42,308:INFO:create_model() successfully completed......................................
2025-07-13 15:16:42,438:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:42,438:INFO:choose_better activated
2025-07-13 15:16:42,438:INFO:SubProcess create_model() called ==================================
2025-07-13 15:16:42,446:INFO:Initializing create_model()
2025-07-13 15:16:42,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:42,446:INFO:Checking exceptions
2025-07-13 15:16:42,446:INFO:Importing libraries
2025-07-13 15:16:42,446:INFO:Copying training dataset
2025-07-13 15:16:42,456:INFO:Defining folds
2025-07-13 15:16:42,456:INFO:Declaring metric variables
2025-07-13 15:16:42,456:INFO:Importing untrained model
2025-07-13 15:16:42,456:INFO:Declaring custom model
2025-07-13 15:16:42,458:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 15:16:42,458:INFO:Starting cross validation
2025-07-13 15:16:42,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-13 15:16:44,765:INFO:Calculating mean and std
2025-07-13 15:16:44,766:INFO:Creating metrics dataframe
2025-07-13 15:16:44,768:INFO:Finalizing model
2025-07-13 15:16:44,948:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] Number of positive: 530, number of negative: 6120
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.
2025-07-13 15:16:44,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-07-13 15:16:44,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] Total Bins 615
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] Number of data points in the train set: 6650, number of used features: 27
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079699 -> initscore=-2.446440
2025-07-13 15:16:44,948:INFO:[LightGBM] [Info] Start training from score -2.446440
2025-07-13 15:16:45,071:INFO:Uploading results into container
2025-07-13 15:16:45,071:INFO:Uploading model into container now
2025-07-13 15:16:45,071:INFO:_master_model_container: 17
2025-07-13 15:16:45,071:INFO:_display_container: 5
2025-07-13 15:16:45,071:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:45,071:INFO:create_model() successfully completed......................................
2025-07-13 15:16:45,212:INFO:SubProcess create_model() end ==================================
2025-07-13 15:16:45,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1517
2025-07-13 15:16:45,220:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.1753
2025-07-13 15:16:45,220:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-07-13 15:16:45,220:INFO:choose_better completed
2025-07-13 15:16:45,230:INFO:_master_model_container: 17
2025-07-13 15:16:45,230:INFO:_display_container: 4
2025-07-13 15:16:45,230:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:45,230:INFO:tune_model() successfully completed......................................
2025-07-13 15:16:45,330:INFO:Initializing plot_model()
2025-07-13 15:16:45,330:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 15:16:45,330:INFO:Checking exceptions
2025-07-13 15:16:45,330:INFO:Preloading libraries
2025-07-13 15:16:45,330:INFO:Copying training dataset
2025-07-13 15:16:45,330:INFO:Plot type: auc
2025-07-13 15:16:45,530:INFO:Fitting Model
2025-07-13 15:16:45,530:INFO:Scoring test/hold-out set
2025-07-13 15:16:45,530:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:45,530:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:45,530:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:45,547:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:45,547:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:45,548:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:45,617:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 15:16:45,662:INFO:Visual Rendered Successfully
2025-07-13 15:16:45,757:INFO:plot_model() successfully completed......................................
2025-07-13 15:16:45,758:INFO:Initializing plot_model()
2025-07-13 15:16:45,758:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 15:16:45,758:INFO:Checking exceptions
2025-07-13 15:16:45,762:INFO:Preloading libraries
2025-07-13 15:16:45,769:INFO:Copying training dataset
2025-07-13 15:16:45,770:INFO:Plot type: auc
2025-07-13 15:16:45,961:INFO:Fitting Model
2025-07-13 15:16:45,963:INFO:Scoring test/hold-out set
2025-07-13 15:16:45,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:45,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:45,965:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:45,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:45,975:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:45,975:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:46,031:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 15:16:46,078:INFO:Visual Rendered Successfully
2025-07-13 15:16:46,179:INFO:plot_model() successfully completed......................................
2025-07-13 15:16:46,180:INFO:Initializing plot_model()
2025-07-13 15:16:46,181:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 15:16:46,181:INFO:Checking exceptions
2025-07-13 15:16:46,184:INFO:Preloading libraries
2025-07-13 15:16:46,187:INFO:Copying training dataset
2025-07-13 15:16:46,187:INFO:Plot type: feature
2025-07-13 15:16:46,187:WARNING:No coef_ found. Trying feature_importances_
2025-07-13 15:16:46,309:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 15:16:46,309:INFO:Visual Rendered Successfully
2025-07-13 15:16:46,404:INFO:plot_model() successfully completed......................................
2025-07-13 15:16:46,404:INFO:Initializing plot_model()
2025-07-13 15:16:46,404:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-07-13 15:16:46,404:INFO:Checking exceptions
2025-07-13 15:16:46,404:INFO:Preloading libraries
2025-07-13 15:16:46,419:INFO:Copying training dataset
2025-07-13 15:16:46,419:INFO:Plot type: confusion_matrix
2025-07-13 15:16:46,604:INFO:Fitting Model
2025-07-13 15:16:46,604:INFO:Scoring test/hold-out set
2025-07-13 15:16:46,604:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:46,604:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:46,604:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:46,620:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:46,620:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:46,620:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:46,732:WARNING:C:\Users\Cristina\AppData\Local\Programs\Python\Python311\Lib\site-packages\yellowbrick\base.py:246: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()

2025-07-13 15:16:46,758:INFO:Visual Rendered Successfully
2025-07-13 15:16:46,847:INFO:plot_model() successfully completed......................................
2025-07-13 15:16:46,847:INFO:Initializing predict_model()
2025-07-13 15:16:46,847:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32520>)
2025-07-13 15:16:46,847:INFO:Checking exceptions
2025-07-13 15:16:46,847:INFO:Preloading libraries
2025-07-13 15:16:47,110:INFO:Initializing predict_model()
2025-07-13 15:16:47,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32520>)
2025-07-13 15:16:47,110:INFO:Checking exceptions
2025-07-13 15:16:47,110:INFO:Preloading libraries
2025-07-13 15:16:47,383:INFO:Initializing predict_model()
2025-07-13 15:16:47,383:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32520>)
2025-07-13 15:16:47,383:INFO:Checking exceptions
2025-07-13 15:16:47,383:INFO:Preloading libraries
2025-07-13 15:16:47,645:INFO:Initializing finalize_model()
2025-07-13 15:16:47,645:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-07-13 15:16:47,645:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-07-13 15:16:47,647:INFO:Initializing create_model()
2025-07-13 15:16:47,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-07-13 15:16:47,647:INFO:Checking exceptions
2025-07-13 15:16:47,647:INFO:Importing libraries
2025-07-13 15:16:47,647:INFO:Copying training dataset
2025-07-13 15:16:47,647:INFO:Defining folds
2025-07-13 15:16:47,647:INFO:Declaring metric variables
2025-07-13 15:16:47,647:INFO:Importing untrained model
2025-07-13 15:16:47,647:INFO:Declaring custom model
2025-07-13 15:16:47,647:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-13 15:16:47,655:INFO:Cross validation set to False
2025-07-13 15:16:47,655:INFO:Fitting Model
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2025-07-13 15:16:47,824:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2025-07-13 15:16:47,824:INFO:[LightGBM] [Info] Number of positive: 757, number of negative: 8743
2025-07-13 15:16:47,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001640 seconds.
2025-07-13 15:16:47,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-07-13 15:16:47,840:INFO:[LightGBM] [Info] Total Bins 620
2025-07-13 15:16:47,840:INFO:[LightGBM] [Info] Number of data points in the train set: 9500, number of used features: 29
2025-07-13 15:16:47,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.079684 -> initscore=-2.446645
2025-07-13 15:16:47,840:INFO:[LightGBM] [Info] Start training from score -2.446645
2025-07-13 15:16:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-13 15:16:48,070:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 15:16:48,070:INFO:create_model() successfully completed......................................
2025-07-13 15:16:48,184:INFO:_master_model_container: 17
2025-07-13 15:16:48,184:INFO:_display_container: 7
2025-07-13 15:16:48,241:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 15:16:48,241:INFO:finalize_model() successfully completed......................................
2025-07-13 15:16:48,394:INFO:Initializing predict_model()
2025-07-13 15:16:48,394:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32C00>)
2025-07-13 15:16:48,394:INFO:Checking exceptions
2025-07-13 15:16:48,394:INFO:Preloading libraries
2025-07-13 15:16:48,777:INFO:Initializing predict_model()
2025-07-13 15:16:48,777:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32C00>)
2025-07-13 15:16:48,777:INFO:Checking exceptions
2025-07-13 15:16:48,777:INFO:Preloading libraries
2025-07-13 15:16:48,778:INFO:Set up data.
2025-07-13 15:16:48,780:INFO:Set up index.
2025-07-13 15:16:49,213:INFO:Initializing save_model()
2025-07-13 15:16:49,213:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=Final GBC Model 02Jun2022, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-13 15:16:49,213:INFO:Adding model into prep_pipe
2025-07-13 15:16:49,213:WARNING:Only Model saved as it was a pipeline.
2025-07-13 15:16:49,245:INFO:Final GBC Model 02Jun2022.pkl saved in current working directory
2025-07-13 15:16:49,347:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWra...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2025-07-13 15:16:49,347:INFO:save_model() successfully completed......................................
2025-07-13 15:16:49,445:INFO:Initializing load_model()
2025-07-13 15:16:49,445:INFO:load_model(model_name=Final GBC Model 02Jun2022, platform=None, authentication=None, verbose=True)
2025-07-13 15:16:49,562:INFO:Initializing predict_model()
2025-07-13 15:16:49,563:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002484D56A190>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Cristina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mea...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.5,
                                importance_type='split', learning_rate=0.4,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=20, n_jobs=-1, num_leaves=150,
                                objective=None, random_state=123,
                                reg_alpha=0.005, reg_lambda=0.0005,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002484EE32840>)
2025-07-13 15:16:49,563:INFO:Checking exceptions
2025-07-13 15:16:49,563:INFO:Preloading libraries
2025-07-13 15:16:49,564:INFO:Set up data.
2025-07-13 15:16:49,573:INFO:Set up index.
